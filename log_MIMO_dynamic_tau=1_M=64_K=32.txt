Loading model from models/ldm/text2img-large/model.ckpt
autoencoder.py
LatentDiffusion: Running in eps-prediction mode
DiffusionWrapper has 872.30 M params.
ldm.modules/diffusionmodules/util.py ; make_schedule = linear
ldm/modules/diffusionmodules/model.py, Enocoder; in_channels = 3, ch_mult = [1, 2, 4, 4]
ldm/modules/diffusionmodules/model.py, Resnet in_channels != out_channels
ldm/modules/diffusionmodules/model.py, Resnet in_channels != out_channels
making attention of type 'vanilla' with 512 in_channels
ldm/models/autoencoder.py, AutoencoderKL init, created
Working with z of shape (1, 4, 32, 32) = 4096 dimensions.
making attention of type 'vanilla' with 512 in_channels
ldm/modules/diffusionmodules/model.py, Resnet in_channels != out_channels
ldm/modules/diffusionmodules/model.py, Resnet in_channels != out_channels
remove_png complete
img shape = torch.Size([20, 3, 256, 256])
20 images are saved in ./sentimg/
Encoder, forward@@@@@@@@@@@@@@@
autoencoder.py, h = torch.Size([20, 8, 32, 32])
autoencoder.py , moments = torch.Size([20, 8, 32, 32])
encode start = 
z_variance before normalization = tensor([0.6331, 0.7854, 0.6502, 0.7924, 0.5607, 0.5562, 1.0437, 0.4510, 0.6230,
        0.6187, 0.5298, 0.5912, 0.5910, 0.6297, 0.6507, 0.9634, 0.4686, 0.9956,
        0.5815, 0.6080], device='cuda:0')
Variance (Real, all elements): 0.506136953830719
Variance (Imag, all elements): 0.5006679892539978
--------SNR = -5,  rho_ul = 0.009882117688026186-----------
G_variance = tensor([0.9744, 1.0019, 1.0215, 0.9712, 0.9990, 1.0122, 1.0074, 0.9876, 1.0131,
        1.0454, 0.9716, 0.9852, 0.9870, 1.0302, 1.0491, 1.0051, 1.0119, 1.0320,
        1.0199, 1.0089], device='cuda:0')
G_hat_variance = tensor([0.2412, 0.2378, 0.2461, 0.2387, 0.2433, 0.2376, 0.2307, 0.2354, 0.2525,
        0.2414, 0.2374, 0.2406, 0.2387, 0.2466, 0.2434, 0.2445, 0.2435, 0.2460,
        0.2490, 0.2498], device='cuda:0')
G_tilde_var = tensor([0.7406, 0.7604, 0.7595, 0.7294, 0.7531, 0.7901, 0.7728, 0.7424, 0.7518,
        0.7806, 0.7268, 0.7411, 0.7585, 0.7676, 0.7937, 0.7487, 0.7728, 0.7664,
        0.7713, 0.7596], device='cuda:0')
gamma = tensor([[[0.2403, 0.2403, 0.2403, 0.2403, 0.2403, 0.2403, 0.2403, 0.2403,
          0.2403, 0.2403, 0.2403, 0.2403, 0.2403, 0.2403, 0.2403, 0.2403,
          0.2403, 0.2403, 0.2403, 0.2403, 0.2403, 0.2403, 0.2403, 0.2403,
          0.2403, 0.2403, 0.2403, 0.2403, 0.2403, 0.2403, 0.2403, 0.2403]]],
       device='cuda:0')
Z_mean = tensor([ 0.0049-0.0081j, -0.0255-0.0180j, -0.0007-0.0178j, -0.0126-0.0042j,
         0.0338-0.0084j, -0.0089+0.0033j,  0.0026-0.0127j,  0.0077+0.0066j,
        -0.0193-0.0184j,  0.0033-0.0142j, -0.0100-0.0142j, -0.0346+0.0185j,
         0.0099-0.0236j, -0.0168-0.0017j, -0.0173-0.0243j,  0.0003-0.0018j,
         0.0048+0.0100j,  0.0067-0.0011j, -0.0093-0.0025j, -0.0029+0.0180j],
       device='cuda:0')
Z_variance ~CN(0, 1)= tensor([1.0037, 0.9899, 1.0245, 0.9935, 1.0127, 0.9890, 0.9604, 0.9797, 1.0510,
        1.0048, 0.9882, 1.0015, 0.9935, 1.0265, 1.0130, 1.0177, 1.0137, 1.0241,
        1.0366, 1.0397], device='cuda:0')
Real_SNR = tensor([-5.1851, -4.2006, -3.3868, -4.4676, -4.5777, -4.8282, -5.7206, -4.2695,
        -4.1985, -4.1358, -4.8738, -4.1815, -4.6030, -4.7250, -3.9713, -4.8259,
        -4.2621, -4.1342, -4.5007, -4.6672], device='cuda:0')
q_var = tensor([1.0001, 1.0002, 1.0002, 1.0002, 0.9999, 1.0002, 1.0000, 1.0002, 0.9999,
        1.0002, 1.0002, 1.0000, 1.0000, 0.9986, 1.0002, 0.9998, 1.0002, 1.0002,
        1.0002, 0.9989], device='cuda:0')
(D_eta_sqrt @ q).var = tensor([1.0001, 1.0002, 1.0002, 1.0002, 0.9999, 1.0002, 1.0000, 1.0002, 0.9999,
        1.0002, 1.0002, 1.0000, 1.0000, 0.9986, 1.0002, 0.9998, 1.0002, 1.0002,
        1.0002, 0.9989], device='cuda:0')
(G @ (D_eta_sqrt @ q)).var = tensor([31.8131, 39.4475, 46.4042, 35.2489, 35.1621, 33.5799, 27.7930, 37.6143,
        37.4824, 39.5426, 32.6166, 39.2948, 35.0133, 34.9083, 41.3760, 34.0090,
        38.1801, 39.0340, 36.3524, 33.8600], device='cuda:0')
signal_var = tensor([0.3144, 0.3898, 0.4586, 0.3483, 0.3475, 0.3318, 0.2747, 0.3717, 0.3704,
        0.3908, 0.3223, 0.3883, 0.3460, 0.3450, 0.4089, 0.3361, 0.3773, 0.3857,
        0.3592, 0.3346], device='cuda:0')
w_var = tensor([1.0374, 1.0255, 1.0002, 0.9744, 0.9970, 1.0087, 1.0253, 0.9935, 0.9739,
        1.0127, 0.9901, 1.0170, 0.9986, 1.0240, 1.0203, 1.0210, 1.0067, 0.9993,
        1.0126, 0.9801], device='cuda:0')
y_var = tensor([1.3595, 1.4001, 1.4515, 1.3470, 1.3335, 1.3396, 1.2807, 1.3800, 1.3534,
        1.4189, 1.2979, 1.4171, 1.3520, 1.3647, 1.4390, 1.3554, 1.3615, 1.3814,
        1.3616, 1.3323], device='cuda:0')
####cond finisihed #####
sum_betak_gammak = tensor([24.3119, 24.3119, 24.3119, 24.3119, 24.3119, 24.3119, 24.3119, 24.3119,
        24.3119, 24.3119, 24.3119, 24.3119, 24.3119, 24.3119, 24.3119, 24.3119,
        24.3119, 24.3119, 24.3119, 24.3119], device='cuda:0')
************
inv_Z_H_Z_k (shape: torch.Size([20, 32])) = tensor([[0.0220, 0.0258, 0.0297, 0.0273, 0.0324, 0.0339, 0.0351, 0.0289, 0.0209,
         0.0394, 0.0356, 0.0339, 0.0317, 0.0306, 0.0243, 0.0399, 0.0351, 0.0415,
         0.0289, 0.0357, 0.0404, 0.0466, 0.0273, 0.0449, 0.0282, 0.0395, 0.0248,
         0.0265, 0.0411, 0.0233, 0.0229, 0.0416],
        [0.0450, 0.0311, 0.0330, 0.0266, 0.0313, 0.0313, 0.0428, 0.0320, 0.0374,
         0.0297, 0.0303, 0.0346, 0.0325, 0.0372, 0.0367, 0.0334, 0.0388, 0.0291,
         0.0283, 0.0342, 0.0365, 0.0265, 0.0264, 0.0311, 0.0296, 0.0443, 0.0320,
         0.0402, 0.0295, 0.0322, 0.0268, 0.0317],
        [0.0388, 0.0324, 0.0300, 0.0323, 0.0299, 0.0382, 0.0364, 0.0279, 0.0212,
         0.0210, 0.0338, 0.0282, 0.0271, 0.0234, 0.0296, 0.0278, 0.0324, 0.0326,
         0.0254, 0.0260, 0.0294, 0.0340, 0.0291, 0.0261, 0.0265, 0.0388, 0.0272,
         0.0251, 0.0312, 0.0226, 0.0260, 0.0249],
        [0.0374, 0.0326, 0.0286, 0.0405, 0.0292, 0.0287, 0.0432, 0.0328, 0.0304,
         0.0324, 0.0305, 0.0236, 0.0318, 0.0325, 0.0428, 0.0260, 0.0304, 0.0306,
         0.0245, 0.0421, 0.0335, 0.0212, 0.0313, 0.0390, 0.0273, 0.0355, 0.0305,
         0.0351, 0.0267, 0.0324, 0.0257, 0.0326],
        [0.0381, 0.0315, 0.0286, 0.0257, 0.0267, 0.0284, 0.0287, 0.0272, 0.0347,
         0.0307, 0.0244, 0.0241, 0.0268, 0.0204, 0.0231, 0.0209, 0.0316, 0.0191,
         0.0310, 0.0316, 0.0257, 0.0289, 0.0226, 0.0275, 0.0421, 0.0290, 0.0331,
         0.0261, 0.0213, 0.0310, 0.0198, 0.0246],
        [0.0275, 0.0348, 0.0405, 0.0328, 0.0274, 0.0327, 0.0418, 0.0307, 0.0300,
         0.0334, 0.0254, 0.0305, 0.0309, 0.0315, 0.0240, 0.0339, 0.0392, 0.0341,
         0.0281, 0.0304, 0.0292, 0.0318, 0.0318, 0.0388, 0.0284, 0.0305, 0.0310,
         0.0366, 0.0296, 0.0319, 0.0270, 0.0283],
        [0.0333, 0.0285, 0.0276, 0.0323, 0.0382, 0.0375, 0.0347, 0.0278, 0.0306,
         0.0354, 0.0395, 0.0333, 0.0316, 0.0298, 0.0488, 0.0349, 0.0318, 0.0284,
         0.0345, 0.0241, 0.0316, 0.0437, 0.0332, 0.0299, 0.0267, 0.0384, 0.0275,
         0.0439, 0.0289, 0.0288, 0.0276, 0.0303],
        [0.0373, 0.0244, 0.0367, 0.0335, 0.0334, 0.0359, 0.0412, 0.0385, 0.0304,
         0.0340, 0.0335, 0.0431, 0.0197, 0.0319, 0.0264, 0.0316, 0.0300, 0.0439,
         0.0380, 0.0326, 0.0377, 0.0283, 0.0396, 0.0297, 0.0357, 0.0359, 0.0412,
         0.0381, 0.0298, 0.0417, 0.0429, 0.0377],
        [0.0261, 0.0235, 0.0328, 0.0218, 0.0344, 0.0253, 0.0294, 0.0329, 0.0304,
         0.0305, 0.0328, 0.0220, 0.0297, 0.0251, 0.0321, 0.0285, 0.0292, 0.0289,
         0.0239, 0.0313, 0.0346, 0.0202, 0.0267, 0.0321, 0.0274, 0.0208, 0.0338,
         0.0275, 0.0323, 0.0375, 0.0308, 0.0257],
        [0.0418, 0.0287, 0.0330, 0.0329, 0.0264, 0.0380, 0.0275, 0.0321, 0.0321,
         0.0264, 0.0333, 0.0305, 0.0220, 0.0321, 0.0380, 0.0315, 0.0352, 0.0248,
         0.0298, 0.0302, 0.0265, 0.0346, 0.0301, 0.0301, 0.0241, 0.0299, 0.0358,
         0.0360, 0.0333, 0.0272, 0.0405, 0.0300],
        [0.0353, 0.0338, 0.0307, 0.0248, 0.0306, 0.0317, 0.0264, 0.0307, 0.0294,
         0.0276, 0.0296, 0.0391, 0.0288, 0.0267, 0.0297, 0.0300, 0.0363, 0.0261,
         0.0273, 0.0215, 0.0311, 0.0313, 0.0300, 0.0275, 0.0292, 0.0382, 0.0371,
         0.0232, 0.0314, 0.0322, 0.0272, 0.0327],
        [0.0298, 0.0247, 0.0303, 0.0240, 0.0324, 0.0312, 0.0425, 0.0320, 0.0316,
         0.0442, 0.0285, 0.0351, 0.0461, 0.0338, 0.0312, 0.0321, 0.0305, 0.0284,
         0.0227, 0.0243, 0.0325, 0.0320, 0.0242, 0.0369, 0.0252, 0.0313, 0.0418,
         0.0259, 0.0318, 0.0335, 0.0283, 0.0425],
        [0.0261, 0.0285, 0.0369, 0.0235, 0.0360, 0.0297, 0.0282, 0.0242, 0.0314,
         0.0270, 0.0281, 0.0336, 0.0277, 0.0253, 0.0360, 0.0279, 0.0293, 0.0274,
         0.0312, 0.0246, 0.0284, 0.0316, 0.0343, 0.0317, 0.0321, 0.0281, 0.0254,
         0.0316, 0.0313, 0.0322, 0.0277, 0.0285],
        [0.0326, 0.0325, 0.0237, 0.0348, 0.0222, 0.0290, 0.0333, 0.0314, 0.0231,
         0.0276, 0.0246, 0.0302, 0.0271, 0.0301, 0.0387, 0.0409, 0.0272, 0.0230,
         0.0263, 0.0350, 0.0229, 0.0298, 0.0295, 0.0253, 0.0340, 0.0201, 0.0480,
         0.0352, 0.0310, 0.0254, 0.0301, 0.0182],
        [0.0349, 0.0314, 0.0406, 0.0399, 0.0239, 0.0322, 0.0281, 0.0269, 0.0269,
         0.0223, 0.0346, 0.0330, 0.0289, 0.0422, 0.0247, 0.0270, 0.0327, 0.0243,
         0.0332, 0.0294, 0.0286, 0.0293, 0.0234, 0.0373, 0.0230, 0.0204, 0.0287,
         0.0364, 0.0329, 0.0249, 0.0243, 0.0285],
        [0.0290, 0.0323, 0.0320, 0.0274, 0.0245, 0.0230, 0.0308, 0.0295, 0.0252,
         0.0219, 0.0205, 0.0248, 0.0363, 0.0269, 0.0263, 0.0256, 0.0255, 0.0186,
         0.0305, 0.0320, 0.0309, 0.0306, 0.0464, 0.0227, 0.0237, 0.0295, 0.0261,
         0.0428, 0.0276, 0.0366, 0.0288, 0.0264],
        [0.0272, 0.0332, 0.0378, 0.0320, 0.0291, 0.0280, 0.0280, 0.0229, 0.0246,
         0.0331, 0.0275, 0.0339, 0.0323, 0.0301, 0.0299, 0.0399, 0.0280, 0.0266,
         0.0296, 0.0255, 0.0271, 0.0194, 0.0311, 0.0269, 0.0330, 0.0284, 0.0306,
         0.0271, 0.0243, 0.0268, 0.0315, 0.0233],
        [0.0282, 0.0418, 0.0313, 0.0328, 0.0344, 0.0283, 0.0326, 0.0265, 0.0277,
         0.0296, 0.0342, 0.0310, 0.0236, 0.0337, 0.0231, 0.0350, 0.0232, 0.0267,
         0.0261, 0.0298, 0.0290, 0.0233, 0.0262, 0.0309, 0.0362, 0.0258, 0.0269,
         0.0387, 0.0284, 0.0275, 0.0260, 0.0254],
        [0.0274, 0.0275, 0.0307, 0.0321, 0.0240, 0.0264, 0.0310, 0.0243, 0.0314,
         0.0335, 0.0328, 0.0411, 0.0298, 0.0307, 0.0278, 0.0239, 0.0266, 0.0326,
         0.0250, 0.0297, 0.0355, 0.0254, 0.0324, 0.0341, 0.0267, 0.0207, 0.0265,
         0.0268, 0.0261, 0.0316, 0.0458, 0.0384],
        [0.0265, 0.0344, 0.0390, 0.0257, 0.0292, 0.0382, 0.0292, 0.0266, 0.0263,
         0.0256, 0.0279, 0.0235, 0.0301, 0.0244, 0.0270, 0.0248, 0.0309, 0.0320,
         0.0286, 0.0267, 0.0313, 0.0278, 0.0277, 0.0275, 0.0396, 0.0379, 0.0171,
         0.0300, 0.0303, 0.0248, 0.0306, 0.0252]], device='cuda:0')
inv_Z_H_Z_k.mean (expected to be = 0.03124999990234375) = 0.030554676428437233
Var (shape: torch.Size([20, 32])) = tensor([[0.0273, 0.0320, 0.0368, 0.0339, 0.0402, 0.0421, 0.0436, 0.0358, 0.0260,
         0.0489, 0.0441, 0.0420, 0.0393, 0.0379, 0.0301, 0.0495, 0.0435, 0.0515,
         0.0359, 0.0443, 0.0501, 0.0578, 0.0339, 0.0556, 0.0350, 0.0489, 0.0308,
         0.0329, 0.0509, 0.0289, 0.0284, 0.0516],
        [0.0558, 0.0386, 0.0409, 0.0330, 0.0388, 0.0388, 0.0531, 0.0397, 0.0464,
         0.0369, 0.0376, 0.0429, 0.0403, 0.0462, 0.0455, 0.0415, 0.0481, 0.0360,
         0.0352, 0.0425, 0.0453, 0.0329, 0.0328, 0.0386, 0.0367, 0.0549, 0.0397,
         0.0499, 0.0366, 0.0400, 0.0332, 0.0393],
        [0.0481, 0.0402, 0.0372, 0.0401, 0.0371, 0.0474, 0.0451, 0.0346, 0.0263,
         0.0261, 0.0419, 0.0349, 0.0336, 0.0290, 0.0367, 0.0345, 0.0401, 0.0404,
         0.0314, 0.0322, 0.0364, 0.0421, 0.0361, 0.0324, 0.0329, 0.0482, 0.0338,
         0.0312, 0.0387, 0.0280, 0.0323, 0.0309],
        [0.0464, 0.0405, 0.0354, 0.0502, 0.0362, 0.0356, 0.0536, 0.0406, 0.0378,
         0.0402, 0.0378, 0.0293, 0.0395, 0.0404, 0.0531, 0.0323, 0.0378, 0.0379,
         0.0304, 0.0522, 0.0416, 0.0263, 0.0388, 0.0484, 0.0339, 0.0440, 0.0378,
         0.0436, 0.0331, 0.0402, 0.0319, 0.0405],
        [0.0473, 0.0390, 0.0354, 0.0319, 0.0331, 0.0352, 0.0355, 0.0337, 0.0431,
         0.0381, 0.0303, 0.0299, 0.0332, 0.0254, 0.0286, 0.0259, 0.0392, 0.0237,
         0.0385, 0.0392, 0.0318, 0.0358, 0.0280, 0.0341, 0.0522, 0.0359, 0.0411,
         0.0324, 0.0264, 0.0385, 0.0245, 0.0305],
        [0.0341, 0.0431, 0.0502, 0.0407, 0.0340, 0.0406, 0.0519, 0.0380, 0.0372,
         0.0414, 0.0315, 0.0378, 0.0383, 0.0390, 0.0297, 0.0420, 0.0486, 0.0423,
         0.0349, 0.0377, 0.0363, 0.0395, 0.0395, 0.0481, 0.0352, 0.0379, 0.0384,
         0.0455, 0.0367, 0.0396, 0.0335, 0.0350],
        [0.0414, 0.0354, 0.0343, 0.0400, 0.0474, 0.0466, 0.0430, 0.0345, 0.0379,
         0.0439, 0.0489, 0.0413, 0.0392, 0.0370, 0.0606, 0.0432, 0.0395, 0.0353,
         0.0428, 0.0299, 0.0392, 0.0542, 0.0412, 0.0371, 0.0331, 0.0476, 0.0341,
         0.0544, 0.0358, 0.0357, 0.0342, 0.0376],
        [0.0463, 0.0303, 0.0455, 0.0415, 0.0414, 0.0445, 0.0511, 0.0477, 0.0377,
         0.0422, 0.0416, 0.0534, 0.0244, 0.0396, 0.0327, 0.0392, 0.0372, 0.0544,
         0.0472, 0.0405, 0.0467, 0.0351, 0.0492, 0.0368, 0.0443, 0.0446, 0.0510,
         0.0473, 0.0370, 0.0517, 0.0532, 0.0468],
        [0.0324, 0.0292, 0.0407, 0.0271, 0.0427, 0.0314, 0.0365, 0.0408, 0.0377,
         0.0378, 0.0407, 0.0272, 0.0369, 0.0311, 0.0398, 0.0354, 0.0362, 0.0359,
         0.0296, 0.0388, 0.0429, 0.0251, 0.0331, 0.0398, 0.0339, 0.0258, 0.0420,
         0.0340, 0.0401, 0.0465, 0.0382, 0.0319],
        [0.0519, 0.0356, 0.0409, 0.0408, 0.0327, 0.0471, 0.0341, 0.0398, 0.0398,
         0.0327, 0.0413, 0.0378, 0.0273, 0.0398, 0.0471, 0.0391, 0.0437, 0.0308,
         0.0370, 0.0375, 0.0329, 0.0429, 0.0374, 0.0373, 0.0299, 0.0371, 0.0444,
         0.0446, 0.0413, 0.0337, 0.0502, 0.0372],
        [0.0437, 0.0419, 0.0381, 0.0308, 0.0379, 0.0393, 0.0328, 0.0381, 0.0364,
         0.0342, 0.0368, 0.0485, 0.0357, 0.0331, 0.0369, 0.0372, 0.0451, 0.0323,
         0.0339, 0.0266, 0.0386, 0.0388, 0.0372, 0.0341, 0.0362, 0.0474, 0.0461,
         0.0287, 0.0389, 0.0399, 0.0338, 0.0405],
        [0.0369, 0.0307, 0.0376, 0.0297, 0.0402, 0.0387, 0.0527, 0.0397, 0.0392,
         0.0549, 0.0353, 0.0435, 0.0572, 0.0419, 0.0387, 0.0398, 0.0378, 0.0352,
         0.0282, 0.0302, 0.0403, 0.0397, 0.0301, 0.0457, 0.0313, 0.0388, 0.0518,
         0.0321, 0.0395, 0.0415, 0.0352, 0.0527],
        [0.0324, 0.0354, 0.0457, 0.0292, 0.0447, 0.0369, 0.0349, 0.0300, 0.0389,
         0.0334, 0.0348, 0.0417, 0.0343, 0.0314, 0.0447, 0.0346, 0.0364, 0.0340,
         0.0387, 0.0305, 0.0352, 0.0392, 0.0425, 0.0394, 0.0398, 0.0348, 0.0314,
         0.0391, 0.0388, 0.0399, 0.0344, 0.0353],
        [0.0404, 0.0403, 0.0294, 0.0432, 0.0276, 0.0359, 0.0413, 0.0390, 0.0286,
         0.0342, 0.0306, 0.0374, 0.0336, 0.0373, 0.0480, 0.0508, 0.0338, 0.0286,
         0.0326, 0.0434, 0.0284, 0.0370, 0.0365, 0.0314, 0.0422, 0.0249, 0.0595,
         0.0437, 0.0385, 0.0315, 0.0373, 0.0226],
        [0.0432, 0.0389, 0.0504, 0.0495, 0.0296, 0.0400, 0.0349, 0.0334, 0.0334,
         0.0276, 0.0429, 0.0410, 0.0358, 0.0523, 0.0306, 0.0335, 0.0406, 0.0301,
         0.0411, 0.0365, 0.0354, 0.0364, 0.0291, 0.0462, 0.0285, 0.0253, 0.0356,
         0.0452, 0.0408, 0.0309, 0.0301, 0.0354],
        [0.0360, 0.0401, 0.0397, 0.0340, 0.0304, 0.0285, 0.0382, 0.0366, 0.0312,
         0.0271, 0.0254, 0.0307, 0.0450, 0.0333, 0.0326, 0.0318, 0.0316, 0.0231,
         0.0379, 0.0396, 0.0383, 0.0380, 0.0576, 0.0282, 0.0294, 0.0366, 0.0324,
         0.0531, 0.0342, 0.0454, 0.0358, 0.0328],
        [0.0338, 0.0412, 0.0469, 0.0397, 0.0361, 0.0347, 0.0347, 0.0284, 0.0304,
         0.0410, 0.0341, 0.0421, 0.0400, 0.0373, 0.0371, 0.0494, 0.0347, 0.0329,
         0.0367, 0.0316, 0.0336, 0.0240, 0.0386, 0.0334, 0.0409, 0.0353, 0.0380,
         0.0336, 0.0301, 0.0333, 0.0391, 0.0289],
        [0.0350, 0.0519, 0.0389, 0.0407, 0.0427, 0.0352, 0.0404, 0.0329, 0.0344,
         0.0367, 0.0424, 0.0384, 0.0292, 0.0417, 0.0287, 0.0434, 0.0288, 0.0331,
         0.0323, 0.0370, 0.0359, 0.0289, 0.0325, 0.0383, 0.0450, 0.0320, 0.0334,
         0.0480, 0.0352, 0.0342, 0.0323, 0.0315],
        [0.0340, 0.0342, 0.0381, 0.0398, 0.0297, 0.0327, 0.0384, 0.0302, 0.0389,
         0.0416, 0.0407, 0.0510, 0.0369, 0.0381, 0.0345, 0.0296, 0.0330, 0.0404,
         0.0310, 0.0368, 0.0440, 0.0315, 0.0401, 0.0423, 0.0331, 0.0257, 0.0328,
         0.0333, 0.0323, 0.0391, 0.0568, 0.0476],
        [0.0329, 0.0426, 0.0484, 0.0318, 0.0362, 0.0474, 0.0363, 0.0330, 0.0326,
         0.0317, 0.0346, 0.0292, 0.0373, 0.0303, 0.0335, 0.0308, 0.0384, 0.0397,
         0.0355, 0.0331, 0.0388, 0.0345, 0.0344, 0.0341, 0.0491, 0.0470, 0.0212,
         0.0372, 0.0376, 0.0307, 0.0379, 0.0313]], device='cuda:0')
***********
SINR = tensor([-12.0899, -12.3025, -11.7250, -12.0978, -11.4517, -12.1201, -12.2457,
        -12.4661, -11.6608, -12.0540, -11.9064, -12.0756, -11.8262, -11.6897,
        -11.7821, -11.5801, -11.7166, -11.7826, -11.8242, -11.6771],
       device='cuda:0')
Real_SINR = tensor([-12.4859, -12.4264, -12.0619, -12.2665, -11.7259, -12.4400, -12.5872,
        -12.6065, -11.8896, -12.2701, -11.8301, -12.4873, -11.9265, -11.7854,
        -12.3062, -11.8675, -11.8621, -12.3769, -12.3532, -12.0443],
       device='cuda:0')
Real_SINR_noise.shape = torch.Size([20])
ldm/modules/diffusionmodules/util.py, make_ddim_timsteps ddim_discr_method = uniform
ldm/modules/diffusionmodules/util.py, make_ddim_timsteps, Selected timesteps for ddim sampler: (200,)
ldm/modules/diffusionmodules/util.py, make_ddim_sampling_parameters, Selected alphas for ddim sampler: a_t: torch.Size([200]); a_(t-1): (200,)
For the chosen value of eta, which is 0.0, this results in the following sigma_t schedule for ddim sampler tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], dtype=torch.float64)
ddim.py alphas_cumprod = torch.Size([1000])
ddim.py, alpha_bar_u = tensor([0.0582, 0.0556, 0.0630, 0.0581, 0.0668, 0.0578, 0.0563, 0.0536, 0.0639,
        0.0587, 0.0606, 0.0584, 0.0616, 0.0635, 0.0622, 0.0650, 0.0631, 0.0622,
        0.0617, 0.0636], device='cuda:0')
ddim.py start_timesteps after clamp S = 200 : tensor([746, 752, 736, 746, 729, 747, 750, 756, 734, 745, 741, 746, 739, 735,
        738, 732, 736, 738, 739, 735], device='cuda:0')
d = torch.Size([20, 4, 32, 32])
recoverd_img = torch.Size([20, 3, 256, 256])
20 images are saved in outputs/MIMOdiffusion/M=64/K=32/dynamic/
20 images are saved in outputs/MIMOdiffusion/M=64/K=32/nonoisenosample/
--------SNR = -4,  rho_ul = 0.012440849079796788-----------
G_variance = tensor([1.0069, 1.0036, 1.0165, 0.9995, 0.9668, 0.9863, 0.9786, 0.9966, 1.0166,
        1.0222, 1.0380, 0.9874, 0.9834, 0.9967, 0.9974, 0.9986, 1.0131, 1.0084,
        1.0172, 0.9839], device='cuda:0')
G_hat_variance = tensor([0.2853, 0.2908, 0.2869, 0.2863, 0.2802, 0.2781, 0.2892, 0.2904, 0.2882,
        0.2899, 0.3001, 0.2800, 0.2870, 0.2843, 0.2789, 0.2842, 0.2844, 0.2868,
        0.2794, 0.2840], device='cuda:0')
G_tilde_var = tensor([0.7085, 0.6922, 0.7252, 0.7053, 0.6909, 0.7075, 0.7095, 0.6966, 0.7401,
        0.7237, 0.7350, 0.7391, 0.7020, 0.7196, 0.7269, 0.7289, 0.7326, 0.7186,
        0.7347, 0.6910], device='cuda:0')
gamma = tensor([[[0.2847, 0.2847, 0.2847, 0.2847, 0.2847, 0.2847, 0.2847, 0.2847,
          0.2847, 0.2847, 0.2847, 0.2847, 0.2847, 0.2847, 0.2847, 0.2847,
          0.2847, 0.2847, 0.2847, 0.2847, 0.2847, 0.2847, 0.2847, 0.2847,
          0.2847, 0.2847, 0.2847, 0.2847, 0.2847, 0.2847, 0.2847, 0.2847]]],
       device='cuda:0')
Z_mean = tensor([ 0.0077+0.0221j, -0.0220-0.0169j,  0.0022+0.0082j,  0.0032-0.0117j,
         0.0070+0.0117j, -0.0011-0.0078j, -0.0107-0.0092j, -0.0122-0.0077j,
        -0.0156-0.0235j, -0.0057+0.0035j,  0.0058-0.0056j, -0.0030+0.0032j,
         0.0098-0.0013j,  0.0208-0.0046j, -0.0088-0.0020j, -0.0232-0.0128j,
         0.0192-0.0098j,  0.0182-0.0158j,  0.0042-0.0126j,  0.0042-0.0206j],
       device='cuda:0')
Z_variance ~CN(0, 1)= tensor([1.0020, 1.0212, 1.0074, 1.0054, 0.9839, 0.9765, 1.0157, 1.0199, 1.0122,
        1.0179, 1.0538, 0.9832, 1.0081, 0.9986, 0.9795, 0.9981, 0.9989, 1.0073,
        0.9811, 0.9975], device='cuda:0')
Real_SNR = tensor([-3.5736, -3.0636, -2.8018, -3.7240, -3.7508, -3.7762, -4.0986, -3.3314,
        -3.4197, -3.3141, -3.5195, -3.6216, -3.7019, -3.3506, -3.4008, -4.4621,
        -3.4437, -4.1325, -3.9689, -3.8732], device='cuda:0')
q_var = tensor([1.0001, 1.0002, 1.0002, 1.0002, 0.9999, 1.0002, 1.0000, 1.0002, 0.9999,
        1.0002, 1.0002, 1.0000, 1.0000, 0.9986, 1.0002, 0.9998, 1.0002, 1.0002,
        1.0002, 0.9989], device='cuda:0')
(D_eta_sqrt @ q).var = tensor([1.0001, 1.0002, 1.0002, 1.0002, 0.9999, 1.0002, 1.0000, 1.0002, 0.9999,
        1.0002, 1.0002, 1.0000, 1.0000, 0.9986, 1.0002, 0.9998, 1.0002, 1.0002,
        1.0002, 0.9989], device='cuda:0')
(G @ (D_eta_sqrt @ q)).var = tensor([34.6361, 39.9906, 41.0772, 34.6561, 33.4841, 34.2780, 31.5293, 36.7523,
        36.6826, 37.8019, 36.1837, 35.9199, 34.5571, 37.1847, 37.5091, 28.7579,
        36.4458, 31.5271, 32.6172, 33.7277], device='cuda:0')
signal_var = tensor([0.4309, 0.4975, 0.5110, 0.4312, 0.4166, 0.4264, 0.3923, 0.4572, 0.4564,
        0.4703, 0.4502, 0.4469, 0.4299, 0.4626, 0.4666, 0.3578, 0.4534, 0.3922,
        0.4058, 0.4196], device='cuda:0')
w_var = tensor([0.9811, 1.0073, 0.9742, 1.0163, 0.9880, 1.0174, 1.0079, 0.9846, 1.0030,
        1.0087, 1.0123, 1.0288, 1.0083, 1.0006, 1.0211, 0.9996, 1.0020, 1.0157,
        1.0120, 1.0237], device='cuda:0')
y_var = tensor([1.4147, 1.4841, 1.4796, 1.4412, 1.4259, 1.4269, 1.3909, 1.4469, 1.4684,
        1.4744, 1.4692, 1.4862, 1.4465, 1.4351, 1.4778, 1.3540, 1.4711, 1.4150,
        1.3948, 1.4124], device='cuda:0')
####cond finisihed #####
sum_betak_gammak = tensor([22.8881, 22.8881, 22.8881, 22.8881, 22.8881, 22.8881, 22.8881, 22.8881,
        22.8881, 22.8881, 22.8881, 22.8881, 22.8881, 22.8881, 22.8881, 22.8881,
        22.8881, 22.8881, 22.8881, 22.8881], device='cuda:0')
************
inv_Z_H_Z_k (shape: torch.Size([20, 32])) = tensor([[0.0322, 0.0289, 0.0373, 0.0310, 0.0296, 0.0280, 0.0301, 0.0614, 0.0277,
         0.0236, 0.0296, 0.0344, 0.0311, 0.0312, 0.0285, 0.0282, 0.0221, 0.0373,
         0.0324, 0.0323, 0.0292, 0.0341, 0.0343, 0.0276, 0.0336, 0.0227, 0.0348,
         0.0279, 0.0302, 0.0303, 0.0381, 0.0356],
        [0.0232, 0.0387, 0.0308, 0.0383, 0.0328, 0.0302, 0.0245, 0.0350, 0.0409,
         0.0274, 0.0318, 0.0363, 0.0322, 0.0247, 0.0339, 0.0284, 0.0272, 0.0269,
         0.0237, 0.0279, 0.0262, 0.0269, 0.0216, 0.0252, 0.0282, 0.0314, 0.0385,
         0.0409, 0.0296, 0.0319, 0.0258, 0.0232],
        [0.0349, 0.0277, 0.0304, 0.0211, 0.0314, 0.0252, 0.0271, 0.0297, 0.0256,
         0.0256, 0.0372, 0.0280, 0.0349, 0.0228, 0.0275, 0.0272, 0.0378, 0.0309,
         0.0254, 0.0419, 0.0298, 0.0281, 0.0286, 0.0313, 0.0343, 0.0351, 0.0305,
         0.0284, 0.0314, 0.0332, 0.0436, 0.0272],
        [0.0252, 0.0311, 0.0266, 0.0276, 0.0359, 0.0355, 0.0282, 0.0372, 0.0284,
         0.0321, 0.0289, 0.0329, 0.0300, 0.0348, 0.0389, 0.0361, 0.0304, 0.0457,
         0.0303, 0.0402, 0.0310, 0.0364, 0.0327, 0.0319, 0.0338, 0.0372, 0.0293,
         0.0297, 0.0307, 0.0460, 0.0396, 0.0276],
        [0.0392, 0.0318, 0.0272, 0.0298, 0.0346, 0.0239, 0.0322, 0.0276, 0.0299,
         0.0397, 0.0327, 0.0267, 0.0239, 0.0396, 0.0300, 0.0347, 0.0258, 0.0260,
         0.0260, 0.0283, 0.0309, 0.0288, 0.0310, 0.0368, 0.0316, 0.0271, 0.0331,
         0.0262, 0.0346, 0.0260, 0.0382, 0.0371],
        [0.0314, 0.0366, 0.0274, 0.0319, 0.0267, 0.0339, 0.0340, 0.0210, 0.0331,
         0.0311, 0.0242, 0.0262, 0.0292, 0.0246, 0.0238, 0.0401, 0.0282, 0.0308,
         0.0313, 0.0308, 0.0423, 0.0359, 0.0259, 0.0290, 0.0297, 0.0321, 0.0289,
         0.0320, 0.0318, 0.0419, 0.0261, 0.0340],
        [0.0358, 0.0364, 0.0350, 0.0209, 0.0279, 0.0377, 0.0358, 0.0287, 0.0324,
         0.0222, 0.0350, 0.0294, 0.0291, 0.0301, 0.0239, 0.0260, 0.0268, 0.0223,
         0.0302, 0.0375, 0.0303, 0.0290, 0.0277, 0.0328, 0.0308, 0.0210, 0.0298,
         0.0418, 0.0288, 0.0249, 0.0239, 0.0288],
        [0.0354, 0.0365, 0.0263, 0.0377, 0.0249, 0.0252, 0.0334, 0.0385, 0.0291,
         0.0300, 0.0241, 0.0358, 0.0389, 0.0205, 0.0294, 0.0257, 0.0283, 0.0453,
         0.0277, 0.0398, 0.0350, 0.0310, 0.0213, 0.0458, 0.0263, 0.0261, 0.0345,
         0.0304, 0.0259, 0.0313, 0.0568, 0.0222],
        [0.0258, 0.0239, 0.0303, 0.0240, 0.0334, 0.0267, 0.0255, 0.0291, 0.0247,
         0.0254, 0.0387, 0.0330, 0.0316, 0.0308, 0.0243, 0.0214, 0.0310, 0.0385,
         0.0267, 0.0310, 0.0267, 0.0327, 0.0417, 0.0554, 0.0340, 0.0246, 0.0435,
         0.0292, 0.0476, 0.0353, 0.0345, 0.0372],
        [0.0238, 0.0297, 0.0295, 0.0257, 0.0374, 0.0393, 0.0272, 0.0241, 0.0232,
         0.0350, 0.0336, 0.0277, 0.0322, 0.0269, 0.0240, 0.0290, 0.0302, 0.0289,
         0.0335, 0.0283, 0.0305, 0.0230, 0.0432, 0.0312, 0.0418, 0.0360, 0.0283,
         0.0317, 0.0244, 0.0266, 0.0325, 0.0313],
        [0.0309, 0.0229, 0.0294, 0.0309, 0.0326, 0.0255, 0.0219, 0.0304, 0.0269,
         0.0323, 0.0281, 0.0286, 0.0301, 0.0291, 0.0330, 0.0288, 0.0257, 0.0288,
         0.0250, 0.0290, 0.0387, 0.0243, 0.0281, 0.0247, 0.0263, 0.0280, 0.0339,
         0.0320, 0.0296, 0.0288, 0.0420, 0.0392],
        [0.0363, 0.0373, 0.0318, 0.0355, 0.0285, 0.0322, 0.0372, 0.0313, 0.0347,
         0.0300, 0.0321, 0.0304, 0.0318, 0.0370, 0.0260, 0.0283, 0.0317, 0.0338,
         0.0248, 0.0318, 0.0312, 0.0336, 0.0406, 0.0313, 0.0279, 0.0370, 0.0305,
         0.0261, 0.0267, 0.0300, 0.0329, 0.0343],
        [0.0332, 0.0371, 0.0245, 0.0359, 0.0367, 0.0221, 0.0341, 0.0379, 0.0346,
         0.0209, 0.0299, 0.0345, 0.0258, 0.0328, 0.0324, 0.0292, 0.0231, 0.0302,
         0.0201, 0.0377, 0.0299, 0.0331, 0.0281, 0.0243, 0.0261, 0.0308, 0.0279,
         0.0299, 0.0315, 0.0252, 0.0282, 0.0286],
        [0.0330, 0.0233, 0.0287, 0.0342, 0.0319, 0.0253, 0.0371, 0.0330, 0.0260,
         0.0242, 0.0286, 0.0252, 0.0408, 0.0295, 0.0270, 0.0347, 0.0293, 0.0269,
         0.0256, 0.0281, 0.0331, 0.0253, 0.0276, 0.0329, 0.0271, 0.0473, 0.0372,
         0.0350, 0.0478, 0.0311, 0.0288, 0.0256],
        [0.0307, 0.0328, 0.0373, 0.0305, 0.0336, 0.0381, 0.0315, 0.0345, 0.0347,
         0.0310, 0.0320, 0.0320, 0.0229, 0.0279, 0.0281, 0.0236, 0.0254, 0.0264,
         0.0230, 0.0326, 0.0271, 0.0321, 0.0324, 0.0328, 0.0344, 0.0243, 0.0397,
         0.0353, 0.0420, 0.0240, 0.0364, 0.0374],
        [0.0232, 0.0418, 0.0276, 0.0319, 0.0330, 0.0352, 0.0307, 0.0380, 0.0201,
         0.0304, 0.0383, 0.0251, 0.0316, 0.0272, 0.0588, 0.0325, 0.0275, 0.0328,
         0.0276, 0.0316, 0.0301, 0.0306, 0.0355, 0.0274, 0.0323, 0.0364, 0.0321,
         0.0316, 0.0337, 0.0239, 0.0386, 0.0326],
        [0.0285, 0.0417, 0.0256, 0.0266, 0.0311, 0.0347, 0.0263, 0.0390, 0.0314,
         0.0326, 0.0260, 0.0465, 0.0316, 0.0399, 0.0412, 0.0338, 0.0312, 0.0369,
         0.0314, 0.0324, 0.0374, 0.0293, 0.0248, 0.0307, 0.0322, 0.0270, 0.0256,
         0.0301, 0.0283, 0.0300, 0.0291, 0.0248],
        [0.0422, 0.0312, 0.0288, 0.0308, 0.0349, 0.0213, 0.0280, 0.0284, 0.0314,
         0.0346, 0.0289, 0.0313, 0.0291, 0.0420, 0.0236, 0.0255, 0.0223, 0.0253,
         0.0275, 0.0336, 0.0243, 0.0265, 0.0305, 0.0278, 0.0329, 0.0414, 0.0259,
         0.0320, 0.0309, 0.0409, 0.0299, 0.0322],
        [0.0302, 0.0263, 0.0414, 0.0379, 0.0269, 0.0378, 0.0328, 0.0343, 0.0324,
         0.0411, 0.0473, 0.0314, 0.0540, 0.0221, 0.0415, 0.0317, 0.0288, 0.0428,
         0.0402, 0.0339, 0.0233, 0.0275, 0.0336, 0.0324, 0.0303, 0.0316, 0.0312,
         0.0281, 0.0448, 0.0273, 0.0434, 0.0306],
        [0.0280, 0.0272, 0.0338, 0.0379, 0.0296, 0.0253, 0.0230, 0.0285, 0.0336,
         0.0206, 0.0293, 0.0290, 0.0256, 0.0325, 0.0410, 0.0287, 0.0466, 0.0371,
         0.0438, 0.0340, 0.0314, 0.0441, 0.0363, 0.0265, 0.0251, 0.0247, 0.0293,
         0.0465, 0.0251, 0.0327, 0.0316, 0.0274]], device='cuda:0')
inv_Z_H_Z_k.mean (expected to be = 0.03124999990234375) = 0.031270887702703476
Var (shape: torch.Size([20, 32])) = tensor([[0.0413, 0.0371, 0.0479, 0.0398, 0.0380, 0.0360, 0.0386, 0.0788, 0.0355,
         0.0304, 0.0381, 0.0441, 0.0399, 0.0401, 0.0366, 0.0362, 0.0284, 0.0479,
         0.0416, 0.0415, 0.0375, 0.0438, 0.0440, 0.0355, 0.0432, 0.0292, 0.0447,
         0.0358, 0.0389, 0.0390, 0.0490, 0.0457],
        [0.0298, 0.0497, 0.0396, 0.0493, 0.0422, 0.0388, 0.0315, 0.0449, 0.0525,
         0.0352, 0.0408, 0.0466, 0.0413, 0.0318, 0.0436, 0.0365, 0.0350, 0.0345,
         0.0304, 0.0359, 0.0337, 0.0346, 0.0277, 0.0323, 0.0362, 0.0403, 0.0495,
         0.0525, 0.0380, 0.0410, 0.0331, 0.0298],
        [0.0448, 0.0356, 0.0391, 0.0271, 0.0404, 0.0324, 0.0348, 0.0382, 0.0328,
         0.0329, 0.0478, 0.0359, 0.0448, 0.0293, 0.0353, 0.0349, 0.0485, 0.0397,
         0.0326, 0.0539, 0.0383, 0.0361, 0.0367, 0.0403, 0.0440, 0.0451, 0.0392,
         0.0365, 0.0404, 0.0427, 0.0560, 0.0350],
        [0.0324, 0.0400, 0.0341, 0.0354, 0.0462, 0.0457, 0.0362, 0.0478, 0.0365,
         0.0413, 0.0371, 0.0422, 0.0386, 0.0447, 0.0500, 0.0463, 0.0391, 0.0587,
         0.0390, 0.0517, 0.0398, 0.0467, 0.0420, 0.0410, 0.0434, 0.0478, 0.0377,
         0.0382, 0.0395, 0.0591, 0.0509, 0.0354],
        [0.0503, 0.0408, 0.0350, 0.0383, 0.0444, 0.0306, 0.0413, 0.0354, 0.0385,
         0.0510, 0.0420, 0.0344, 0.0307, 0.0509, 0.0386, 0.0446, 0.0332, 0.0334,
         0.0334, 0.0363, 0.0397, 0.0370, 0.0398, 0.0473, 0.0406, 0.0348, 0.0426,
         0.0336, 0.0445, 0.0334, 0.0490, 0.0476],
        [0.0403, 0.0470, 0.0351, 0.0410, 0.0343, 0.0435, 0.0437, 0.0270, 0.0425,
         0.0399, 0.0311, 0.0336, 0.0376, 0.0316, 0.0305, 0.0515, 0.0362, 0.0395,
         0.0402, 0.0396, 0.0543, 0.0461, 0.0333, 0.0373, 0.0382, 0.0412, 0.0372,
         0.0411, 0.0409, 0.0539, 0.0336, 0.0437],
        [0.0460, 0.0468, 0.0450, 0.0268, 0.0359, 0.0484, 0.0460, 0.0368, 0.0416,
         0.0285, 0.0450, 0.0378, 0.0373, 0.0387, 0.0307, 0.0334, 0.0344, 0.0286,
         0.0388, 0.0482, 0.0389, 0.0372, 0.0355, 0.0422, 0.0396, 0.0270, 0.0383,
         0.0538, 0.0370, 0.0320, 0.0307, 0.0370],
        [0.0455, 0.0469, 0.0338, 0.0484, 0.0320, 0.0323, 0.0428, 0.0494, 0.0374,
         0.0385, 0.0310, 0.0460, 0.0499, 0.0263, 0.0377, 0.0331, 0.0364, 0.0582,
         0.0356, 0.0511, 0.0449, 0.0399, 0.0274, 0.0588, 0.0338, 0.0335, 0.0443,
         0.0391, 0.0333, 0.0402, 0.0729, 0.0286],
        [0.0332, 0.0307, 0.0389, 0.0308, 0.0429, 0.0343, 0.0328, 0.0374, 0.0318,
         0.0327, 0.0497, 0.0424, 0.0406, 0.0396, 0.0312, 0.0274, 0.0398, 0.0494,
         0.0342, 0.0398, 0.0343, 0.0419, 0.0536, 0.0712, 0.0436, 0.0315, 0.0559,
         0.0375, 0.0612, 0.0453, 0.0443, 0.0478],
        [0.0306, 0.0382, 0.0379, 0.0331, 0.0480, 0.0505, 0.0349, 0.0310, 0.0298,
         0.0449, 0.0431, 0.0356, 0.0413, 0.0346, 0.0308, 0.0373, 0.0388, 0.0371,
         0.0431, 0.0363, 0.0392, 0.0296, 0.0555, 0.0401, 0.0537, 0.0463, 0.0363,
         0.0407, 0.0314, 0.0342, 0.0417, 0.0402],
        [0.0397, 0.0294, 0.0378, 0.0397, 0.0419, 0.0327, 0.0282, 0.0390, 0.0345,
         0.0415, 0.0361, 0.0367, 0.0386, 0.0374, 0.0424, 0.0370, 0.0331, 0.0370,
         0.0321, 0.0373, 0.0498, 0.0312, 0.0362, 0.0317, 0.0338, 0.0359, 0.0435,
         0.0411, 0.0381, 0.0371, 0.0540, 0.0503],
        [0.0467, 0.0479, 0.0408, 0.0456, 0.0366, 0.0413, 0.0478, 0.0403, 0.0445,
         0.0386, 0.0412, 0.0391, 0.0408, 0.0476, 0.0334, 0.0363, 0.0407, 0.0434,
         0.0318, 0.0409, 0.0401, 0.0432, 0.0522, 0.0402, 0.0359, 0.0475, 0.0392,
         0.0335, 0.0343, 0.0385, 0.0422, 0.0441],
        [0.0426, 0.0477, 0.0315, 0.0461, 0.0472, 0.0284, 0.0439, 0.0486, 0.0444,
         0.0268, 0.0384, 0.0444, 0.0331, 0.0421, 0.0416, 0.0376, 0.0297, 0.0387,
         0.0258, 0.0484, 0.0384, 0.0426, 0.0361, 0.0312, 0.0336, 0.0396, 0.0358,
         0.0384, 0.0405, 0.0324, 0.0362, 0.0368],
        [0.0424, 0.0300, 0.0369, 0.0439, 0.0410, 0.0324, 0.0477, 0.0424, 0.0334,
         0.0310, 0.0368, 0.0323, 0.0524, 0.0380, 0.0347, 0.0446, 0.0376, 0.0346,
         0.0329, 0.0361, 0.0425, 0.0325, 0.0355, 0.0423, 0.0348, 0.0607, 0.0478,
         0.0449, 0.0614, 0.0400, 0.0370, 0.0329],
        [0.0394, 0.0421, 0.0479, 0.0392, 0.0432, 0.0490, 0.0405, 0.0443, 0.0446,
         0.0399, 0.0411, 0.0411, 0.0295, 0.0358, 0.0361, 0.0303, 0.0327, 0.0339,
         0.0295, 0.0418, 0.0349, 0.0413, 0.0416, 0.0421, 0.0442, 0.0312, 0.0510,
         0.0453, 0.0540, 0.0309, 0.0467, 0.0481],
        [0.0298, 0.0537, 0.0355, 0.0409, 0.0424, 0.0452, 0.0394, 0.0488, 0.0258,
         0.0390, 0.0491, 0.0323, 0.0405, 0.0350, 0.0756, 0.0418, 0.0354, 0.0421,
         0.0354, 0.0406, 0.0387, 0.0393, 0.0456, 0.0352, 0.0415, 0.0468, 0.0413,
         0.0406, 0.0433, 0.0307, 0.0496, 0.0419],
        [0.0367, 0.0536, 0.0329, 0.0342, 0.0400, 0.0445, 0.0338, 0.0501, 0.0403,
         0.0418, 0.0334, 0.0598, 0.0406, 0.0512, 0.0529, 0.0434, 0.0401, 0.0475,
         0.0404, 0.0416, 0.0480, 0.0376, 0.0319, 0.0394, 0.0413, 0.0347, 0.0329,
         0.0386, 0.0364, 0.0385, 0.0374, 0.0319],
        [0.0543, 0.0401, 0.0371, 0.0396, 0.0449, 0.0273, 0.0359, 0.0365, 0.0403,
         0.0445, 0.0371, 0.0402, 0.0373, 0.0540, 0.0304, 0.0328, 0.0287, 0.0324,
         0.0353, 0.0432, 0.0312, 0.0340, 0.0392, 0.0358, 0.0422, 0.0532, 0.0333,
         0.0411, 0.0397, 0.0525, 0.0384, 0.0414],
        [0.0388, 0.0338, 0.0531, 0.0487, 0.0345, 0.0485, 0.0422, 0.0441, 0.0416,
         0.0528, 0.0608, 0.0403, 0.0693, 0.0284, 0.0533, 0.0407, 0.0370, 0.0550,
         0.0516, 0.0436, 0.0299, 0.0353, 0.0431, 0.0417, 0.0389, 0.0406, 0.0400,
         0.0361, 0.0576, 0.0351, 0.0558, 0.0394],
        [0.0360, 0.0350, 0.0434, 0.0487, 0.0380, 0.0325, 0.0296, 0.0367, 0.0432,
         0.0265, 0.0377, 0.0372, 0.0329, 0.0417, 0.0527, 0.0369, 0.0599, 0.0477,
         0.0563, 0.0437, 0.0403, 0.0566, 0.0466, 0.0341, 0.0322, 0.0317, 0.0376,
         0.0597, 0.0322, 0.0420, 0.0405, 0.0352]], device='cuda:0')
***********
SINR = tensor([-10.4701, -10.2534, -10.3162, -10.7113, -10.4099, -10.3715, -10.1993,
        -10.3931, -10.4144, -10.2923, -10.2107, -10.5898, -10.2224, -10.3664,
        -10.4571, -10.5097, -10.5071, -10.3110, -10.7708, -10.4288],
       device='cuda:0')
Real_SINR = tensor([-10.9096, -10.5688, -10.4320, -10.6862, -10.5941, -10.8577,  -9.9306,
        -10.9865, -10.7190, -10.7968, -10.4947, -10.9506, -10.2753, -10.7902,
        -10.7662, -10.7862, -10.8047, -10.2488, -11.1264, -11.0534],
       device='cuda:0')
Real_SINR_noise.shape = torch.Size([20])
ldm/modules/diffusionmodules/util.py, make_ddim_timsteps ddim_discr_method = uniform
ldm/modules/diffusionmodules/util.py, make_ddim_timsteps, Selected timesteps for ddim sampler: (200,)
ldm/modules/diffusionmodules/util.py, make_ddim_sampling_parameters, Selected alphas for ddim sampler: a_t: torch.Size([200]); a_(t-1): (200,)
For the chosen value of eta, which is 0.0, this results in the following sigma_t schedule for ddim sampler tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], dtype=torch.float64)
ddim.py alphas_cumprod = torch.Size([1000])
ddim.py, alpha_bar_u = tensor([0.0823, 0.0862, 0.0851, 0.0783, 0.0834, 0.0841, 0.0872, 0.0837, 0.0833,
        0.0855, 0.0870, 0.0803, 0.0868, 0.0842, 0.0826, 0.0817, 0.0817, 0.0852,
        0.0773, 0.0831], device='cuda:0')
ddim.py start_timesteps after clamp S = 200 : tensor([701, 695, 696, 708, 699, 698, 693, 699, 699, 696, 693, 704, 694, 698,
        700, 702, 702, 696, 709, 700], device='cuda:0')
d = torch.Size([20, 4, 32, 32])
recoverd_img = torch.Size([20, 3, 256, 256])
20 images are saved in outputs/MIMOdiffusion/M=64/K=32/dynamic/
20 images are saved in outputs/MIMOdiffusion/M=64/K=32/nonoisenosample/
--------SNR = -3,  rho_ul = 0.015662101050852258-----------
G_variance = tensor([0.9987, 0.9916, 1.0251, 0.9771, 0.9557, 1.0186, 1.0002, 0.9692, 0.9782,
        1.0458, 0.9882, 1.0103, 0.9827, 0.9642, 1.0063, 1.0038, 0.9696, 0.9946,
        1.0263, 0.9530], device='cuda:0')
G_hat_variance = tensor([0.3420, 0.3214, 0.3340, 0.3124, 0.3301, 0.3224, 0.3326, 0.3245, 0.3209,
        0.3377, 0.3531, 0.3349, 0.3346, 0.3194, 0.3367, 0.3274, 0.3371, 0.3379,
        0.3377, 0.3276], device='cuda:0')
G_tilde_var = tensor([0.6636, 0.6574, 0.6848, 0.6699, 0.6675, 0.6781, 0.6540, 0.6406, 0.6783,
        0.6843, 0.6570, 0.6560, 0.6434, 0.6551, 0.6682, 0.6861, 0.6560, 0.6572,
        0.7101, 0.6500], device='cuda:0')
gamma = tensor([[[0.3339, 0.3339, 0.3339, 0.3339, 0.3339, 0.3339, 0.3339, 0.3339,
          0.3339, 0.3339, 0.3339, 0.3339, 0.3339, 0.3339, 0.3339, 0.3339,
          0.3339, 0.3339, 0.3339, 0.3339, 0.3339, 0.3339, 0.3339, 0.3339,
          0.3339, 0.3339, 0.3339, 0.3339, 0.3339, 0.3339, 0.3339, 0.3339]]],
       device='cuda:0')
Z_mean = tensor([ 2.2249e-02-0.0148j,  2.0530e-02-0.0097j,  7.7375e-03-0.0136j,
         6.4530e-04+0.0105j,  6.9054e-03+0.0169j, -9.9940e-04-0.0005j,
        -1.8063e-02-0.0232j,  1.3350e-02+0.0178j,  1.5326e-02+0.0051j,
        -3.9700e-03-0.0004j,  2.1057e-03+0.0012j,  6.8426e-03-0.0075j,
        -2.3512e-02+0.0052j, -1.6915e-02-0.0015j, -7.6159e-03+0.0073j,
         6.8786e-05-0.0007j,  2.1774e-03-0.0240j, -8.6324e-03-0.0119j,
        -1.7823e-02+0.0116j, -1.4159e-02-0.0318j], device='cuda:0')
Z_variance ~CN(0, 1)= tensor([1.0244, 0.9625, 1.0005, 0.9359, 0.9886, 0.9657, 0.9962, 0.9719, 0.9612,
        1.0114, 1.0576, 1.0031, 1.0022, 0.9567, 1.0086, 0.9806, 1.0097, 1.0122,
        1.0116, 0.9813], device='cuda:0')
Real_SNR = tensor([-3.1931, -2.2620, -1.2816, -3.2839, -2.5033, -2.5011, -3.0136, -2.6500,
        -2.9150, -2.3949, -2.5278, -1.9690, -2.4832, -3.1445, -2.4786, -2.6802,
        -2.7871, -2.2437, -1.9682, -2.8375], device='cuda:0')
q_var = tensor([1.0001, 1.0002, 1.0002, 1.0002, 0.9999, 1.0002, 1.0000, 1.0002, 0.9999,
        1.0002, 1.0002, 1.0000, 1.0000, 0.9986, 1.0002, 0.9998, 1.0002, 1.0002,
        1.0002, 0.9989], device='cuda:0')
(D_eta_sqrt @ q).var = tensor([1.0001, 1.0002, 1.0002, 1.0002, 0.9999, 1.0002, 1.0000, 1.0002, 0.9999,
        1.0002, 1.0002, 1.0000, 1.0000, 0.9986, 1.0002, 0.9998, 1.0002, 1.0002,
        1.0002, 0.9989], device='cuda:0')
(G @ (D_eta_sqrt @ q)).var = tensor([30.9309, 37.9167, 47.9060, 29.8203, 34.9050, 36.2585, 32.1982, 34.8285,
        33.3625, 37.0820, 36.1070, 40.8643, 36.2443, 30.9527, 36.7022, 33.6750,
        33.7007, 38.5806, 41.1074, 33.5322], device='cuda:0')
signal_var = tensor([0.4844, 0.5939, 0.7503, 0.4670, 0.5467, 0.5679, 0.5043, 0.5455, 0.5225,
        0.5808, 0.5655, 0.6400, 0.5677, 0.4848, 0.5748, 0.5274, 0.5278, 0.6043,
        0.6438, 0.5252], device='cuda:0')
w_var = tensor([1.0105, 0.9997, 1.0079, 0.9948, 0.9729, 1.0101, 1.0094, 1.0041, 1.0224,
        1.0081, 1.0121, 1.0072, 1.0056, 1.0000, 1.0172, 0.9776, 1.0028, 1.0130,
        1.0130, 1.0094], device='cuda:0')
y_var = tensor([1.5265, 1.5980, 1.7792, 1.4769, 1.5328, 1.5750, 1.5268, 1.5597, 1.5479,
        1.5938, 1.5852, 1.6400, 1.5807, 1.5015, 1.6114, 1.5231, 1.5491, 1.6124,
        1.6546, 1.5380], device='cuda:0')
####cond finisihed #####
sum_betak_gammak = tensor([21.3165, 21.3165, 21.3165, 21.3165, 21.3165, 21.3165, 21.3165, 21.3165,
        21.3165, 21.3165, 21.3165, 21.3165, 21.3165, 21.3165, 21.3165, 21.3165,
        21.3165, 21.3165, 21.3165, 21.3165], device='cuda:0')
************
inv_Z_H_Z_k (shape: torch.Size([20, 32])) = tensor([[0.0481, 0.0346, 0.0282, 0.0397, 0.0424, 0.0300, 0.0390, 0.0295, 0.0265,
         0.0267, 0.0369, 0.0255, 0.0278, 0.0320, 0.0261, 0.0341, 0.0285, 0.0306,
         0.0263, 0.0382, 0.0238, 0.0353, 0.0279, 0.0256, 0.0242, 0.0308, 0.0338,
         0.0228, 0.0273, 0.0298, 0.0314, 0.0272],
        [0.0298, 0.0272, 0.0401, 0.0351, 0.0358, 0.0313, 0.0318, 0.0349, 0.0299,
         0.0298, 0.0335, 0.0381, 0.0352, 0.0419, 0.0286, 0.0293, 0.0365, 0.0368,
         0.0239, 0.0329, 0.0302, 0.0306, 0.0240, 0.0262, 0.0246, 0.0289, 0.0525,
         0.0205, 0.0247, 0.0268, 0.0278, 0.0292],
        [0.0365, 0.0265, 0.0362, 0.0232, 0.0310, 0.0319, 0.0343, 0.0264, 0.0235,
         0.0330, 0.0312, 0.0250, 0.0297, 0.0299, 0.0301, 0.0276, 0.0246, 0.0321,
         0.0412, 0.0277, 0.0231, 0.0311, 0.0326, 0.0328, 0.0284, 0.0369, 0.0285,
         0.0309, 0.0277, 0.0342, 0.0261, 0.0315],
        [0.0317, 0.0369, 0.0391, 0.0268, 0.0363, 0.0402, 0.0301, 0.0279, 0.0431,
         0.0350, 0.0353, 0.0333, 0.0270, 0.0360, 0.0313, 0.0330, 0.0556, 0.0396,
         0.0351, 0.0343, 0.0301, 0.0379, 0.0294, 0.0268, 0.0451, 0.0363, 0.0377,
         0.0296, 0.0269, 0.0459, 0.0324, 0.0316],
        [0.0329, 0.0231, 0.0307, 0.0425, 0.0351, 0.0351, 0.0200, 0.0329, 0.0351,
         0.0268, 0.0293, 0.0270, 0.0259, 0.0294, 0.0281, 0.0296, 0.0336, 0.0290,
         0.0296, 0.0298, 0.0366, 0.0301, 0.0435, 0.0338, 0.0276, 0.0382, 0.0296,
         0.0356, 0.0302, 0.0297, 0.0288, 0.0286],
        [0.0279, 0.0273, 0.0292, 0.0336, 0.0348, 0.0317, 0.0287, 0.0387, 0.0370,
         0.0368, 0.0408, 0.0390, 0.0298, 0.0176, 0.0392, 0.0414, 0.0300, 0.0249,
         0.0367, 0.0707, 0.0333, 0.0487, 0.0288, 0.0305, 0.0332, 0.0373, 0.0300,
         0.0248, 0.0277, 0.0297, 0.0420, 0.0447],
        [0.0325, 0.0414, 0.0346, 0.0345, 0.0320, 0.0350, 0.0334, 0.0386, 0.0249,
         0.0340, 0.0282, 0.0356, 0.0480, 0.0234, 0.0284, 0.0398, 0.0291, 0.0344,
         0.0373, 0.0348, 0.0332, 0.0315, 0.0290, 0.0293, 0.0278, 0.0299, 0.0322,
         0.0287, 0.0297, 0.0293, 0.0250, 0.0310],
        [0.0380, 0.0339, 0.0351, 0.0283, 0.0313, 0.0331, 0.0267, 0.0317, 0.0250,
         0.0278, 0.0349, 0.0288, 0.0352, 0.0262, 0.0420, 0.0288, 0.0332, 0.0352,
         0.0320, 0.0327, 0.0443, 0.0262, 0.0288, 0.0284, 0.0327, 0.0325, 0.0389,
         0.0363, 0.0325, 0.0281, 0.0340, 0.0272],
        [0.0412, 0.0312, 0.0294, 0.0271, 0.0301, 0.0357, 0.0342, 0.0458, 0.0323,
         0.0309, 0.0359, 0.0270, 0.0285, 0.0349, 0.0315, 0.0248, 0.0311, 0.0395,
         0.0323, 0.0252, 0.0312, 0.0284, 0.0361, 0.0323, 0.0298, 0.0242, 0.0368,
         0.0296, 0.0330, 0.0308, 0.0378, 0.0457],
        [0.0430, 0.0312, 0.0241, 0.0447, 0.0348, 0.0263, 0.0335, 0.0316, 0.0255,
         0.0286, 0.0278, 0.0380, 0.0259, 0.0507, 0.0371, 0.0377, 0.0293, 0.0381,
         0.0339, 0.0379, 0.0358, 0.0432, 0.0290, 0.0278, 0.0245, 0.0320, 0.0303,
         0.0293, 0.0333, 0.0466, 0.0304, 0.0309],
        [0.0324, 0.0273, 0.0269, 0.0215, 0.0305, 0.0254, 0.0286, 0.0276, 0.0280,
         0.0276, 0.0312, 0.0326, 0.0253, 0.0280, 0.0360, 0.0398, 0.0251, 0.0322,
         0.0347, 0.0384, 0.0330, 0.0259, 0.0334, 0.0289, 0.0330, 0.0256, 0.0287,
         0.0259, 0.0335, 0.0304, 0.0304, 0.0295],
        [0.0185, 0.0287, 0.0356, 0.0359, 0.0259, 0.0309, 0.0241, 0.0196, 0.0253,
         0.0381, 0.0319, 0.0311, 0.0309, 0.0355, 0.0333, 0.0340, 0.0364, 0.0266,
         0.0373, 0.0273, 0.0458, 0.0334, 0.0332, 0.0332, 0.0278, 0.0500, 0.0390,
         0.0401, 0.0228, 0.0369, 0.0330, 0.0273],
        [0.0250, 0.0258, 0.0402, 0.0287, 0.0326, 0.0234, 0.0266, 0.0354, 0.0253,
         0.0252, 0.0340, 0.0259, 0.0292, 0.0270, 0.0365, 0.0286, 0.0284, 0.0334,
         0.0286, 0.0337, 0.0310, 0.0222, 0.0297, 0.0399, 0.0329, 0.0287, 0.0284,
         0.0297, 0.0326, 0.0377, 0.0357, 0.0243],
        [0.0343, 0.0365, 0.0308, 0.0324, 0.0261, 0.0347, 0.0325, 0.0306, 0.0365,
         0.0365, 0.0396, 0.0276, 0.0275, 0.0275, 0.0272, 0.0278, 0.0264, 0.0270,
         0.0257, 0.0247, 0.0268, 0.0300, 0.0303, 0.0395, 0.0343, 0.0235, 0.0445,
         0.0254, 0.0248, 0.0336, 0.0321, 0.0325],
        [0.0297, 0.0348, 0.0280, 0.0312, 0.0222, 0.0271, 0.0216, 0.0257, 0.0241,
         0.0329, 0.0323, 0.0382, 0.0266, 0.0361, 0.0301, 0.0272, 0.0242, 0.0219,
         0.0265, 0.0307, 0.0294, 0.0225, 0.0345, 0.0274, 0.0310, 0.0257, 0.0253,
         0.0305, 0.0261, 0.0218, 0.0255, 0.0249],
        [0.0242, 0.0334, 0.0308, 0.0347, 0.0395, 0.0224, 0.0285, 0.0252, 0.0404,
         0.0289, 0.0288, 0.0288, 0.0260, 0.0290, 0.0236, 0.0361, 0.0288, 0.0307,
         0.0212, 0.0316, 0.0251, 0.0310, 0.0346, 0.0254, 0.0310, 0.0413, 0.0269,
         0.0265, 0.0299, 0.0277, 0.0304, 0.0247],
        [0.0264, 0.0273, 0.0308, 0.0260, 0.0319, 0.0279, 0.0348, 0.0266, 0.0191,
         0.0256, 0.0231, 0.0362, 0.0379, 0.0324, 0.0313, 0.0246, 0.0296, 0.0341,
         0.0285, 0.0295, 0.0281, 0.0258, 0.0283, 0.0324, 0.0289, 0.0255, 0.0270,
         0.0267, 0.0304, 0.0344, 0.0285, 0.0335],
        [0.0308, 0.0266, 0.0248, 0.0290, 0.0324, 0.0446, 0.0284, 0.0286, 0.0251,
         0.0293, 0.0345, 0.0272, 0.0355, 0.0271, 0.0326, 0.0305, 0.0364, 0.0344,
         0.0344, 0.0385, 0.0273, 0.0271, 0.0407, 0.0268, 0.0263, 0.0331, 0.0323,
         0.0359, 0.0243, 0.0241, 0.0244, 0.0231],
        [0.0230, 0.0287, 0.0317, 0.0308, 0.0316, 0.0293, 0.0262, 0.0332, 0.0302,
         0.0280, 0.0295, 0.0325, 0.0270, 0.0301, 0.0227, 0.0311, 0.0342, 0.0384,
         0.0246, 0.0381, 0.0232, 0.0289, 0.0318, 0.0308, 0.0322, 0.0283, 0.0309,
         0.0316, 0.0331, 0.0263, 0.0400, 0.0256],
        [0.0232, 0.0432, 0.0337, 0.0415, 0.0389, 0.0301, 0.0317, 0.0335, 0.0267,
         0.0350, 0.0341, 0.0261, 0.0270, 0.0253, 0.0371, 0.0371, 0.0322, 0.0227,
         0.0374, 0.0302, 0.0401, 0.0277, 0.0393, 0.0299, 0.0257, 0.0252, 0.0241,
         0.0315, 0.0343, 0.0397, 0.0316, 0.0357]], device='cuda:0')
inv_Z_H_Z_k.mean (expected to be = 0.03124999990234375) = 0.031343236565589905
Var (shape: torch.Size([20, 32])) = tensor([[0.0641, 0.0461, 0.0376, 0.0529, 0.0565, 0.0401, 0.0520, 0.0393, 0.0354,
         0.0356, 0.0492, 0.0340, 0.0371, 0.0427, 0.0348, 0.0454, 0.0380, 0.0408,
         0.0351, 0.0509, 0.0318, 0.0471, 0.0372, 0.0342, 0.0323, 0.0411, 0.0451,
         0.0305, 0.0364, 0.0397, 0.0418, 0.0363],
        [0.0397, 0.0363, 0.0535, 0.0468, 0.0478, 0.0418, 0.0424, 0.0466, 0.0399,
         0.0397, 0.0447, 0.0508, 0.0470, 0.0559, 0.0381, 0.0391, 0.0486, 0.0491,
         0.0319, 0.0439, 0.0403, 0.0409, 0.0320, 0.0349, 0.0328, 0.0385, 0.0700,
         0.0274, 0.0330, 0.0358, 0.0371, 0.0389],
        [0.0486, 0.0354, 0.0483, 0.0309, 0.0414, 0.0426, 0.0457, 0.0352, 0.0314,
         0.0441, 0.0416, 0.0333, 0.0396, 0.0398, 0.0402, 0.0368, 0.0328, 0.0428,
         0.0550, 0.0369, 0.0308, 0.0415, 0.0434, 0.0438, 0.0378, 0.0492, 0.0380,
         0.0413, 0.0370, 0.0456, 0.0348, 0.0419],
        [0.0423, 0.0492, 0.0521, 0.0358, 0.0485, 0.0537, 0.0401, 0.0371, 0.0575,
         0.0467, 0.0471, 0.0445, 0.0361, 0.0480, 0.0418, 0.0440, 0.0742, 0.0528,
         0.0469, 0.0458, 0.0402, 0.0505, 0.0392, 0.0358, 0.0601, 0.0485, 0.0502,
         0.0395, 0.0359, 0.0613, 0.0432, 0.0421],
        [0.0439, 0.0308, 0.0410, 0.0567, 0.0468, 0.0468, 0.0267, 0.0439, 0.0468,
         0.0358, 0.0391, 0.0360, 0.0346, 0.0392, 0.0375, 0.0394, 0.0448, 0.0387,
         0.0395, 0.0397, 0.0488, 0.0401, 0.0581, 0.0451, 0.0369, 0.0510, 0.0394,
         0.0475, 0.0402, 0.0396, 0.0384, 0.0381],
        [0.0372, 0.0364, 0.0389, 0.0448, 0.0464, 0.0423, 0.0382, 0.0516, 0.0494,
         0.0491, 0.0544, 0.0520, 0.0397, 0.0235, 0.0523, 0.0552, 0.0400, 0.0333,
         0.0489, 0.0944, 0.0445, 0.0650, 0.0384, 0.0407, 0.0443, 0.0498, 0.0400,
         0.0331, 0.0370, 0.0396, 0.0560, 0.0597],
        [0.0434, 0.0552, 0.0461, 0.0461, 0.0426, 0.0467, 0.0446, 0.0515, 0.0333,
         0.0453, 0.0376, 0.0475, 0.0641, 0.0312, 0.0379, 0.0530, 0.0388, 0.0459,
         0.0498, 0.0465, 0.0442, 0.0421, 0.0387, 0.0391, 0.0371, 0.0399, 0.0429,
         0.0382, 0.0396, 0.0391, 0.0333, 0.0413],
        [0.0507, 0.0452, 0.0468, 0.0378, 0.0417, 0.0441, 0.0356, 0.0422, 0.0333,
         0.0371, 0.0466, 0.0385, 0.0470, 0.0350, 0.0560, 0.0385, 0.0442, 0.0469,
         0.0427, 0.0436, 0.0592, 0.0350, 0.0384, 0.0379, 0.0436, 0.0434, 0.0519,
         0.0484, 0.0434, 0.0374, 0.0453, 0.0363],
        [0.0549, 0.0416, 0.0392, 0.0361, 0.0401, 0.0476, 0.0456, 0.0611, 0.0431,
         0.0412, 0.0479, 0.0360, 0.0380, 0.0466, 0.0421, 0.0331, 0.0415, 0.0526,
         0.0431, 0.0337, 0.0415, 0.0379, 0.0482, 0.0430, 0.0397, 0.0323, 0.0491,
         0.0394, 0.0440, 0.0411, 0.0505, 0.0610],
        [0.0574, 0.0417, 0.0322, 0.0596, 0.0464, 0.0351, 0.0446, 0.0422, 0.0340,
         0.0382, 0.0371, 0.0507, 0.0346, 0.0676, 0.0495, 0.0502, 0.0391, 0.0508,
         0.0452, 0.0505, 0.0477, 0.0576, 0.0387, 0.0371, 0.0327, 0.0427, 0.0405,
         0.0391, 0.0444, 0.0622, 0.0405, 0.0412],
        [0.0433, 0.0365, 0.0359, 0.0287, 0.0407, 0.0339, 0.0381, 0.0368, 0.0373,
         0.0368, 0.0417, 0.0435, 0.0338, 0.0374, 0.0480, 0.0531, 0.0334, 0.0429,
         0.0462, 0.0512, 0.0440, 0.0346, 0.0445, 0.0386, 0.0440, 0.0341, 0.0383,
         0.0346, 0.0447, 0.0405, 0.0406, 0.0393],
        [0.0247, 0.0383, 0.0475, 0.0479, 0.0346, 0.0412, 0.0322, 0.0261, 0.0338,
         0.0508, 0.0426, 0.0415, 0.0413, 0.0473, 0.0445, 0.0453, 0.0486, 0.0355,
         0.0497, 0.0364, 0.0611, 0.0445, 0.0443, 0.0443, 0.0370, 0.0667, 0.0520,
         0.0535, 0.0304, 0.0493, 0.0440, 0.0364],
        [0.0334, 0.0345, 0.0536, 0.0383, 0.0435, 0.0312, 0.0355, 0.0472, 0.0338,
         0.0336, 0.0453, 0.0345, 0.0389, 0.0360, 0.0487, 0.0381, 0.0378, 0.0446,
         0.0381, 0.0450, 0.0413, 0.0296, 0.0397, 0.0532, 0.0439, 0.0383, 0.0379,
         0.0396, 0.0435, 0.0503, 0.0476, 0.0324],
        [0.0457, 0.0486, 0.0411, 0.0433, 0.0348, 0.0463, 0.0433, 0.0408, 0.0487,
         0.0487, 0.0528, 0.0368, 0.0367, 0.0367, 0.0363, 0.0370, 0.0352, 0.0360,
         0.0342, 0.0329, 0.0357, 0.0400, 0.0404, 0.0527, 0.0457, 0.0314, 0.0594,
         0.0339, 0.0331, 0.0448, 0.0428, 0.0434],
        [0.0396, 0.0464, 0.0374, 0.0416, 0.0297, 0.0361, 0.0288, 0.0343, 0.0322,
         0.0439, 0.0430, 0.0510, 0.0354, 0.0482, 0.0401, 0.0362, 0.0322, 0.0292,
         0.0354, 0.0409, 0.0392, 0.0300, 0.0460, 0.0366, 0.0413, 0.0343, 0.0338,
         0.0406, 0.0348, 0.0291, 0.0340, 0.0332],
        [0.0323, 0.0445, 0.0410, 0.0463, 0.0527, 0.0299, 0.0380, 0.0336, 0.0539,
         0.0385, 0.0385, 0.0385, 0.0346, 0.0387, 0.0315, 0.0482, 0.0384, 0.0409,
         0.0283, 0.0422, 0.0335, 0.0414, 0.0461, 0.0338, 0.0414, 0.0551, 0.0358,
         0.0354, 0.0399, 0.0369, 0.0405, 0.0330],
        [0.0352, 0.0364, 0.0411, 0.0346, 0.0425, 0.0372, 0.0464, 0.0355, 0.0255,
         0.0342, 0.0308, 0.0482, 0.0505, 0.0432, 0.0417, 0.0328, 0.0395, 0.0455,
         0.0380, 0.0394, 0.0375, 0.0344, 0.0378, 0.0433, 0.0386, 0.0340, 0.0360,
         0.0356, 0.0406, 0.0458, 0.0380, 0.0447],
        [0.0411, 0.0355, 0.0330, 0.0387, 0.0432, 0.0594, 0.0379, 0.0382, 0.0335,
         0.0391, 0.0460, 0.0363, 0.0474, 0.0362, 0.0435, 0.0407, 0.0486, 0.0459,
         0.0459, 0.0514, 0.0365, 0.0361, 0.0543, 0.0357, 0.0351, 0.0442, 0.0430,
         0.0479, 0.0324, 0.0321, 0.0326, 0.0308],
        [0.0307, 0.0383, 0.0423, 0.0411, 0.0422, 0.0391, 0.0349, 0.0443, 0.0403,
         0.0373, 0.0393, 0.0433, 0.0360, 0.0402, 0.0303, 0.0414, 0.0457, 0.0512,
         0.0328, 0.0508, 0.0310, 0.0386, 0.0424, 0.0411, 0.0430, 0.0378, 0.0412,
         0.0421, 0.0441, 0.0351, 0.0533, 0.0342],
        [0.0310, 0.0576, 0.0449, 0.0553, 0.0519, 0.0401, 0.0423, 0.0447, 0.0356,
         0.0467, 0.0455, 0.0348, 0.0360, 0.0338, 0.0495, 0.0495, 0.0429, 0.0303,
         0.0499, 0.0403, 0.0535, 0.0369, 0.0525, 0.0399, 0.0342, 0.0336, 0.0321,
         0.0420, 0.0457, 0.0529, 0.0422, 0.0476]], device='cuda:0')
***********
SINR = tensor([-8.8397, -8.8997, -8.7760, -9.3726, -8.9004, -9.2011, -9.0742, -9.0601,
        -9.0985, -9.1655, -8.7485, -8.9381, -8.7636, -8.8611, -8.4369, -8.6652,
        -8.6299, -8.7959, -8.7735, -9.0106], device='cuda:0')
Real_SINR = tensor([-9.1551, -9.4773, -9.3738, -9.2144, -9.1874, -9.5022, -9.2060, -9.4871,
        -9.3867, -9.0778, -9.3028, -8.9205, -8.9269, -8.9014, -8.8473, -8.6913,
        -8.8072, -9.1712, -9.2199, -9.2197], device='cuda:0')
Real_SINR_noise.shape = torch.Size([20])
ldm/modules/diffusionmodules/util.py, make_ddim_timsteps ddim_discr_method = uniform
ldm/modules/diffusionmodules/util.py, make_ddim_timsteps, Selected timesteps for ddim sampler: (200,)
ldm/modules/diffusionmodules/util.py, make_ddim_sampling_parameters, Selected alphas for ddim sampler: a_t: torch.Size([200]); a_(t-1): (200,)
For the chosen value of eta, which is 0.0, this results in the following sigma_t schedule for ddim sampler tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], dtype=torch.float64)
ddim.py alphas_cumprod = torch.Size([1000])
ddim.py, alpha_bar_u = tensor([0.1155, 0.1141, 0.1170, 0.1036, 0.1141, 0.1073, 0.1101, 0.1104, 0.1096,
        0.1081, 0.1177, 0.1132, 0.1173, 0.1150, 0.1254, 0.1197, 0.1206, 0.1166,
        0.1171, 0.1116], device='cuda:0')
ddim.py start_timesteps after clamp S = 200 : tensor([653, 654, 651, 669, 654, 663, 660, 659, 660, 662, 650, 656, 650, 653,
        640, 647, 646, 651, 651, 658], device='cuda:0')
d = torch.Size([20, 4, 32, 32])
recoverd_img = torch.Size([20, 3, 256, 256])
20 images are saved in outputs/MIMOdiffusion/M=64/K=32/dynamic/
20 images are saved in outputs/MIMOdiffusion/M=64/K=32/nonoisenosample/
--------SNR = -2,  rho_ul = 0.01971741701500604-----------
G_variance = tensor([1.0259, 1.0137, 1.0198, 0.9877, 1.0141, 0.9854, 1.0115, 0.9846, 0.9988,
        1.0350, 0.9973, 0.9954, 0.9661, 0.9815, 0.9873, 0.9953, 1.0166, 1.0257,
        1.0276, 0.9894], device='cuda:0')
G_hat_variance = tensor([0.4027, 0.3900, 0.3776, 0.3861, 0.3886, 0.3918, 0.3880, 0.3787, 0.3962,
        0.4009, 0.3959, 0.3989, 0.3772, 0.3848, 0.3872, 0.3843, 0.3852, 0.4006,
        0.4022, 0.3850], device='cuda:0')
G_tilde_var = tensor([0.6221, 0.6317, 0.6285, 0.6048, 0.6016, 0.5926, 0.6062, 0.6047, 0.6077,
        0.6288, 0.5967, 0.6097, 0.5872, 0.6014, 0.6057, 0.5930, 0.6183, 0.6204,
        0.6109, 0.5996], device='cuda:0')
gamma = tensor([[[0.3869, 0.3869, 0.3869, 0.3869, 0.3869, 0.3869, 0.3869, 0.3869,
          0.3869, 0.3869, 0.3869, 0.3869, 0.3869, 0.3869, 0.3869, 0.3869,
          0.3869, 0.3869, 0.3869, 0.3869, 0.3869, 0.3869, 0.3869, 0.3869,
          0.3869, 0.3869, 0.3869, 0.3869, 0.3869, 0.3869, 0.3869, 0.3869]]],
       device='cuda:0')
Z_mean = tensor([-0.0194-0.0087j,  0.0014+0.0093j, -0.0034-0.0327j,  0.0016+0.0117j,
        -0.0230-0.0026j,  0.0076+0.0129j, -0.0076+0.0002j, -0.0106+0.0066j,
        -0.0037+0.0264j,  0.0014-0.0063j,  0.0187-0.0092j,  0.0143-0.0334j,
         0.0238+0.0085j, -0.0049-0.0099j, -0.0176-0.0212j, -0.0091-0.0204j,
         0.0013+0.0181j, -0.0293+0.0091j, -0.0085+0.0032j,  0.0087+0.0039j],
       device='cuda:0')
Z_variance ~CN(0, 1)= tensor([1.0408, 1.0082, 0.9760, 0.9980, 1.0044, 1.0127, 1.0029, 0.9788, 1.0241,
        1.0362, 1.0235, 1.0312, 0.9751, 0.9945, 1.0009, 0.9935, 0.9958, 1.0355,
        1.0395, 0.9952], device='cuda:0')
Real_SNR = tensor([-1.6917, -1.1527, -0.7535, -2.2328, -2.1226, -1.2593, -1.6909, -1.5671,
        -1.7739, -1.4088, -1.1615, -1.3379, -1.8999, -1.6890, -1.5420, -1.5238,
        -1.9342, -1.0003, -1.2964, -2.6111], device='cuda:0')
q_var = tensor([1.0001, 1.0002, 1.0002, 1.0002, 0.9999, 1.0002, 1.0000, 1.0002, 0.9999,
        1.0002, 1.0002, 1.0000, 1.0000, 0.9986, 1.0002, 0.9998, 1.0002, 1.0002,
        1.0002, 0.9989], device='cuda:0')
(D_eta_sqrt @ q).var = tensor([1.0001, 1.0002, 1.0002, 1.0002, 0.9999, 1.0002, 1.0000, 1.0002, 0.9999,
        1.0002, 1.0002, 1.0000, 1.0000, 0.9986, 1.0002, 0.9998, 1.0002, 1.0002,
        1.0002, 0.9989], device='cuda:0')
(G @ (D_eta_sqrt @ q)).var = tensor([35.2128, 39.9162, 41.8694, 30.5574, 31.9947, 37.6495, 33.6304, 35.3546,
        33.8784, 36.6785, 37.7912, 38.1039, 32.5058, 34.6856, 35.8367, 34.4745,
        32.8535, 40.6417, 38.0036, 28.3039], device='cuda:0')
signal_var = tensor([0.6943, 0.7870, 0.8256, 0.6025, 0.6309, 0.7424, 0.6631, 0.6971, 0.6680,
        0.7232, 0.7451, 0.7513, 0.6409, 0.6839, 0.7066, 0.6797, 0.6478, 0.8013,
        0.7493, 0.5581], device='cuda:0')
w_var = tensor([1.0250, 1.0263, 0.9820, 1.0075, 1.0285, 0.9921, 0.9788, 1.0000, 1.0050,
        1.0003, 0.9736, 1.0224, 0.9927, 1.0090, 1.0078, 0.9654, 1.0112, 1.0089,
        1.0100, 1.0181], device='cuda:0')
y_var = tensor([1.7256, 1.8509, 1.8008, 1.6235, 1.6524, 1.7304, 1.6457, 1.6997, 1.6903,
        1.7212, 1.7571, 1.7629, 1.6327, 1.6860, 1.7003, 1.6700, 1.6600, 1.8144,
        1.7925, 1.5691], device='cuda:0')
####cond finisihed #####
sum_betak_gammak = tensor([19.6204, 19.6204, 19.6204, 19.6204, 19.6204, 19.6204, 19.6204, 19.6204,
        19.6204, 19.6204, 19.6204, 19.6204, 19.6204, 19.6204, 19.6204, 19.6204,
        19.6204, 19.6204, 19.6204, 19.6204], device='cuda:0')
************
inv_Z_H_Z_k (shape: torch.Size([20, 32])) = tensor([[0.0349, 0.0278, 0.0360, 0.0257, 0.0265, 0.0383, 0.0256, 0.0399, 0.0329,
         0.0290, 0.0404, 0.0336, 0.0341, 0.0322, 0.0280, 0.0218, 0.0395, 0.0343,
         0.0233, 0.0280, 0.0280, 0.0458, 0.0445, 0.0321, 0.0260, 0.0311, 0.0339,
         0.0237, 0.0286, 0.0300, 0.0314, 0.0230],
        [0.0301, 0.0339, 0.0325, 0.0330, 0.0281, 0.0322, 0.0269, 0.0269, 0.0361,
         0.0328, 0.0262, 0.0302, 0.0295, 0.0279, 0.0254, 0.0314, 0.0254, 0.0286,
         0.0346, 0.0372, 0.0386, 0.0330, 0.0397, 0.0303, 0.0281, 0.0284, 0.0261,
         0.0275, 0.0335, 0.0355, 0.0261, 0.0235],
        [0.0344, 0.0319, 0.0317, 0.0348, 0.0434, 0.0307, 0.0304, 0.0240, 0.0296,
         0.0274, 0.0404, 0.0281, 0.0272, 0.0270, 0.0289, 0.0244, 0.0326, 0.0359,
         0.0317, 0.0222, 0.0485, 0.0321, 0.0227, 0.0405, 0.0321, 0.0386, 0.0430,
         0.0356, 0.0249, 0.0354, 0.0258, 0.0252],
        [0.0325, 0.0306, 0.0341, 0.0383, 0.0304, 0.0381, 0.0329, 0.0342, 0.0365,
         0.0283, 0.0399, 0.0309, 0.0301, 0.0272, 0.0368, 0.0278, 0.0285, 0.0240,
         0.0309, 0.0333, 0.0288, 0.0431, 0.0306, 0.0287, 0.0267, 0.0323, 0.0299,
         0.0255, 0.0311, 0.0267, 0.0370, 0.0290],
        [0.0327, 0.0278, 0.0256, 0.0244, 0.0359, 0.0360, 0.0428, 0.0409, 0.0294,
         0.0273, 0.0313, 0.0297, 0.0269, 0.0267, 0.0340, 0.0391, 0.0219, 0.0283,
         0.0321, 0.0255, 0.0314, 0.0255, 0.0338, 0.0416, 0.0354, 0.0303, 0.0400,
         0.0283, 0.0343, 0.0318, 0.0237, 0.0333],
        [0.0282, 0.0376, 0.0299, 0.0391, 0.0328, 0.0463, 0.0263, 0.0369, 0.0364,
         0.0250, 0.0286, 0.0297, 0.0269, 0.0343, 0.0445, 0.0331, 0.0319, 0.0204,
         0.0265, 0.0331, 0.0392, 0.0301, 0.0264, 0.0361, 0.0281, 0.0599, 0.0272,
         0.0268, 0.0342, 0.0271, 0.0209, 0.0304],
        [0.0331, 0.0358, 0.0313, 0.0216, 0.0258, 0.0344, 0.0273, 0.0271, 0.0351,
         0.0290, 0.0287, 0.0382, 0.0356, 0.0348, 0.0214, 0.0294, 0.0283, 0.0306,
         0.0352, 0.0342, 0.0327, 0.0286, 0.0299, 0.0250, 0.0351, 0.0249, 0.0451,
         0.0510, 0.0287, 0.0325, 0.0261, 0.0419],
        [0.0349, 0.0394, 0.0248, 0.0306, 0.0305, 0.0407, 0.0247, 0.0306, 0.0340,
         0.0367, 0.0320, 0.0333, 0.0267, 0.0365, 0.0335, 0.0220, 0.0350, 0.0294,
         0.0285, 0.0266, 0.0285, 0.0450, 0.0228, 0.0368, 0.0278, 0.0313, 0.0250,
         0.0341, 0.0375, 0.0275, 0.0320, 0.0263],
        [0.0273, 0.0258, 0.0327, 0.0371, 0.0330, 0.0278, 0.0384, 0.0236, 0.0361,
         0.0255, 0.0337, 0.0291, 0.0302, 0.0397, 0.0244, 0.0395, 0.0303, 0.0290,
         0.0220, 0.0242, 0.0340, 0.0342, 0.0276, 0.0273, 0.0334, 0.0272, 0.0320,
         0.0317, 0.0339, 0.0317, 0.0243, 0.0278],
        [0.0323, 0.0317, 0.0246, 0.0323, 0.0315, 0.0304, 0.0285, 0.0246, 0.0288,
         0.0256, 0.0263, 0.0265, 0.0329, 0.0341, 0.0257, 0.0260, 0.0387, 0.0276,
         0.0290, 0.0370, 0.0308, 0.0285, 0.0250, 0.0292, 0.0307, 0.0411, 0.0180,
         0.0285, 0.0295, 0.0391, 0.0257, 0.0342],
        [0.0304, 0.0310, 0.0375, 0.0395, 0.0278, 0.0247, 0.0237, 0.0291, 0.0255,
         0.0267, 0.0273, 0.0287, 0.0240, 0.0277, 0.0238, 0.0271, 0.0260, 0.0383,
         0.0319, 0.0230, 0.0307, 0.0293, 0.0259, 0.0357, 0.0316, 0.0366, 0.0312,
         0.0226, 0.0317, 0.0440, 0.0236, 0.0260],
        [0.0319, 0.0433, 0.0194, 0.0267, 0.0301, 0.0246, 0.0344, 0.0269, 0.0328,
         0.0461, 0.0333, 0.0223, 0.0282, 0.0315, 0.0316, 0.0305, 0.0297, 0.0286,
         0.0304, 0.0269, 0.0377, 0.0442, 0.0297, 0.0290, 0.0255, 0.0460, 0.0335,
         0.0411, 0.0314, 0.0264, 0.0253, 0.0298],
        [0.0279, 0.0237, 0.0392, 0.0424, 0.0341, 0.0267, 0.0327, 0.0437, 0.0379,
         0.0302, 0.0324, 0.0399, 0.0264, 0.0298, 0.0290, 0.0236, 0.0283, 0.0346,
         0.0324, 0.0324, 0.0303, 0.0269, 0.0342, 0.0260, 0.0420, 0.0344, 0.0358,
         0.0382, 0.0368, 0.0285, 0.0279, 0.0293],
        [0.0236, 0.0387, 0.0244, 0.0278, 0.0290, 0.0305, 0.0275, 0.0209, 0.0286,
         0.0224, 0.0296, 0.0426, 0.0255, 0.0430, 0.0328, 0.0291, 0.0323, 0.0313,
         0.0246, 0.0246, 0.0405, 0.0247, 0.0258, 0.0333, 0.0266, 0.0300, 0.0268,
         0.0260, 0.0278, 0.0218, 0.0259, 0.0248],
        [0.0282, 0.0351, 0.0363, 0.0309, 0.0328, 0.0332, 0.0297, 0.0339, 0.0240,
         0.0320, 0.0354, 0.0397, 0.0290, 0.0289, 0.0271, 0.0297, 0.0324, 0.0324,
         0.0227, 0.0315, 0.0357, 0.0317, 0.0421, 0.0342, 0.0250, 0.0361, 0.0414,
         0.0311, 0.0217, 0.0293, 0.0240, 0.0364],
        [0.0367, 0.0300, 0.0348, 0.0373, 0.0353, 0.0325, 0.0266, 0.0446, 0.0236,
         0.0381, 0.0298, 0.0292, 0.0410, 0.0329, 0.0300, 0.0253, 0.0269, 0.0381,
         0.0302, 0.0328, 0.0467, 0.0234, 0.0278, 0.0378, 0.0317, 0.0232, 0.0284,
         0.0212, 0.0328, 0.0323, 0.0331, 0.0258],
        [0.0333, 0.0309, 0.0404, 0.0446, 0.0331, 0.0400, 0.0280, 0.0317, 0.0336,
         0.0339, 0.0358, 0.0292, 0.0399, 0.0370, 0.0303, 0.0298, 0.0226, 0.0294,
         0.0279, 0.0283, 0.0239, 0.0242, 0.0282, 0.0334, 0.0272, 0.0305, 0.0248,
         0.0350, 0.0421, 0.0259, 0.0319, 0.0416],
        [0.0284, 0.0322, 0.0313, 0.0332, 0.0231, 0.0256, 0.0301, 0.0249, 0.0312,
         0.0271, 0.0331, 0.0259, 0.0315, 0.0303, 0.0390, 0.0323, 0.0313, 0.0330,
         0.0254, 0.0479, 0.0281, 0.0300, 0.0303, 0.0240, 0.0347, 0.0294, 0.0309,
         0.0383, 0.0354, 0.0289, 0.0201, 0.0265],
        [0.0267, 0.0285, 0.0333, 0.0327, 0.0244, 0.0269, 0.0375, 0.0227, 0.0281,
         0.0245, 0.0365, 0.0264, 0.0293, 0.0265, 0.0298, 0.0276, 0.0285, 0.0319,
         0.0320, 0.0284, 0.0313, 0.0329, 0.0256, 0.0389, 0.0389, 0.0265, 0.0323,
         0.0255, 0.0397, 0.0311, 0.0331, 0.0274],
        [0.0446, 0.0317, 0.0431, 0.0381, 0.0332, 0.0359, 0.0232, 0.0331, 0.0345,
         0.0280, 0.0372, 0.0268, 0.0420, 0.0377, 0.0320, 0.0333, 0.0279, 0.0304,
         0.0255, 0.0361, 0.0262, 0.0345, 0.0280, 0.0338, 0.0359, 0.0277, 0.0298,
         0.0239, 0.0270, 0.0280, 0.0330, 0.0307]], device='cuda:0')
inv_Z_H_Z_k.mean (expected to be = 0.03124999990234375) = 0.03119400143623352
Var (shape: torch.Size([20, 32])) = tensor([[0.0484, 0.0386, 0.0500, 0.0356, 0.0368, 0.0531, 0.0355, 0.0553, 0.0456,
         0.0402, 0.0560, 0.0466, 0.0473, 0.0446, 0.0388, 0.0302, 0.0548, 0.0476,
         0.0323, 0.0388, 0.0388, 0.0635, 0.0618, 0.0445, 0.0361, 0.0431, 0.0470,
         0.0329, 0.0396, 0.0417, 0.0435, 0.0319],
        [0.0418, 0.0470, 0.0451, 0.0457, 0.0390, 0.0447, 0.0373, 0.0374, 0.0501,
         0.0455, 0.0363, 0.0418, 0.0409, 0.0387, 0.0352, 0.0436, 0.0352, 0.0397,
         0.0479, 0.0515, 0.0536, 0.0457, 0.0550, 0.0420, 0.0389, 0.0394, 0.0363,
         0.0381, 0.0464, 0.0492, 0.0362, 0.0326],
        [0.0477, 0.0443, 0.0439, 0.0483, 0.0601, 0.0425, 0.0421, 0.0333, 0.0411,
         0.0380, 0.0560, 0.0389, 0.0378, 0.0374, 0.0401, 0.0339, 0.0453, 0.0497,
         0.0440, 0.0309, 0.0672, 0.0445, 0.0315, 0.0561, 0.0445, 0.0535, 0.0596,
         0.0494, 0.0345, 0.0491, 0.0358, 0.0350],
        [0.0451, 0.0425, 0.0472, 0.0532, 0.0421, 0.0528, 0.0457, 0.0475, 0.0506,
         0.0392, 0.0553, 0.0429, 0.0418, 0.0377, 0.0511, 0.0385, 0.0395, 0.0333,
         0.0428, 0.0461, 0.0399, 0.0598, 0.0425, 0.0398, 0.0370, 0.0448, 0.0415,
         0.0354, 0.0431, 0.0370, 0.0513, 0.0402],
        [0.0453, 0.0386, 0.0355, 0.0338, 0.0498, 0.0499, 0.0593, 0.0567, 0.0408,
         0.0378, 0.0434, 0.0411, 0.0373, 0.0371, 0.0471, 0.0542, 0.0304, 0.0392,
         0.0446, 0.0353, 0.0435, 0.0354, 0.0469, 0.0577, 0.0491, 0.0420, 0.0555,
         0.0393, 0.0476, 0.0440, 0.0329, 0.0461],
        [0.0390, 0.0522, 0.0414, 0.0542, 0.0455, 0.0642, 0.0364, 0.0512, 0.0505,
         0.0347, 0.0397, 0.0413, 0.0374, 0.0476, 0.0617, 0.0459, 0.0443, 0.0283,
         0.0368, 0.0459, 0.0544, 0.0418, 0.0367, 0.0500, 0.0389, 0.0830, 0.0377,
         0.0371, 0.0474, 0.0376, 0.0290, 0.0422],
        [0.0459, 0.0496, 0.0434, 0.0300, 0.0358, 0.0477, 0.0378, 0.0376, 0.0487,
         0.0402, 0.0398, 0.0530, 0.0494, 0.0482, 0.0297, 0.0408, 0.0392, 0.0425,
         0.0488, 0.0475, 0.0453, 0.0397, 0.0415, 0.0347, 0.0487, 0.0346, 0.0625,
         0.0707, 0.0398, 0.0450, 0.0362, 0.0582],
        [0.0485, 0.0547, 0.0344, 0.0425, 0.0423, 0.0564, 0.0343, 0.0424, 0.0471,
         0.0509, 0.0444, 0.0461, 0.0371, 0.0506, 0.0464, 0.0306, 0.0486, 0.0408,
         0.0395, 0.0368, 0.0395, 0.0625, 0.0316, 0.0510, 0.0385, 0.0434, 0.0346,
         0.0473, 0.0520, 0.0382, 0.0443, 0.0364],
        [0.0379, 0.0357, 0.0453, 0.0514, 0.0457, 0.0385, 0.0532, 0.0327, 0.0501,
         0.0353, 0.0468, 0.0404, 0.0418, 0.0551, 0.0339, 0.0548, 0.0420, 0.0403,
         0.0305, 0.0336, 0.0472, 0.0474, 0.0383, 0.0378, 0.0463, 0.0377, 0.0444,
         0.0440, 0.0470, 0.0440, 0.0337, 0.0386],
        [0.0448, 0.0440, 0.0341, 0.0447, 0.0437, 0.0422, 0.0395, 0.0342, 0.0400,
         0.0355, 0.0365, 0.0368, 0.0456, 0.0473, 0.0357, 0.0360, 0.0536, 0.0382,
         0.0402, 0.0514, 0.0427, 0.0395, 0.0347, 0.0405, 0.0426, 0.0570, 0.0249,
         0.0396, 0.0409, 0.0542, 0.0357, 0.0474],
        [0.0422, 0.0430, 0.0520, 0.0547, 0.0386, 0.0343, 0.0329, 0.0404, 0.0354,
         0.0371, 0.0378, 0.0398, 0.0333, 0.0384, 0.0330, 0.0376, 0.0361, 0.0531,
         0.0442, 0.0318, 0.0426, 0.0407, 0.0359, 0.0496, 0.0438, 0.0508, 0.0433,
         0.0314, 0.0440, 0.0610, 0.0327, 0.0361],
        [0.0443, 0.0601, 0.0269, 0.0371, 0.0418, 0.0341, 0.0477, 0.0374, 0.0455,
         0.0639, 0.0462, 0.0309, 0.0391, 0.0437, 0.0438, 0.0423, 0.0412, 0.0397,
         0.0421, 0.0374, 0.0522, 0.0614, 0.0412, 0.0402, 0.0354, 0.0639, 0.0464,
         0.0570, 0.0435, 0.0366, 0.0351, 0.0413],
        [0.0387, 0.0329, 0.0543, 0.0588, 0.0473, 0.0370, 0.0454, 0.0606, 0.0525,
         0.0419, 0.0450, 0.0554, 0.0366, 0.0413, 0.0402, 0.0327, 0.0393, 0.0479,
         0.0450, 0.0449, 0.0420, 0.0374, 0.0474, 0.0361, 0.0583, 0.0477, 0.0497,
         0.0530, 0.0511, 0.0395, 0.0387, 0.0406],
        [0.0328, 0.0537, 0.0338, 0.0385, 0.0402, 0.0423, 0.0382, 0.0289, 0.0397,
         0.0311, 0.0411, 0.0590, 0.0354, 0.0597, 0.0455, 0.0403, 0.0448, 0.0434,
         0.0341, 0.0341, 0.0562, 0.0343, 0.0357, 0.0461, 0.0369, 0.0416, 0.0372,
         0.0360, 0.0386, 0.0303, 0.0360, 0.0345],
        [0.0391, 0.0486, 0.0504, 0.0429, 0.0455, 0.0460, 0.0412, 0.0470, 0.0333,
         0.0443, 0.0491, 0.0550, 0.0403, 0.0401, 0.0375, 0.0412, 0.0449, 0.0449,
         0.0314, 0.0437, 0.0495, 0.0440, 0.0584, 0.0475, 0.0347, 0.0501, 0.0575,
         0.0431, 0.0301, 0.0407, 0.0333, 0.0504],
        [0.0508, 0.0416, 0.0482, 0.0517, 0.0490, 0.0451, 0.0369, 0.0619, 0.0327,
         0.0528, 0.0413, 0.0405, 0.0569, 0.0456, 0.0417, 0.0351, 0.0373, 0.0528,
         0.0419, 0.0455, 0.0648, 0.0325, 0.0385, 0.0524, 0.0440, 0.0322, 0.0393,
         0.0294, 0.0455, 0.0448, 0.0459, 0.0358],
        [0.0462, 0.0428, 0.0561, 0.0618, 0.0459, 0.0555, 0.0388, 0.0440, 0.0466,
         0.0470, 0.0497, 0.0405, 0.0553, 0.0513, 0.0420, 0.0413, 0.0314, 0.0408,
         0.0387, 0.0392, 0.0332, 0.0335, 0.0392, 0.0464, 0.0378, 0.0423, 0.0344,
         0.0486, 0.0584, 0.0360, 0.0442, 0.0577],
        [0.0394, 0.0446, 0.0434, 0.0461, 0.0321, 0.0355, 0.0417, 0.0345, 0.0433,
         0.0376, 0.0459, 0.0359, 0.0437, 0.0421, 0.0541, 0.0448, 0.0433, 0.0458,
         0.0352, 0.0665, 0.0389, 0.0415, 0.0421, 0.0333, 0.0481, 0.0408, 0.0429,
         0.0532, 0.0491, 0.0401, 0.0279, 0.0368],
        [0.0371, 0.0395, 0.0461, 0.0453, 0.0338, 0.0374, 0.0520, 0.0315, 0.0390,
         0.0340, 0.0506, 0.0367, 0.0406, 0.0367, 0.0413, 0.0383, 0.0396, 0.0442,
         0.0443, 0.0394, 0.0434, 0.0456, 0.0356, 0.0540, 0.0540, 0.0368, 0.0448,
         0.0354, 0.0550, 0.0431, 0.0459, 0.0380],
        [0.0618, 0.0440, 0.0597, 0.0528, 0.0460, 0.0498, 0.0321, 0.0459, 0.0478,
         0.0389, 0.0516, 0.0371, 0.0583, 0.0523, 0.0444, 0.0462, 0.0386, 0.0421,
         0.0353, 0.0501, 0.0363, 0.0478, 0.0389, 0.0469, 0.0497, 0.0384, 0.0413,
         0.0331, 0.0374, 0.0388, 0.0457, 0.0426]], device='cuda:0')
***********
SINR = tensor([-7.4322, -7.3783, -7.4701, -7.5280, -7.4506, -7.4813, -7.4694, -7.4404,
        -7.3266, -7.2273, -7.1644, -7.4110, -7.5862, -7.0549, -7.4891, -7.4753,
        -7.5358, -7.3102, -7.3026, -7.5676], device='cuda:0')
Real_SINR = tensor([-7.9489, -7.6913, -8.0369, -7.8369, -7.5157, -7.6359, -7.8528, -7.4522,
        -7.7184, -7.5893, -7.3843, -7.9393, -7.4468, -7.1935, -7.6416, -7.2166,
        -7.8188, -7.4036, -7.6196, -7.8417], device='cuda:0')
Real_SINR_noise.shape = torch.Size([20])
ldm/modules/diffusionmodules/util.py, make_ddim_timsteps ddim_discr_method = uniform
ldm/modules/diffusionmodules/util.py, make_ddim_timsteps, Selected timesteps for ddim sampler: (200,)
ldm/modules/diffusionmodules/util.py, make_ddim_sampling_parameters, Selected alphas for ddim sampler: a_t: torch.Size([200]); a_(t-1): (200,)
For the chosen value of eta, which is 0.0, this results in the following sigma_t schedule for ddim sampler tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], dtype=torch.float64)
ddim.py alphas_cumprod = torch.Size([1000])
ddim.py, alpha_bar_u = tensor([0.1530, 0.1546, 0.1519, 0.1502, 0.1524, 0.1515, 0.1519, 0.1527, 0.1562,
        0.1592, 0.1612, 0.1536, 0.1485, 0.1646, 0.1513, 0.1517, 0.1499, 0.1567,
        0.1569, 0.1490], device='cuda:0')
ddim.py start_timesteps after clamp S = 200 : tensor([609, 607, 610, 612, 609, 610, 610, 609, 605, 602, 600, 608, 614, 597,
        610, 610, 612, 605, 605, 613], device='cuda:0')
d = torch.Size([20, 4, 32, 32])
recoverd_img = torch.Size([20, 3, 256, 256])
20 images are saved in outputs/MIMOdiffusion/M=64/K=32/dynamic/
20 images are saved in outputs/MIMOdiffusion/M=64/K=32/nonoisenosample/
--------SNR = -1,  rho_ul = 0.024822757335133797-----------
G_variance = tensor([1.0036, 1.0205, 0.9672, 1.0047, 1.0035, 0.9890, 1.0220, 0.9769, 0.9983,
        1.0201, 1.0034, 1.0197, 0.9805, 0.9942, 0.9455, 1.0007, 0.9679, 1.0145,
        0.9964, 1.0158], device='cuda:0')
G_hat_variance = tensor([0.4336, 0.4423, 0.4393, 0.4328, 0.4545, 0.4606, 0.4487, 0.4464, 0.4578,
        0.4469, 0.4389, 0.4453, 0.4335, 0.4286, 0.4325, 0.4491, 0.4255, 0.4409,
        0.4498, 0.4530], device='cuda:0')
G_tilde_var = tensor([0.5689, 0.5496, 0.5460, 0.5749, 0.5591, 0.5483, 0.5691, 0.5220, 0.5559,
        0.5488, 0.5637, 0.5794, 0.5459, 0.5544, 0.5352, 0.5465, 0.5531, 0.5542,
        0.5536, 0.5604], device='cuda:0')
gamma = tensor([[[0.4427, 0.4427, 0.4427, 0.4427, 0.4427, 0.4427, 0.4427, 0.4427,
          0.4427, 0.4427, 0.4427, 0.4427, 0.4427, 0.4427, 0.4427, 0.4427,
          0.4427, 0.4427, 0.4427, 0.4427, 0.4427, 0.4427, 0.4427, 0.4427,
          0.4427, 0.4427, 0.4427, 0.4427, 0.4427, 0.4427, 0.4427, 0.4427]]],
       device='cuda:0')
Z_mean = tensor([-0.0203-0.0251j,  0.0375+0.0127j, -0.0035+0.0048j, -0.0149+0.0085j,
         0.0168-0.0043j, -0.0142+0.0066j,  0.0029-0.0067j, -0.0021-0.0046j,
         0.0191+0.0028j, -0.0126-0.0057j,  0.0009-0.0070j,  0.0206+0.0058j,
         0.0171+0.0289j,  0.0069+0.0163j, -0.0031+0.0104j, -0.0293-0.0068j,
         0.0006-0.0132j,  0.0046-0.0182j,  0.0018+0.0086j, -0.0158-0.0316j],
       device='cuda:0')
Z_variance ~CN(0, 1)= tensor([0.9796, 0.9992, 0.9925, 0.9776, 1.0267, 1.0405, 1.0136, 1.0084, 1.0342,
        1.0096, 0.9914, 1.0059, 0.9793, 0.9682, 0.9770, 1.0144, 0.9612, 0.9960,
        1.0161, 1.0233], device='cuda:0')
Real_SNR = tensor([-0.7162, -0.9976,  0.0571, -0.3286, -0.6202, -0.7280, -0.0299, -0.4448,
        -0.5437, -0.1226, -0.5592, -0.1937, -0.8749, -0.9644,  0.4053, -0.8390,
        -0.8871,  0.2223, -0.7037, -0.9132], device='cuda:0')
q_var = tensor([1.0001, 1.0002, 1.0002, 1.0002, 0.9999, 1.0002, 1.0000, 1.0002, 0.9999,
        1.0002, 1.0002, 1.0000, 1.0000, 0.9986, 1.0002, 0.9998, 1.0002, 1.0002,
        1.0002, 0.9989], device='cuda:0')
(D_eta_sqrt @ q).var = tensor([1.0001, 1.0002, 1.0002, 1.0002, 0.9999, 1.0002, 1.0000, 1.0002, 0.9999,
        1.0002, 1.0002, 1.0000, 1.0000, 0.9986, 1.0002, 0.9998, 1.0002, 1.0002,
        1.0002, 0.9989], device='cuda:0')
(G @ (D_eta_sqrt @ q)).var = tensor([33.8810, 32.0247, 40.1620, 36.9295, 34.9426, 34.0344, 39.6173, 35.6306,
        34.9817, 39.3348, 35.3226, 37.7992, 33.8598, 31.7651, 44.0614, 34.2881,
        32.8750, 42.6268, 35.0556, 33.1286], device='cuda:0')
signal_var = tensor([0.8410, 0.7949, 0.9969, 0.9167, 0.8674, 0.8448, 0.9834, 0.8844, 0.8683,
        0.9764, 0.8768, 0.9383, 0.8405, 0.7885, 1.0937, 0.8511, 0.8160, 1.0581,
        0.8702, 0.8223], device='cuda:0')
w_var = tensor([0.9918, 1.0002, 0.9839, 0.9887, 1.0005, 0.9990, 0.9902, 0.9798, 0.9842,
        1.0044, 0.9973, 0.9811, 1.0281, 0.9846, 0.9963, 1.0325, 1.0010, 1.0053,
        1.0232, 1.0148], device='cuda:0')
y_var = tensor([1.8384, 1.7600, 1.9799, 1.9055, 1.8521, 1.8228, 1.9800, 1.9021, 1.8609,
        1.9547, 1.8569, 1.8954, 1.8761, 1.7787, 2.0851, 1.9248, 1.8097, 2.0477,
        1.8848, 1.8470], device='cuda:0')
####cond finisihed #####
sum_betak_gammak = tensor([17.8340, 17.8340, 17.8340, 17.8340, 17.8340, 17.8340, 17.8340, 17.8340,
        17.8340, 17.8340, 17.8340, 17.8340, 17.8340, 17.8340, 17.8340, 17.8340,
        17.8340, 17.8340, 17.8340, 17.8340], device='cuda:0')
************
inv_Z_H_Z_k (shape: torch.Size([20, 32])) = tensor([[0.0254, 0.0249, 0.0350, 0.0305, 0.0355, 0.0260, 0.0333, 0.0325, 0.0259,
         0.0335, 0.0322, 0.0296, 0.0242, 0.0349, 0.0336, 0.0319, 0.0329, 0.0384,
         0.0259, 0.0245, 0.0231, 0.0236, 0.0307, 0.0303, 0.0276, 0.0310, 0.0332,
         0.0345, 0.0332, 0.0249, 0.0313, 0.0373],
        [0.0314, 0.0275, 0.0354, 0.0313, 0.0403, 0.0284, 0.0298, 0.0334, 0.0251,
         0.0265, 0.0482, 0.0278, 0.0387, 0.0313, 0.0305, 0.0272, 0.0358, 0.0247,
         0.0363, 0.0251, 0.0326, 0.0281, 0.0236, 0.0237, 0.0352, 0.0381, 0.0339,
         0.0350, 0.0248, 0.0337, 0.0381, 0.0342],
        [0.0313, 0.0354, 0.0305, 0.0275, 0.0284, 0.0282, 0.0298, 0.0308, 0.0323,
         0.0310, 0.0314, 0.0287, 0.0260, 0.0338, 0.0329, 0.0366, 0.0249, 0.0290,
         0.0354, 0.0264, 0.0244, 0.0256, 0.0298, 0.0330, 0.0353, 0.0324, 0.0358,
         0.0414, 0.0268, 0.0279, 0.0301, 0.0294],
        [0.0380, 0.0374, 0.0341, 0.0374, 0.0267, 0.0400, 0.0306, 0.0269, 0.0249,
         0.0275, 0.0281, 0.0417, 0.0303, 0.0355, 0.0257, 0.0260, 0.0298, 0.0347,
         0.0398, 0.0302, 0.0361, 0.0295, 0.0328, 0.0313, 0.0240, 0.0305, 0.0300,
         0.0331, 0.0314, 0.0326, 0.0320, 0.0350],
        [0.0236, 0.0362, 0.0309, 0.0273, 0.0334, 0.0398, 0.0347, 0.0308, 0.0277,
         0.0425, 0.0310, 0.0308, 0.0321, 0.0269, 0.0348, 0.0285, 0.0282, 0.0327,
         0.0244, 0.0217, 0.0286, 0.0276, 0.0344, 0.0304, 0.0341, 0.0320, 0.0198,
         0.0427, 0.0269, 0.0328, 0.0248, 0.0260],
        [0.0222, 0.0318, 0.0405, 0.0264, 0.0344, 0.0314, 0.0293, 0.0441, 0.0542,
         0.0413, 0.0369, 0.0364, 0.0327, 0.0370, 0.0339, 0.0357, 0.0323, 0.0391,
         0.0271, 0.0292, 0.0330, 0.0309, 0.0239, 0.0259, 0.0232, 0.0378, 0.0279,
         0.0324, 0.0375, 0.0360, 0.0310, 0.0310],
        [0.0398, 0.0330, 0.0303, 0.0242, 0.0266, 0.0287, 0.0275, 0.0276, 0.0247,
         0.0224, 0.0232, 0.0234, 0.0292, 0.0340, 0.0364, 0.0325, 0.0272, 0.0368,
         0.0293, 0.0292, 0.0310, 0.0339, 0.0256, 0.0231, 0.0395, 0.0462, 0.0265,
         0.0429, 0.0264, 0.0338, 0.0410, 0.0204],
        [0.0301, 0.0341, 0.0324, 0.0430, 0.0237, 0.0359, 0.0457, 0.0280, 0.0342,
         0.0378, 0.0300, 0.0327, 0.0306, 0.0246, 0.0236, 0.0350, 0.0309, 0.0273,
         0.0330, 0.0267, 0.0308, 0.0438, 0.0363, 0.0240, 0.0215, 0.0426, 0.0408,
         0.0554, 0.0416, 0.0338, 0.0263, 0.0355],
        [0.0290, 0.0252, 0.0238, 0.0505, 0.0242, 0.0205, 0.0248, 0.0432, 0.0306,
         0.0326, 0.0309, 0.0281, 0.0268, 0.0235, 0.0300, 0.0317, 0.0217, 0.0228,
         0.0317, 0.0269, 0.0297, 0.0440, 0.0273, 0.0319, 0.0399, 0.0405, 0.0361,
         0.0405, 0.0318, 0.0322, 0.0314, 0.0305],
        [0.0248, 0.0264, 0.0312, 0.0271, 0.0302, 0.0291, 0.0201, 0.0338, 0.0307,
         0.0456, 0.0216, 0.0227, 0.0293, 0.0338, 0.0265, 0.0366, 0.0298, 0.0241,
         0.0373, 0.0278, 0.0234, 0.0303, 0.0254, 0.0406, 0.0291, 0.0280, 0.0359,
         0.0276, 0.0379, 0.0345, 0.0288, 0.0269],
        [0.0277, 0.0340, 0.0239, 0.0335, 0.0267, 0.0311, 0.0276, 0.0464, 0.0294,
         0.0314, 0.0289, 0.0319, 0.0329, 0.0296, 0.0365, 0.0323, 0.0307, 0.0302,
         0.0313, 0.0282, 0.0284, 0.0416, 0.0295, 0.0287, 0.0315, 0.0280, 0.0413,
         0.0320, 0.0385, 0.0339, 0.0249, 0.0210],
        [0.0303, 0.0310, 0.0356, 0.0237, 0.0278, 0.0301, 0.0400, 0.0416, 0.0474,
         0.0353, 0.0339, 0.0317, 0.0333, 0.0294, 0.0302, 0.0331, 0.0326, 0.0353,
         0.0372, 0.0224, 0.0287, 0.0391, 0.0278, 0.0304, 0.0312, 0.0297, 0.0249,
         0.0318, 0.0286, 0.0306, 0.0324, 0.0329],
        [0.0240, 0.0293, 0.0302, 0.0260, 0.0336, 0.0320, 0.0250, 0.0470, 0.0267,
         0.0293, 0.0352, 0.0247, 0.0333, 0.0438, 0.0263, 0.0349, 0.0462, 0.0273,
         0.0470, 0.0304, 0.0286, 0.0264, 0.0213, 0.0269, 0.0303, 0.0300, 0.0303,
         0.0338, 0.0356, 0.0331, 0.0410, 0.0298],
        [0.0382, 0.0375, 0.0333, 0.0300, 0.0312, 0.0321, 0.0388, 0.0328, 0.0306,
         0.0371, 0.0321, 0.0334, 0.0268, 0.0288, 0.0261, 0.0320, 0.0311, 0.0239,
         0.0288, 0.0290, 0.0304, 0.0385, 0.0311, 0.0277, 0.0429, 0.0295, 0.0266,
         0.0330, 0.0348, 0.0363, 0.0268, 0.0252],
        [0.0241, 0.0272, 0.0319, 0.0275, 0.0290, 0.0284, 0.0303, 0.0342, 0.0325,
         0.0416, 0.0236, 0.0293, 0.0276, 0.0241, 0.0288, 0.0379, 0.0317, 0.0339,
         0.0375, 0.0353, 0.0350, 0.0316, 0.0318, 0.0344, 0.0288, 0.0236, 0.0312,
         0.0265, 0.0339, 0.0272, 0.0279, 0.0329],
        [0.0271, 0.0362, 0.0318, 0.0326, 0.0292, 0.0255, 0.0353, 0.0223, 0.0334,
         0.0327, 0.0245, 0.0205, 0.0218, 0.0274, 0.0265, 0.0300, 0.0341, 0.0252,
         0.0373, 0.0254, 0.0459, 0.0239, 0.0358, 0.0360, 0.0382, 0.0290, 0.0281,
         0.0299, 0.0270, 0.0208, 0.0268, 0.0363],
        [0.0315, 0.0377, 0.0227, 0.0252, 0.0305, 0.0282, 0.0265, 0.0342, 0.0279,
         0.0338, 0.0295, 0.0426, 0.0276, 0.0300, 0.0356, 0.0315, 0.0273, 0.0336,
         0.0329, 0.0231, 0.0396, 0.0321, 0.0321, 0.0267, 0.0291, 0.0207, 0.0245,
         0.0255, 0.0286, 0.0288, 0.0250, 0.0325],
        [0.0273, 0.0296, 0.0260, 0.0372, 0.0347, 0.0385, 0.0197, 0.0308, 0.0294,
         0.0262, 0.0327, 0.0278, 0.0381, 0.0425, 0.0346, 0.0249, 0.0360, 0.0272,
         0.0300, 0.0292, 0.0309, 0.0375, 0.0311, 0.0355, 0.0315, 0.0334, 0.0304,
         0.0269, 0.0315, 0.0320, 0.0371, 0.0335],
        [0.0285, 0.0294, 0.0262, 0.0311, 0.0338, 0.0280, 0.0335, 0.0253, 0.0439,
         0.0313, 0.0332, 0.0353, 0.0243, 0.0283, 0.0216, 0.0241, 0.0244, 0.0329,
         0.0274, 0.0281, 0.0296, 0.0275, 0.0366, 0.0287, 0.0278, 0.0348, 0.0312,
         0.0255, 0.0314, 0.0470, 0.0412, 0.0283],
        [0.0298, 0.0279, 0.0332, 0.0334, 0.0294, 0.0245, 0.0242, 0.0365, 0.0301,
         0.0282, 0.0323, 0.0364, 0.0257, 0.0261, 0.0307, 0.0277, 0.0250, 0.0428,
         0.0222, 0.0261, 0.0215, 0.0341, 0.0360, 0.0346, 0.0306, 0.0244, 0.0286,
         0.0277, 0.0371, 0.0289, 0.0269, 0.0495]], device='cuda:0')
inv_Z_H_Z_k.mean (expected to be = 0.03124999990234375) = 0.03119756653904915
Var (shape: torch.Size([20, 32])) = tensor([[0.0366, 0.0360, 0.0506, 0.0441, 0.0512, 0.0375, 0.0480, 0.0468, 0.0374,
         0.0484, 0.0464, 0.0427, 0.0349, 0.0503, 0.0485, 0.0461, 0.0475, 0.0554,
         0.0374, 0.0354, 0.0334, 0.0340, 0.0443, 0.0438, 0.0398, 0.0447, 0.0479,
         0.0498, 0.0479, 0.0360, 0.0452, 0.0539],
        [0.0454, 0.0397, 0.0511, 0.0451, 0.0582, 0.0410, 0.0430, 0.0482, 0.0363,
         0.0382, 0.0695, 0.0401, 0.0558, 0.0452, 0.0439, 0.0392, 0.0516, 0.0356,
         0.0523, 0.0362, 0.0470, 0.0405, 0.0341, 0.0343, 0.0507, 0.0550, 0.0489,
         0.0506, 0.0357, 0.0485, 0.0550, 0.0494],
        [0.0451, 0.0511, 0.0441, 0.0397, 0.0409, 0.0406, 0.0430, 0.0445, 0.0466,
         0.0447, 0.0452, 0.0414, 0.0375, 0.0488, 0.0475, 0.0528, 0.0360, 0.0419,
         0.0511, 0.0380, 0.0351, 0.0369, 0.0430, 0.0476, 0.0510, 0.0467, 0.0516,
         0.0598, 0.0387, 0.0402, 0.0434, 0.0424],
        [0.0548, 0.0539, 0.0492, 0.0539, 0.0386, 0.0577, 0.0441, 0.0389, 0.0359,
         0.0397, 0.0406, 0.0602, 0.0437, 0.0511, 0.0371, 0.0376, 0.0430, 0.0500,
         0.0574, 0.0435, 0.0521, 0.0425, 0.0474, 0.0452, 0.0346, 0.0441, 0.0433,
         0.0477, 0.0453, 0.0471, 0.0461, 0.0505],
        [0.0341, 0.0523, 0.0446, 0.0394, 0.0482, 0.0574, 0.0501, 0.0444, 0.0399,
         0.0613, 0.0447, 0.0445, 0.0462, 0.0388, 0.0502, 0.0411, 0.0407, 0.0472,
         0.0352, 0.0314, 0.0412, 0.0399, 0.0496, 0.0438, 0.0491, 0.0462, 0.0286,
         0.0616, 0.0388, 0.0474, 0.0358, 0.0375],
        [0.0320, 0.0459, 0.0585, 0.0381, 0.0497, 0.0453, 0.0423, 0.0637, 0.0782,
         0.0596, 0.0533, 0.0525, 0.0472, 0.0533, 0.0490, 0.0515, 0.0466, 0.0564,
         0.0391, 0.0421, 0.0476, 0.0445, 0.0345, 0.0374, 0.0335, 0.0546, 0.0402,
         0.0467, 0.0540, 0.0519, 0.0447, 0.0447],
        [0.0574, 0.0477, 0.0438, 0.0349, 0.0384, 0.0414, 0.0397, 0.0398, 0.0356,
         0.0323, 0.0335, 0.0338, 0.0421, 0.0490, 0.0525, 0.0469, 0.0392, 0.0531,
         0.0423, 0.0421, 0.0447, 0.0489, 0.0370, 0.0334, 0.0569, 0.0666, 0.0382,
         0.0620, 0.0381, 0.0488, 0.0592, 0.0295],
        [0.0434, 0.0492, 0.0467, 0.0620, 0.0341, 0.0517, 0.0659, 0.0404, 0.0494,
         0.0545, 0.0433, 0.0472, 0.0441, 0.0355, 0.0340, 0.0504, 0.0446, 0.0393,
         0.0476, 0.0385, 0.0445, 0.0632, 0.0524, 0.0347, 0.0311, 0.0615, 0.0588,
         0.0799, 0.0601, 0.0487, 0.0379, 0.0513],
        [0.0419, 0.0364, 0.0343, 0.0728, 0.0349, 0.0296, 0.0358, 0.0623, 0.0441,
         0.0470, 0.0446, 0.0406, 0.0387, 0.0339, 0.0433, 0.0457, 0.0314, 0.0330,
         0.0457, 0.0388, 0.0429, 0.0635, 0.0394, 0.0461, 0.0575, 0.0584, 0.0521,
         0.0584, 0.0458, 0.0465, 0.0453, 0.0440],
        [0.0358, 0.0382, 0.0451, 0.0391, 0.0436, 0.0420, 0.0290, 0.0488, 0.0443,
         0.0658, 0.0312, 0.0328, 0.0422, 0.0488, 0.0382, 0.0528, 0.0430, 0.0348,
         0.0538, 0.0401, 0.0338, 0.0437, 0.0366, 0.0585, 0.0420, 0.0404, 0.0517,
         0.0398, 0.0547, 0.0497, 0.0415, 0.0388],
        [0.0400, 0.0490, 0.0345, 0.0484, 0.0385, 0.0448, 0.0398, 0.0669, 0.0424,
         0.0453, 0.0417, 0.0460, 0.0474, 0.0428, 0.0527, 0.0467, 0.0443, 0.0435,
         0.0451, 0.0407, 0.0409, 0.0600, 0.0426, 0.0414, 0.0454, 0.0404, 0.0596,
         0.0461, 0.0555, 0.0489, 0.0360, 0.0304],
        [0.0438, 0.0448, 0.0513, 0.0342, 0.0401, 0.0434, 0.0578, 0.0600, 0.0684,
         0.0509, 0.0489, 0.0457, 0.0481, 0.0424, 0.0436, 0.0477, 0.0471, 0.0509,
         0.0537, 0.0323, 0.0414, 0.0564, 0.0402, 0.0439, 0.0450, 0.0429, 0.0360,
         0.0459, 0.0412, 0.0442, 0.0467, 0.0475],
        [0.0346, 0.0423, 0.0436, 0.0375, 0.0485, 0.0462, 0.0361, 0.0677, 0.0386,
         0.0423, 0.0507, 0.0357, 0.0480, 0.0632, 0.0379, 0.0503, 0.0666, 0.0394,
         0.0678, 0.0438, 0.0413, 0.0380, 0.0308, 0.0389, 0.0438, 0.0433, 0.0438,
         0.0487, 0.0513, 0.0478, 0.0591, 0.0430],
        [0.0552, 0.0541, 0.0480, 0.0433, 0.0451, 0.0464, 0.0560, 0.0473, 0.0441,
         0.0536, 0.0463, 0.0482, 0.0386, 0.0415, 0.0377, 0.0462, 0.0449, 0.0345,
         0.0415, 0.0418, 0.0439, 0.0556, 0.0449, 0.0399, 0.0618, 0.0426, 0.0383,
         0.0476, 0.0502, 0.0523, 0.0386, 0.0364],
        [0.0348, 0.0392, 0.0460, 0.0396, 0.0419, 0.0410, 0.0437, 0.0494, 0.0469,
         0.0601, 0.0341, 0.0423, 0.0399, 0.0348, 0.0415, 0.0547, 0.0457, 0.0490,
         0.0540, 0.0509, 0.0505, 0.0456, 0.0458, 0.0496, 0.0416, 0.0341, 0.0450,
         0.0382, 0.0489, 0.0392, 0.0403, 0.0475],
        [0.0390, 0.0522, 0.0459, 0.0470, 0.0421, 0.0368, 0.0509, 0.0321, 0.0481,
         0.0471, 0.0353, 0.0295, 0.0314, 0.0395, 0.0382, 0.0432, 0.0491, 0.0363,
         0.0538, 0.0366, 0.0662, 0.0344, 0.0516, 0.0519, 0.0551, 0.0419, 0.0406,
         0.0431, 0.0390, 0.0300, 0.0387, 0.0524],
        [0.0454, 0.0543, 0.0327, 0.0363, 0.0440, 0.0407, 0.0383, 0.0494, 0.0402,
         0.0488, 0.0426, 0.0614, 0.0399, 0.0433, 0.0514, 0.0454, 0.0394, 0.0485,
         0.0475, 0.0333, 0.0572, 0.0463, 0.0463, 0.0385, 0.0420, 0.0298, 0.0354,
         0.0368, 0.0413, 0.0416, 0.0361, 0.0468],
        [0.0393, 0.0427, 0.0375, 0.0536, 0.0501, 0.0555, 0.0285, 0.0445, 0.0425,
         0.0378, 0.0471, 0.0401, 0.0550, 0.0613, 0.0499, 0.0359, 0.0519, 0.0392,
         0.0433, 0.0422, 0.0446, 0.0541, 0.0448, 0.0512, 0.0455, 0.0481, 0.0438,
         0.0388, 0.0454, 0.0461, 0.0535, 0.0484],
        [0.0411, 0.0424, 0.0378, 0.0449, 0.0488, 0.0404, 0.0484, 0.0365, 0.0633,
         0.0452, 0.0480, 0.0509, 0.0351, 0.0408, 0.0312, 0.0347, 0.0351, 0.0475,
         0.0395, 0.0406, 0.0427, 0.0397, 0.0528, 0.0414, 0.0401, 0.0502, 0.0450,
         0.0367, 0.0454, 0.0678, 0.0594, 0.0408],
        [0.0430, 0.0402, 0.0479, 0.0482, 0.0424, 0.0353, 0.0350, 0.0526, 0.0435,
         0.0406, 0.0466, 0.0525, 0.0370, 0.0377, 0.0442, 0.0399, 0.0361, 0.0618,
         0.0321, 0.0377, 0.0311, 0.0492, 0.0520, 0.0500, 0.0441, 0.0353, 0.0413,
         0.0400, 0.0535, 0.0417, 0.0388, 0.0714]], device='cuda:0')
***********
SINR = tensor([-5.9150, -6.0703, -5.9877, -6.1431, -5.9043, -6.2558, -5.8485, -6.2252,
        -5.9085, -5.7951, -6.0372, -6.1585, -6.0455, -6.1190, -5.9633, -5.7744,
        -5.8299, -6.0863, -5.9156, -5.8646], device='cuda:0')
Real_SINR = tensor([-6.0902, -6.2146, -6.7300, -6.9097, -6.0190, -6.5034, -6.1850, -6.2975,
        -6.4953, -6.2581, -6.0328, -6.0846, -6.3972, -6.2033, -6.5221, -5.9899,
        -6.2021, -6.6324, -6.1321, -6.1927], device='cuda:0')
Real_SINR_noise.shape = torch.Size([20])
ldm/modules/diffusionmodules/util.py, make_ddim_timsteps ddim_discr_method = uniform
ldm/modules/diffusionmodules/util.py, make_ddim_timsteps, Selected timesteps for ddim sampler: (200,)
ldm/modules/diffusionmodules/util.py, make_ddim_sampling_parameters, Selected alphas for ddim sampler: a_t: torch.Size([200]); a_(t-1): (200,)
For the chosen value of eta, which is 0.0, this results in the following sigma_t schedule for ddim sampler tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], dtype=torch.float64)
ddim.py alphas_cumprod = torch.Size([1000])
ddim.py, alpha_bar_u = tensor([0.2039, 0.1982, 0.2012, 0.1955, 0.2043, 0.1915, 0.2064, 0.1926, 0.2042,
        0.2084, 0.1994, 0.1950, 0.1991, 0.1964, 0.2021, 0.2092, 0.2071, 0.1976,
        0.2039, 0.2058], device='cuda:0')
ddim.py start_timesteps after clamp S = 200 : tensor([559, 564, 562, 567, 559, 571, 557, 570, 559, 555, 563, 567, 564, 566,
        561, 555, 556, 565, 559, 558], device='cuda:0')
d = torch.Size([20, 4, 32, 32])
recoverd_img = torch.Size([20, 3, 256, 256])
20 images are saved in outputs/MIMOdiffusion/M=64/K=32/dynamic/
20 images are saved in outputs/MIMOdiffusion/M=64/K=32/nonoisenosample/
--------SNR = 0,  rho_ul = 0.03125-----------
G_variance = tensor([1.0208, 1.0129, 0.9652, 1.0127, 1.0005, 1.0118, 0.9642, 0.9709, 0.9704,
        1.0530, 1.0006, 0.9806, 1.0206, 1.0273, 1.0102, 0.9655, 1.0027, 1.0037,
        1.0018, 0.9721], device='cuda:0')
G_hat_variance = tensor([0.5172, 0.4963, 0.4968, 0.5246, 0.5026, 0.5111, 0.5129, 0.4948, 0.4900,
        0.5240, 0.5011, 0.4902, 0.5093, 0.4992, 0.4794, 0.4892, 0.5024, 0.4980,
        0.5094, 0.4862], device='cuda:0')
G_tilde_var = tensor([0.5279, 0.4945, 0.4626, 0.5138, 0.4813, 0.4994, 0.4870, 0.4929, 0.4785,
        0.5179, 0.5035, 0.4927, 0.5004, 0.5149, 0.5046, 0.5014, 0.5023, 0.5036,
        0.5122, 0.5145], device='cuda:0')
gamma = tensor([[[0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
          0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
          0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
          0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000]]],
       device='cuda:0')
Z_mean = tensor([-0.0101-0.0236j, -0.0288+0.0028j, -0.0215+0.0092j, -0.0018-0.0105j,
         0.0031+0.0193j, -0.0015-0.0055j,  0.0291-0.0090j, -0.0143+0.0182j,
        -0.0074-0.0068j, -0.0164+0.0114j, -0.0066+0.0085j,  0.0396-0.0022j,
         0.0159-0.0230j, -0.0034+0.0122j, -0.0208+0.0191j, -0.0164-0.0050j,
        -0.0152+0.0115j,  0.0220-0.0151j,  0.0033-0.0126j, -0.0025+0.0287j],
       device='cuda:0')
Z_variance ~CN(0, 1)= tensor([1.0343, 0.9927, 0.9936, 1.0491, 1.0053, 1.0222, 1.0258, 0.9896, 0.9800,
        1.0481, 1.0022, 0.9805, 1.0187, 0.9984, 0.9588, 0.9784, 1.0048, 0.9960,
        1.0188, 0.9723], device='cuda:0')
Real_SNR = tensor([6.2947e-01, 4.5048e-01, 1.1597e+00, 3.1453e-01, 3.9374e-01, 4.7462e-01,
        5.1199e-02, 1.0877e+00, 9.3606e-02, 9.6348e-01, 3.8802e-01, 5.1928e-01,
        8.8916e-01, 5.9437e-01, 1.0260e+00, 4.6020e-01, 8.1430e-04, 5.5928e-01,
        6.4146e-01, 3.8581e-01], device='cuda:0')
q_var = tensor([1.0001, 1.0002, 1.0002, 1.0002, 0.9999, 1.0002, 1.0000, 1.0002, 0.9999,
        1.0002, 1.0002, 1.0000, 1.0000, 0.9986, 1.0002, 0.9998, 1.0002, 1.0002,
        1.0002, 0.9989], device='cuda:0')
(D_eta_sqrt @ q).var = tensor([1.0001, 1.0002, 1.0002, 1.0002, 0.9999, 1.0002, 1.0000, 1.0002, 0.9999,
        1.0002, 1.0002, 1.0000, 1.0000, 0.9986, 1.0002, 0.9998, 1.0002, 1.0002,
        1.0002, 0.9989], device='cuda:0')
(G @ (D_eta_sqrt @ q)).var = tensor([36.8640, 36.1725, 42.3012, 33.8564, 35.3307, 35.9598, 32.4438, 41.1503,
        32.1876, 39.5877, 33.9607, 35.5634, 38.1881, 37.1431, 40.8016, 35.5422,
        32.0837, 36.4440, 36.8935, 34.2531], device='cuda:0')
signal_var = tensor([1.1520, 1.1304, 1.3219, 1.0580, 1.1041, 1.1237, 1.0139, 1.2859, 1.0059,
        1.2371, 1.0613, 1.1114, 1.1934, 1.1607, 1.2750, 1.1107, 1.0026, 1.1389,
        1.1529, 1.0704], device='cuda:0')
w_var = tensor([0.9966, 1.0190, 1.0121, 0.9841, 1.0084, 1.0074, 1.0020, 1.0010, 0.9844,
        0.9910, 0.9706, 0.9861, 0.9724, 1.0123, 1.0068, 0.9990, 1.0024, 1.0013,
        0.9946, 0.9794], device='cuda:0')
y_var = tensor([2.1393, 2.1548, 2.3323, 2.0208, 2.1078, 2.0734, 2.0415, 2.2505, 2.0014,
        2.2324, 2.0724, 2.0774, 2.1589, 2.1069, 2.2633, 2.1393, 2.0098, 2.1038,
        2.1694, 2.0592], device='cuda:0')
####cond finisihed #####
sum_betak_gammak = tensor([16., 16., 16., 16., 16., 16., 16., 16., 16., 16., 16., 16., 16., 16.,
        16., 16., 16., 16., 16., 16.], device='cuda:0')
************
inv_Z_H_Z_k (shape: torch.Size([20, 32])) = tensor([[0.0293, 0.0273, 0.0347, 0.0427, 0.0311, 0.0414, 0.0333, 0.0282, 0.0309,
         0.0296, 0.0315, 0.0392, 0.0376, 0.0354, 0.0277, 0.0322, 0.0278, 0.0337,
         0.0457, 0.0310, 0.0302, 0.0311, 0.0385, 0.0302, 0.0239, 0.0272, 0.0315,
         0.0366, 0.0253, 0.0349, 0.0250, 0.0312],
        [0.0261, 0.0320, 0.0279, 0.0235, 0.0275, 0.0259, 0.0275, 0.0356, 0.0314,
         0.0274, 0.0248, 0.0363, 0.0310, 0.0266, 0.0227, 0.0274, 0.0249, 0.0280,
         0.0302, 0.0278, 0.0409, 0.0367, 0.0360, 0.0380, 0.0374, 0.0309, 0.0422,
         0.0339, 0.0357, 0.0266, 0.0258, 0.0325],
        [0.0293, 0.0350, 0.0353, 0.0342, 0.0281, 0.0400, 0.0324, 0.0208, 0.0310,
         0.0324, 0.0257, 0.0350, 0.0222, 0.0303, 0.0372, 0.0414, 0.0273, 0.0318,
         0.0286, 0.0328, 0.0328, 0.0366, 0.0452, 0.0204, 0.0204, 0.0431, 0.0445,
         0.0337, 0.0216, 0.0421, 0.0391, 0.0227],
        [0.0321, 0.0371, 0.0366, 0.0210, 0.0265, 0.0274, 0.0282, 0.0270, 0.0319,
         0.0332, 0.0278, 0.0250, 0.0256, 0.0286, 0.0294, 0.0341, 0.0318, 0.0278,
         0.0246, 0.0330, 0.0220, 0.0317, 0.0390, 0.0383, 0.0366, 0.0360, 0.0333,
         0.0358, 0.0273, 0.0256, 0.0329, 0.0325],
        [0.0296, 0.0312, 0.0239, 0.0275, 0.0360, 0.0376, 0.0367, 0.0227, 0.0286,
         0.0216, 0.0308, 0.0245, 0.0277, 0.0302, 0.0314, 0.0294, 0.0338, 0.0294,
         0.0280, 0.0359, 0.0287, 0.0283, 0.0406, 0.0307, 0.0394, 0.0234, 0.0332,
         0.0281, 0.0310, 0.0446, 0.0258, 0.0326],
        [0.0417, 0.0265, 0.0257, 0.0541, 0.0325, 0.0330, 0.0419, 0.0362, 0.0314,
         0.0285, 0.0392, 0.0305, 0.0335, 0.0265, 0.0332, 0.0359, 0.0445, 0.0289,
         0.0449, 0.0341, 0.0327, 0.0278, 0.0316, 0.0274, 0.0256, 0.0354, 0.0373,
         0.0316, 0.0295, 0.0402, 0.0298, 0.0270],
        [0.0356, 0.0298, 0.0422, 0.0210, 0.0218, 0.0240, 0.0274, 0.0237, 0.0208,
         0.0240, 0.0339, 0.0258, 0.0290, 0.0300, 0.0276, 0.0262, 0.0223, 0.0335,
         0.0406, 0.0220, 0.0330, 0.0290, 0.0282, 0.0327, 0.0278, 0.0263, 0.0195,
         0.0258, 0.0301, 0.0274, 0.0274, 0.0292],
        [0.0256, 0.0352, 0.0301, 0.0434, 0.0462, 0.0366, 0.0268, 0.0311, 0.0408,
         0.0364, 0.0290, 0.0285, 0.0211, 0.0342, 0.0285, 0.0271, 0.0217, 0.0341,
         0.0274, 0.0327, 0.0288, 0.0350, 0.0394, 0.0271, 0.0266, 0.0283, 0.0335,
         0.0265, 0.0314, 0.0301, 0.0283, 0.0370],
        [0.0271, 0.0284, 0.0255, 0.0316, 0.0356, 0.0203, 0.0326, 0.0335, 0.0287,
         0.0269, 0.0251, 0.0236, 0.0327, 0.0252, 0.0257, 0.0388, 0.0445, 0.0268,
         0.0219, 0.0427, 0.0247, 0.0462, 0.0273, 0.0292, 0.0325, 0.0274, 0.0406,
         0.0274, 0.0277, 0.0353, 0.0305, 0.0293],
        [0.0403, 0.0350, 0.0343, 0.0299, 0.0248, 0.0356, 0.0302, 0.0283, 0.0308,
         0.0268, 0.0364, 0.0298, 0.0255, 0.0286, 0.0304, 0.0428, 0.0404, 0.0334,
         0.0239, 0.0294, 0.0403, 0.0379, 0.0320, 0.0475, 0.0470, 0.0356, 0.0303,
         0.0240, 0.0260, 0.0222, 0.0250, 0.0306],
        [0.0368, 0.0335, 0.0389, 0.0255, 0.0345, 0.0375, 0.0397, 0.0254, 0.0224,
         0.0350, 0.0250, 0.0295, 0.0246, 0.0412, 0.0303, 0.0270, 0.0421, 0.0377,
         0.0257, 0.0379, 0.0329, 0.0246, 0.0245, 0.0306, 0.0294, 0.0395, 0.0368,
         0.0285, 0.0318, 0.0375, 0.0274, 0.0331],
        [0.0348, 0.0327, 0.0351, 0.0258, 0.0338, 0.0403, 0.0275, 0.0261, 0.0403,
         0.0297, 0.0253, 0.0347, 0.0316, 0.0342, 0.0277, 0.0287, 0.0287, 0.0308,
         0.0198, 0.0384, 0.0294, 0.0315, 0.0269, 0.0281, 0.0300, 0.0349, 0.0298,
         0.0308, 0.0330, 0.0243, 0.0369, 0.0278],
        [0.0254, 0.0257, 0.0323, 0.0418, 0.0321, 0.0313, 0.0303, 0.0413, 0.0286,
         0.0349, 0.0350, 0.0270, 0.0379, 0.0266, 0.0374, 0.0370, 0.0206, 0.0346,
         0.0289, 0.0275, 0.0380, 0.0373, 0.0287, 0.0410, 0.0240, 0.0285, 0.0281,
         0.0288, 0.0300, 0.0342, 0.0264, 0.0307],
        [0.0274, 0.0243, 0.0304, 0.0262, 0.0349, 0.0380, 0.0260, 0.0295, 0.0224,
         0.0271, 0.0295, 0.0296, 0.0272, 0.0293, 0.0333, 0.0283, 0.0241, 0.0404,
         0.0292, 0.0371, 0.0377, 0.0257, 0.0352, 0.0312, 0.0280, 0.0490, 0.0316,
         0.0307, 0.0304, 0.0295, 0.0315, 0.0292],
        [0.0274, 0.0486, 0.0301, 0.0281, 0.0242, 0.0273, 0.0324, 0.0313, 0.0277,
         0.0199, 0.0340, 0.0321, 0.0328, 0.0253, 0.0333, 0.0376, 0.0339, 0.0332,
         0.0323, 0.0352, 0.0394, 0.0324, 0.0234, 0.0297, 0.0309, 0.0309, 0.0253,
         0.0214, 0.0283, 0.0349, 0.0391, 0.0338],
        [0.0269, 0.0326, 0.0286, 0.0321, 0.0300, 0.0243, 0.0230, 0.0305, 0.0311,
         0.0297, 0.0244, 0.0249, 0.0302, 0.0288, 0.0312, 0.0340, 0.0337, 0.0265,
         0.0379, 0.0289, 0.0271, 0.0249, 0.0323, 0.0352, 0.0366, 0.0492, 0.0305,
         0.0386, 0.0282, 0.0386, 0.0436, 0.0310],
        [0.0306, 0.0275, 0.0468, 0.0525, 0.0335, 0.0278, 0.0444, 0.0331, 0.0298,
         0.0300, 0.0238, 0.0380, 0.0335, 0.0251, 0.0302, 0.0341, 0.0313, 0.0351,
         0.0232, 0.0328, 0.0298, 0.0317, 0.0349, 0.0346, 0.0293, 0.0327, 0.0294,
         0.0268, 0.0237, 0.0317, 0.0307, 0.0245],
        [0.0330, 0.0432, 0.0318, 0.0252, 0.0292, 0.0325, 0.0295, 0.0253, 0.0312,
         0.0282, 0.0296, 0.0378, 0.0341, 0.0353, 0.0280, 0.0297, 0.0286, 0.0358,
         0.0197, 0.0316, 0.0341, 0.0410, 0.0283, 0.0254, 0.0378, 0.0335, 0.0346,
         0.0375, 0.0307, 0.0336, 0.0380, 0.0324],
        [0.0220, 0.0294, 0.0225, 0.0308, 0.0313, 0.0235, 0.0268, 0.0202, 0.0197,
         0.0284, 0.0366, 0.0239, 0.0349, 0.0276, 0.0326, 0.0283, 0.0300, 0.0242,
         0.0272, 0.0250, 0.0359, 0.0368, 0.0413, 0.0333, 0.0305, 0.0215, 0.0261,
         0.0263, 0.0279, 0.0273, 0.0271, 0.0292],
        [0.0329, 0.0345, 0.0364, 0.0286, 0.0296, 0.0358, 0.0259, 0.0319, 0.0348,
         0.0303, 0.0297, 0.0283, 0.0322, 0.0362, 0.0259, 0.0368, 0.0337, 0.0291,
         0.0275, 0.0255, 0.0443, 0.0249, 0.0290, 0.0318, 0.0322, 0.0286, 0.0290,
         0.0457, 0.0341, 0.0266, 0.0265, 0.0379]], device='cuda:0')
inv_Z_H_Z_k.mean (expected to be = 0.03124999990234375) = 0.03124144673347473
Var (shape: torch.Size([20, 32])) = tensor([[0.0439, 0.0410, 0.0521, 0.0641, 0.0467, 0.0621, 0.0500, 0.0423, 0.0464,
         0.0444, 0.0472, 0.0589, 0.0563, 0.0530, 0.0415, 0.0483, 0.0416, 0.0505,
         0.0686, 0.0465, 0.0453, 0.0467, 0.0578, 0.0453, 0.0358, 0.0408, 0.0472,
         0.0549, 0.0379, 0.0523, 0.0375, 0.0468],
        [0.0391, 0.0480, 0.0418, 0.0353, 0.0412, 0.0389, 0.0413, 0.0534, 0.0472,
         0.0411, 0.0372, 0.0544, 0.0465, 0.0400, 0.0341, 0.0411, 0.0373, 0.0421,
         0.0453, 0.0417, 0.0613, 0.0551, 0.0541, 0.0571, 0.0562, 0.0463, 0.0633,
         0.0508, 0.0536, 0.0399, 0.0387, 0.0488],
        [0.0440, 0.0525, 0.0529, 0.0514, 0.0421, 0.0600, 0.0486, 0.0312, 0.0466,
         0.0486, 0.0386, 0.0524, 0.0333, 0.0455, 0.0558, 0.0620, 0.0410, 0.0477,
         0.0428, 0.0493, 0.0492, 0.0549, 0.0679, 0.0306, 0.0305, 0.0646, 0.0668,
         0.0506, 0.0324, 0.0632, 0.0587, 0.0340],
        [0.0481, 0.0557, 0.0549, 0.0315, 0.0398, 0.0411, 0.0422, 0.0405, 0.0478,
         0.0498, 0.0416, 0.0374, 0.0385, 0.0429, 0.0441, 0.0512, 0.0478, 0.0417,
         0.0368, 0.0496, 0.0330, 0.0476, 0.0584, 0.0574, 0.0549, 0.0540, 0.0499,
         0.0537, 0.0409, 0.0385, 0.0494, 0.0487],
        [0.0444, 0.0468, 0.0358, 0.0413, 0.0540, 0.0564, 0.0551, 0.0340, 0.0429,
         0.0325, 0.0462, 0.0368, 0.0415, 0.0453, 0.0471, 0.0440, 0.0508, 0.0442,
         0.0420, 0.0538, 0.0430, 0.0424, 0.0609, 0.0460, 0.0591, 0.0351, 0.0498,
         0.0421, 0.0465, 0.0669, 0.0387, 0.0490],
        [0.0625, 0.0397, 0.0385, 0.0811, 0.0487, 0.0495, 0.0628, 0.0542, 0.0471,
         0.0427, 0.0587, 0.0457, 0.0502, 0.0397, 0.0498, 0.0538, 0.0668, 0.0434,
         0.0674, 0.0512, 0.0490, 0.0418, 0.0474, 0.0411, 0.0384, 0.0532, 0.0559,
         0.0474, 0.0443, 0.0604, 0.0448, 0.0405],
        [0.0533, 0.0447, 0.0633, 0.0315, 0.0326, 0.0361, 0.0411, 0.0355, 0.0311,
         0.0360, 0.0508, 0.0387, 0.0435, 0.0451, 0.0414, 0.0392, 0.0335, 0.0503,
         0.0609, 0.0331, 0.0494, 0.0435, 0.0423, 0.0491, 0.0417, 0.0395, 0.0293,
         0.0387, 0.0451, 0.0410, 0.0412, 0.0437],
        [0.0384, 0.0529, 0.0452, 0.0652, 0.0693, 0.0549, 0.0401, 0.0467, 0.0612,
         0.0547, 0.0435, 0.0427, 0.0317, 0.0513, 0.0428, 0.0406, 0.0326, 0.0512,
         0.0410, 0.0490, 0.0432, 0.0525, 0.0592, 0.0407, 0.0399, 0.0424, 0.0503,
         0.0397, 0.0470, 0.0451, 0.0424, 0.0555],
        [0.0406, 0.0425, 0.0382, 0.0474, 0.0534, 0.0304, 0.0489, 0.0502, 0.0431,
         0.0404, 0.0377, 0.0353, 0.0490, 0.0378, 0.0386, 0.0583, 0.0668, 0.0402,
         0.0329, 0.0640, 0.0371, 0.0692, 0.0410, 0.0438, 0.0488, 0.0411, 0.0609,
         0.0410, 0.0416, 0.0530, 0.0457, 0.0439],
        [0.0604, 0.0524, 0.0514, 0.0449, 0.0372, 0.0534, 0.0452, 0.0425, 0.0462,
         0.0402, 0.0545, 0.0446, 0.0383, 0.0429, 0.0456, 0.0643, 0.0606, 0.0502,
         0.0359, 0.0441, 0.0605, 0.0568, 0.0480, 0.0712, 0.0705, 0.0534, 0.0455,
         0.0359, 0.0390, 0.0333, 0.0376, 0.0459],
        [0.0552, 0.0502, 0.0584, 0.0383, 0.0518, 0.0562, 0.0596, 0.0382, 0.0336,
         0.0525, 0.0375, 0.0443, 0.0369, 0.0618, 0.0454, 0.0405, 0.0631, 0.0565,
         0.0386, 0.0569, 0.0494, 0.0370, 0.0367, 0.0459, 0.0441, 0.0593, 0.0552,
         0.0427, 0.0476, 0.0563, 0.0411, 0.0497],
        [0.0522, 0.0491, 0.0527, 0.0388, 0.0507, 0.0605, 0.0413, 0.0392, 0.0604,
         0.0445, 0.0379, 0.0521, 0.0474, 0.0513, 0.0415, 0.0431, 0.0431, 0.0462,
         0.0297, 0.0576, 0.0441, 0.0472, 0.0403, 0.0422, 0.0450, 0.0524, 0.0448,
         0.0463, 0.0495, 0.0364, 0.0553, 0.0417],
        [0.0381, 0.0386, 0.0484, 0.0627, 0.0481, 0.0469, 0.0454, 0.0619, 0.0429,
         0.0523, 0.0526, 0.0404, 0.0568, 0.0399, 0.0561, 0.0555, 0.0309, 0.0519,
         0.0434, 0.0412, 0.0569, 0.0559, 0.0430, 0.0616, 0.0361, 0.0427, 0.0421,
         0.0431, 0.0449, 0.0513, 0.0396, 0.0460],
        [0.0411, 0.0364, 0.0455, 0.0393, 0.0524, 0.0571, 0.0390, 0.0442, 0.0336,
         0.0406, 0.0443, 0.0443, 0.0409, 0.0439, 0.0499, 0.0425, 0.0361, 0.0606,
         0.0439, 0.0557, 0.0566, 0.0385, 0.0528, 0.0469, 0.0420, 0.0736, 0.0474,
         0.0461, 0.0456, 0.0443, 0.0472, 0.0438],
        [0.0410, 0.0729, 0.0452, 0.0422, 0.0363, 0.0410, 0.0486, 0.0470, 0.0416,
         0.0298, 0.0511, 0.0481, 0.0492, 0.0380, 0.0499, 0.0564, 0.0508, 0.0498,
         0.0484, 0.0528, 0.0590, 0.0487, 0.0351, 0.0446, 0.0464, 0.0463, 0.0380,
         0.0321, 0.0424, 0.0524, 0.0586, 0.0508],
        [0.0403, 0.0489, 0.0429, 0.0482, 0.0450, 0.0365, 0.0345, 0.0458, 0.0467,
         0.0446, 0.0366, 0.0374, 0.0453, 0.0431, 0.0467, 0.0511, 0.0506, 0.0398,
         0.0568, 0.0434, 0.0407, 0.0373, 0.0485, 0.0528, 0.0548, 0.0737, 0.0457,
         0.0579, 0.0423, 0.0578, 0.0655, 0.0465],
        [0.0458, 0.0413, 0.0702, 0.0788, 0.0503, 0.0417, 0.0666, 0.0497, 0.0447,
         0.0450, 0.0357, 0.0570, 0.0502, 0.0377, 0.0453, 0.0512, 0.0470, 0.0527,
         0.0348, 0.0493, 0.0448, 0.0476, 0.0523, 0.0519, 0.0440, 0.0490, 0.0441,
         0.0402, 0.0355, 0.0475, 0.0460, 0.0368],
        [0.0495, 0.0648, 0.0478, 0.0379, 0.0439, 0.0487, 0.0442, 0.0379, 0.0468,
         0.0423, 0.0443, 0.0567, 0.0511, 0.0530, 0.0421, 0.0445, 0.0428, 0.0537,
         0.0295, 0.0473, 0.0512, 0.0615, 0.0425, 0.0380, 0.0567, 0.0503, 0.0519,
         0.0563, 0.0461, 0.0505, 0.0570, 0.0486],
        [0.0330, 0.0440, 0.0338, 0.0462, 0.0470, 0.0352, 0.0402, 0.0303, 0.0296,
         0.0427, 0.0550, 0.0359, 0.0524, 0.0414, 0.0488, 0.0424, 0.0450, 0.0362,
         0.0409, 0.0374, 0.0538, 0.0552, 0.0619, 0.0499, 0.0458, 0.0322, 0.0392,
         0.0394, 0.0419, 0.0410, 0.0407, 0.0439],
        [0.0493, 0.0518, 0.0547, 0.0429, 0.0444, 0.0538, 0.0388, 0.0479, 0.0522,
         0.0455, 0.0445, 0.0425, 0.0483, 0.0544, 0.0389, 0.0551, 0.0506, 0.0437,
         0.0412, 0.0382, 0.0664, 0.0373, 0.0436, 0.0476, 0.0483, 0.0428, 0.0435,
         0.0685, 0.0512, 0.0399, 0.0397, 0.0568]], device='cuda:0')
***********
SINR = tensor([-4.8211, -4.5728, -4.6783, -4.5737, -4.5729, -4.9577, -4.1563, -4.6693,
        -4.4927, -4.7529, -4.7441, -4.6255, -4.6971, -4.5875, -4.6136, -4.6675,
        -4.7248, -4.7750, -4.2155, -4.7437], device='cuda:0')
Real_SINR = tensor([-5.3931, -4.5739, -5.3991, -4.8316, -5.0028, -5.0845, -5.0518, -4.8597,
        -4.5068, -4.6857, -4.7841, -4.4273, -4.8073, -5.0841, -5.2645, -5.0448,
        -4.6544, -4.8316, -4.3206, -5.0803], device='cuda:0')
Real_SINR_noise.shape = torch.Size([20])
ldm/modules/diffusionmodules/util.py, make_ddim_timsteps ddim_discr_method = uniform
ldm/modules/diffusionmodules/util.py, make_ddim_timsteps, Selected timesteps for ddim sampler: (200,)
ldm/modules/diffusionmodules/util.py, make_ddim_sampling_parameters, Selected alphas for ddim sampler: a_t: torch.Size([200]); a_(t-1): (200,)
For the chosen value of eta, which is 0.0, this results in the following sigma_t schedule for ddim sampler tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], dtype=torch.float64)
ddim.py alphas_cumprod = torch.Size([1000])
ddim.py, alpha_bar_u = tensor([0.2479, 0.2587, 0.2540, 0.2586, 0.2587, 0.2420, 0.2775, 0.2544, 0.2622,
        0.2508, 0.2512, 0.2563, 0.2532, 0.2580, 0.2569, 0.2545, 0.2520, 0.2498,
        0.2748, 0.2512], device='cuda:0')
ddim.py start_timesteps after clamp S = 200 : tensor([522, 514, 518, 514, 514, 527, 500, 517, 511, 520, 520, 516, 518, 514,
        515, 517, 519, 521, 502, 520], device='cuda:0')
d = torch.Size([20, 4, 32, 32])
recoverd_img = torch.Size([20, 3, 256, 256])
20 images are saved in outputs/MIMOdiffusion/M=64/K=32/dynamic/
20 images are saved in outputs/MIMOdiffusion/M=64/K=32/nonoisenosample/
--------SNR = 1,  rho_ul = 0.03934141911856773-----------
G_variance = tensor([0.9745, 0.9953, 1.0084, 0.9960, 1.0248, 0.9978, 0.9950, 0.9697, 1.0231,
        1.0149, 1.0033, 0.9991, 1.0356, 1.0250, 0.9707, 1.0048, 0.9656, 0.9673,
        1.0242, 1.0202], device='cuda:0')
G_hat_variance = tensor([0.5402, 0.5497, 0.5466, 0.5555, 0.5859, 0.5489, 0.5595, 0.5344, 0.5809,
        0.5459, 0.5608, 0.5659, 0.5788, 0.5709, 0.5416, 0.5613, 0.5339, 0.5425,
        0.5666, 0.5484], device='cuda:0')
G_tilde_var = tensor([0.4463, 0.4575, 0.4482, 0.4387, 0.4509, 0.4509, 0.4377, 0.4362, 0.4477,
        0.4336, 0.4343, 0.4409, 0.4540, 0.4500, 0.4444, 0.4434, 0.4370, 0.4257,
        0.4543, 0.4348], device='cuda:0')
gamma = tensor([[[0.5573, 0.5573, 0.5573, 0.5573, 0.5573, 0.5573, 0.5573, 0.5573,
          0.5573, 0.5573, 0.5573, 0.5573, 0.5573, 0.5573, 0.5573, 0.5573,
          0.5573, 0.5573, 0.5573, 0.5573, 0.5573, 0.5573, 0.5573, 0.5573,
          0.5573, 0.5573, 0.5573, 0.5573, 0.5573, 0.5573, 0.5573, 0.5573]]],
       device='cuda:0')
Z_mean = tensor([ 6.6201e-03+0.0093j,  1.9025e-02+0.0107j, -1.5482e-02-0.0021j,
         2.9074e-03-0.0132j, -2.5600e-02-0.0081j,  3.8561e-02-0.0003j,
         5.2489e-03+0.0227j,  2.5760e-03-0.0004j, -1.2502e-02-0.0129j,
         1.7895e-03+0.0055j,  1.3540e-02-0.0225j, -8.1668e-03-0.0124j,
        -1.6556e-02+0.0080j,  1.4714e-02+0.0057j,  1.1226e-02+0.0075j,
         3.7379e-03+0.0072j, -2.4957e-02-0.0099j, -6.7727e-05+0.0154j,
        -1.9077e-02+0.0031j, -3.3122e-03+0.0120j], device='cuda:0')
Z_variance ~CN(0, 1)= tensor([0.9693, 0.9863, 0.9808, 0.9968, 1.0513, 0.9849, 1.0039, 0.9589, 1.0423,
        0.9795, 1.0062, 1.0154, 1.0386, 1.0243, 0.9718, 1.0072, 0.9580, 0.9735,
        1.0166, 0.9841], device='cuda:0')
Real_SNR = tensor([1.2207, 1.6498, 2.4470, 1.2545, 1.4698, 1.6851, 0.6972, 1.3752, 1.6846,
        1.4962, 1.6114, 1.7192, 1.6499, 1.9881, 1.2175, 1.6043, 0.8469, 1.7010,
        1.4799, 1.3881], device='cuda:0')
q_var = tensor([1.0001, 1.0002, 1.0002, 1.0002, 0.9999, 1.0002, 1.0000, 1.0002, 0.9999,
        1.0002, 1.0002, 1.0000, 1.0000, 0.9986, 1.0002, 0.9998, 1.0002, 1.0002,
        1.0002, 0.9989], device='cuda:0')
(D_eta_sqrt @ q).var = tensor([1.0001, 1.0002, 1.0002, 1.0002, 0.9999, 1.0002, 1.0000, 1.0002, 0.9999,
        1.0002, 1.0002, 1.0000, 1.0000, 0.9986, 1.0002, 0.9998, 1.0002, 1.0002,
        1.0002, 0.9989], device='cuda:0')
(G @ (D_eta_sqrt @ q)).var = tensor([34.1761, 37.1022, 45.7066, 33.2104, 36.3498, 37.0277, 29.5007, 35.6430,
        36.9135, 36.5472, 36.4101, 37.1334, 36.9131, 40.4510, 33.8123, 37.2098,
        31.1987, 37.1446, 35.6421, 34.8261], device='cuda:0')
signal_var = tensor([1.3445, 1.4597, 1.7982, 1.3065, 1.4301, 1.4567, 1.1606, 1.4022, 1.4522,
        1.4378, 1.4324, 1.4609, 1.4522, 1.5914, 1.3302, 1.4639, 1.2274, 1.4613,
        1.4022, 1.3701], device='cuda:0')
w_var = tensor([1.0151, 0.9983, 1.0236, 0.9788, 1.0195, 0.9883, 0.9885, 1.0217, 0.9853,
        1.0188, 0.9884, 0.9833, 0.9932, 1.0069, 1.0050, 1.0118, 1.0100, 0.9877,
        0.9973, 0.9953], device='cuda:0')
y_var = tensor([2.3603, 2.4460, 2.8290, 2.2788, 2.4924, 2.4228, 2.1168, 2.4529, 2.4419,
        2.4819, 2.4346, 2.4631, 2.4115, 2.6347, 2.3599, 2.4551, 2.2512, 2.4614,
        2.4105, 2.3974], device='cuda:0')
####cond finisihed #####
sum_betak_gammak = tensor([14.1660, 14.1660, 14.1660, 14.1660, 14.1660, 14.1660, 14.1660, 14.1660,
        14.1660, 14.1660, 14.1660, 14.1660, 14.1660, 14.1660, 14.1660, 14.1660,
        14.1660, 14.1660, 14.1660, 14.1660], device='cuda:0')
************
inv_Z_H_Z_k (shape: torch.Size([20, 32])) = tensor([[0.0361, 0.0368, 0.0292, 0.0267, 0.0280, 0.0430, 0.0258, 0.0365, 0.0225,
         0.0331, 0.0297, 0.0406, 0.0365, 0.0342, 0.0241, 0.0265, 0.0406, 0.0344,
         0.0322, 0.0329, 0.0292, 0.0267, 0.0336, 0.0281, 0.0301, 0.0292, 0.0253,
         0.0354, 0.0342, 0.0244, 0.0322, 0.0242],
        [0.0266, 0.0265, 0.0276, 0.0373, 0.0308, 0.0274, 0.0354, 0.0342, 0.0258,
         0.0347, 0.0365, 0.0527, 0.0350, 0.0335, 0.0345, 0.0227, 0.0229, 0.0362,
         0.0344, 0.0260, 0.0354, 0.0242, 0.0452, 0.0251, 0.0219, 0.0180, 0.0411,
         0.0280, 0.0271, 0.0311, 0.0388, 0.0307],
        [0.0371, 0.0314, 0.0344, 0.0268, 0.0311, 0.0398, 0.0391, 0.0297, 0.0296,
         0.0327, 0.0242, 0.0382, 0.0318, 0.0481, 0.0360, 0.0373, 0.0245, 0.0320,
         0.0321, 0.0325, 0.0342, 0.0407, 0.0366, 0.0366, 0.0320, 0.0339, 0.0474,
         0.0430, 0.0297, 0.0270, 0.0357, 0.0365],
        [0.0308, 0.0356, 0.0349, 0.0349, 0.0319, 0.0270, 0.0242, 0.0265, 0.0291,
         0.0287, 0.0320, 0.0336, 0.0332, 0.0277, 0.0266, 0.0276, 0.0453, 0.0260,
         0.0293, 0.0302, 0.0296, 0.0289, 0.0259, 0.0248, 0.0303, 0.0297, 0.0437,
         0.0279, 0.0327, 0.0279, 0.0268, 0.0399],
        [0.0270, 0.0352, 0.0278, 0.0254, 0.0354, 0.0283, 0.0294, 0.0325, 0.0293,
         0.0286, 0.0241, 0.0242, 0.0285, 0.0322, 0.0336, 0.0284, 0.0312, 0.0260,
         0.0400, 0.0355, 0.0200, 0.0292, 0.0338, 0.0343, 0.0415, 0.0261, 0.0280,
         0.0270, 0.0315, 0.0255, 0.0292, 0.0300],
        [0.0397, 0.0188, 0.0244, 0.0320, 0.0268, 0.0318, 0.0275, 0.0282, 0.0302,
         0.0248, 0.0222, 0.0344, 0.0236, 0.0325, 0.0374, 0.0423, 0.0345, 0.0301,
         0.0312, 0.0251, 0.0336, 0.0299, 0.0314, 0.0342, 0.0256, 0.0399, 0.0270,
         0.0339, 0.0214, 0.0327, 0.0301, 0.0367],
        [0.0277, 0.0307, 0.0329, 0.0302, 0.0338, 0.0366, 0.0347, 0.0255, 0.0306,
         0.0346, 0.0322, 0.0305, 0.0340, 0.0278, 0.0357, 0.0273, 0.0236, 0.0287,
         0.0404, 0.0342, 0.0310, 0.0350, 0.0484, 0.0315, 0.0337, 0.0256, 0.0446,
         0.0260, 0.0358, 0.0289, 0.0354, 0.0227],
        [0.0358, 0.0372, 0.0342, 0.0422, 0.0281, 0.0305, 0.0301, 0.0316, 0.0369,
         0.0281, 0.0298, 0.0357, 0.0427, 0.0313, 0.0321, 0.0270, 0.0444, 0.0220,
         0.0334, 0.0326, 0.0348, 0.0265, 0.0445, 0.0397, 0.0332, 0.0353, 0.0282,
         0.0332, 0.0328, 0.0284, 0.0327, 0.0302],
        [0.0199, 0.0308, 0.0249, 0.0317, 0.0280, 0.0321, 0.0327, 0.0283, 0.0266,
         0.0342, 0.0331, 0.0349, 0.0299, 0.0242, 0.0292, 0.0235, 0.0458, 0.0266,
         0.0345, 0.0357, 0.0273, 0.0309, 0.0325, 0.0274, 0.0298, 0.0234, 0.0293,
         0.0265, 0.0283, 0.0302, 0.0260, 0.0286],
        [0.0401, 0.0370, 0.0338, 0.0274, 0.0290, 0.0370, 0.0382, 0.0329, 0.0399,
         0.0331, 0.0258, 0.0282, 0.0328, 0.0248, 0.0253, 0.0329, 0.0386, 0.0310,
         0.0346, 0.0391, 0.0415, 0.0243, 0.0310, 0.0307, 0.0302, 0.0244, 0.0379,
         0.0365, 0.0257, 0.0391, 0.0258, 0.0410],
        [0.0285, 0.0377, 0.0424, 0.0318, 0.0260, 0.0256, 0.0230, 0.0225, 0.0333,
         0.0269, 0.0280, 0.0262, 0.0243, 0.0315, 0.0277, 0.0242, 0.0337, 0.0258,
         0.0308, 0.0288, 0.0344, 0.0352, 0.0358, 0.0323, 0.0241, 0.0275, 0.0256,
         0.0311, 0.0277, 0.0265, 0.0279, 0.0353],
        [0.0240, 0.0415, 0.0312, 0.0293, 0.0365, 0.0268, 0.0313, 0.0260, 0.0319,
         0.0343, 0.0277, 0.0354, 0.0301, 0.0322, 0.0335, 0.0354, 0.0306, 0.0347,
         0.0405, 0.0288, 0.0345, 0.0353, 0.0278, 0.0288, 0.0369, 0.0275, 0.0269,
         0.0221, 0.0331, 0.0264, 0.0317, 0.0199],
        [0.0239, 0.0258, 0.0322, 0.0314, 0.0225, 0.0306, 0.0378, 0.0296, 0.0269,
         0.0267, 0.0383, 0.0259, 0.0207, 0.0301, 0.0337, 0.0271, 0.0256, 0.0255,
         0.0288, 0.0270, 0.0218, 0.0342, 0.0280, 0.0231, 0.0209, 0.0312, 0.0332,
         0.0270, 0.0402, 0.0316, 0.0343, 0.0299],
        [0.0305, 0.0273, 0.0311, 0.0213, 0.0272, 0.0300, 0.0266, 0.0266, 0.0272,
         0.0285, 0.0341, 0.0248, 0.0354, 0.0333, 0.0226, 0.0320, 0.0232, 0.0311,
         0.0256, 0.0293, 0.0283, 0.0321, 0.0336, 0.0407, 0.0330, 0.0232, 0.0383,
         0.0261, 0.0336, 0.0410, 0.0315, 0.0372],
        [0.0298, 0.0294, 0.0322, 0.0292, 0.0368, 0.0410, 0.0371, 0.0318, 0.0396,
         0.0232, 0.0321, 0.0253, 0.0285, 0.0305, 0.0358, 0.0375, 0.0312, 0.0259,
         0.0339, 0.0260, 0.0287, 0.0441, 0.0453, 0.0317, 0.0425, 0.0386, 0.0278,
         0.0343, 0.0355, 0.0371, 0.0232, 0.0311],
        [0.0356, 0.0333, 0.0297, 0.0230, 0.0301, 0.0270, 0.0289, 0.0395, 0.0289,
         0.0227, 0.0300, 0.0251, 0.0313, 0.0251, 0.0299, 0.0268, 0.0325, 0.0270,
         0.0276, 0.0291, 0.0340, 0.0370, 0.0302, 0.0408, 0.0219, 0.0319, 0.0270,
         0.0276, 0.0253, 0.0316, 0.0435, 0.0275],
        [0.0322, 0.0401, 0.0303, 0.0304, 0.0268, 0.0343, 0.0348, 0.0262, 0.0388,
         0.0250, 0.0273, 0.0399, 0.0334, 0.0370, 0.0365, 0.0302, 0.0290, 0.0270,
         0.0364, 0.0363, 0.0371, 0.0412, 0.0367, 0.0308, 0.0277, 0.0283, 0.0342,
         0.0399, 0.0322, 0.0310, 0.0297, 0.0232],
        [0.0282, 0.0383, 0.0333, 0.0296, 0.0380, 0.0280, 0.0351, 0.0292, 0.0297,
         0.0345, 0.0302, 0.0324, 0.0306, 0.0327, 0.0309, 0.0371, 0.0301, 0.0379,
         0.0222, 0.0284, 0.0340, 0.0308, 0.0277, 0.0282, 0.0282, 0.0362, 0.0265,
         0.0278, 0.0233, 0.0300, 0.0354, 0.0307],
        [0.0299, 0.0279, 0.0325, 0.0301, 0.0276, 0.0325, 0.0330, 0.0369, 0.0304,
         0.0353, 0.0342, 0.0464, 0.0294, 0.0223, 0.0279, 0.0294, 0.0245, 0.0387,
         0.0452, 0.0325, 0.0395, 0.0245, 0.0340, 0.0353, 0.0329, 0.0307, 0.0259,
         0.0211, 0.0262, 0.0317, 0.0299, 0.0260],
        [0.0350, 0.0304, 0.0409, 0.0271, 0.0432, 0.0278, 0.0269, 0.0269, 0.0259,
         0.0290, 0.0359, 0.0274, 0.0364, 0.0322, 0.0352, 0.0320, 0.0245, 0.0311,
         0.0319, 0.0294, 0.0341, 0.0273, 0.0377, 0.0258, 0.0335, 0.0301, 0.0366,
         0.0208, 0.0301, 0.0305, 0.0340, 0.0466]], device='cuda:0')
inv_Z_H_Z_k.mean (expected to be = 0.03124999990234375) = 0.03128612041473389
Var (shape: torch.Size([20, 32])) = tensor([[0.0562, 0.0574, 0.0454, 0.0415, 0.0436, 0.0670, 0.0402, 0.0568, 0.0350,
         0.0516, 0.0463, 0.0633, 0.0568, 0.0533, 0.0376, 0.0413, 0.0632, 0.0536,
         0.0501, 0.0512, 0.0454, 0.0416, 0.0523, 0.0437, 0.0469, 0.0455, 0.0394,
         0.0552, 0.0532, 0.0379, 0.0501, 0.0377],
        [0.0414, 0.0413, 0.0430, 0.0581, 0.0480, 0.0427, 0.0552, 0.0533, 0.0402,
         0.0541, 0.0569, 0.0821, 0.0544, 0.0522, 0.0537, 0.0354, 0.0357, 0.0563,
         0.0536, 0.0405, 0.0551, 0.0378, 0.0704, 0.0391, 0.0341, 0.0280, 0.0639,
         0.0435, 0.0421, 0.0485, 0.0604, 0.0478],
        [0.0578, 0.0489, 0.0535, 0.0417, 0.0484, 0.0620, 0.0609, 0.0463, 0.0461,
         0.0509, 0.0376, 0.0595, 0.0495, 0.0749, 0.0561, 0.0581, 0.0382, 0.0498,
         0.0500, 0.0506, 0.0533, 0.0634, 0.0570, 0.0570, 0.0498, 0.0528, 0.0738,
         0.0670, 0.0463, 0.0421, 0.0555, 0.0569],
        [0.0479, 0.0555, 0.0543, 0.0544, 0.0497, 0.0420, 0.0377, 0.0413, 0.0453,
         0.0447, 0.0498, 0.0523, 0.0518, 0.0431, 0.0415, 0.0430, 0.0706, 0.0405,
         0.0457, 0.0471, 0.0461, 0.0450, 0.0403, 0.0386, 0.0471, 0.0462, 0.0680,
         0.0434, 0.0510, 0.0435, 0.0417, 0.0621],
        [0.0420, 0.0549, 0.0433, 0.0395, 0.0551, 0.0440, 0.0457, 0.0506, 0.0456,
         0.0445, 0.0375, 0.0377, 0.0443, 0.0501, 0.0523, 0.0443, 0.0486, 0.0404,
         0.0622, 0.0553, 0.0312, 0.0454, 0.0526, 0.0534, 0.0646, 0.0407, 0.0435,
         0.0420, 0.0490, 0.0397, 0.0454, 0.0467],
        [0.0618, 0.0294, 0.0380, 0.0498, 0.0417, 0.0495, 0.0429, 0.0440, 0.0470,
         0.0386, 0.0346, 0.0535, 0.0368, 0.0507, 0.0582, 0.0658, 0.0537, 0.0469,
         0.0486, 0.0391, 0.0524, 0.0466, 0.0489, 0.0532, 0.0398, 0.0621, 0.0420,
         0.0527, 0.0333, 0.0509, 0.0469, 0.0572],
        [0.0432, 0.0479, 0.0512, 0.0471, 0.0526, 0.0570, 0.0541, 0.0397, 0.0477,
         0.0539, 0.0502, 0.0475, 0.0529, 0.0434, 0.0556, 0.0425, 0.0367, 0.0447,
         0.0629, 0.0533, 0.0484, 0.0545, 0.0754, 0.0490, 0.0524, 0.0399, 0.0695,
         0.0404, 0.0558, 0.0450, 0.0551, 0.0353],
        [0.0558, 0.0580, 0.0532, 0.0657, 0.0437, 0.0475, 0.0469, 0.0492, 0.0574,
         0.0438, 0.0464, 0.0556, 0.0666, 0.0487, 0.0500, 0.0420, 0.0692, 0.0342,
         0.0521, 0.0507, 0.0542, 0.0412, 0.0693, 0.0618, 0.0517, 0.0549, 0.0439,
         0.0517, 0.0511, 0.0443, 0.0509, 0.0470],
        [0.0309, 0.0480, 0.0388, 0.0493, 0.0436, 0.0500, 0.0509, 0.0441, 0.0414,
         0.0533, 0.0515, 0.0543, 0.0466, 0.0378, 0.0455, 0.0366, 0.0714, 0.0415,
         0.0537, 0.0556, 0.0425, 0.0481, 0.0506, 0.0427, 0.0464, 0.0365, 0.0456,
         0.0412, 0.0441, 0.0470, 0.0405, 0.0446],
        [0.0624, 0.0576, 0.0527, 0.0427, 0.0451, 0.0577, 0.0595, 0.0513, 0.0621,
         0.0515, 0.0403, 0.0439, 0.0511, 0.0386, 0.0394, 0.0512, 0.0601, 0.0482,
         0.0538, 0.0608, 0.0646, 0.0378, 0.0483, 0.0479, 0.0471, 0.0380, 0.0590,
         0.0568, 0.0400, 0.0610, 0.0402, 0.0638],
        [0.0444, 0.0588, 0.0660, 0.0495, 0.0405, 0.0399, 0.0358, 0.0350, 0.0519,
         0.0419, 0.0436, 0.0407, 0.0379, 0.0490, 0.0432, 0.0377, 0.0525, 0.0402,
         0.0480, 0.0449, 0.0535, 0.0548, 0.0557, 0.0504, 0.0376, 0.0428, 0.0399,
         0.0484, 0.0431, 0.0412, 0.0434, 0.0550],
        [0.0374, 0.0646, 0.0486, 0.0456, 0.0569, 0.0417, 0.0488, 0.0404, 0.0497,
         0.0534, 0.0431, 0.0551, 0.0469, 0.0502, 0.0521, 0.0551, 0.0477, 0.0540,
         0.0631, 0.0448, 0.0538, 0.0550, 0.0433, 0.0448, 0.0575, 0.0428, 0.0418,
         0.0344, 0.0515, 0.0411, 0.0493, 0.0310],
        [0.0372, 0.0403, 0.0502, 0.0490, 0.0350, 0.0477, 0.0588, 0.0462, 0.0419,
         0.0417, 0.0596, 0.0403, 0.0322, 0.0469, 0.0524, 0.0422, 0.0398, 0.0397,
         0.0449, 0.0420, 0.0339, 0.0532, 0.0436, 0.0360, 0.0326, 0.0486, 0.0517,
         0.0420, 0.0626, 0.0492, 0.0534, 0.0466],
        [0.0475, 0.0426, 0.0485, 0.0332, 0.0424, 0.0467, 0.0414, 0.0415, 0.0424,
         0.0444, 0.0531, 0.0386, 0.0551, 0.0519, 0.0352, 0.0498, 0.0362, 0.0485,
         0.0399, 0.0457, 0.0440, 0.0500, 0.0524, 0.0634, 0.0514, 0.0361, 0.0597,
         0.0406, 0.0524, 0.0638, 0.0491, 0.0579],
        [0.0464, 0.0458, 0.0502, 0.0455, 0.0572, 0.0638, 0.0578, 0.0496, 0.0617,
         0.0361, 0.0500, 0.0394, 0.0444, 0.0475, 0.0557, 0.0584, 0.0486, 0.0403,
         0.0528, 0.0404, 0.0447, 0.0687, 0.0706, 0.0493, 0.0662, 0.0601, 0.0433,
         0.0534, 0.0553, 0.0578, 0.0361, 0.0485],
        [0.0554, 0.0519, 0.0463, 0.0358, 0.0469, 0.0420, 0.0450, 0.0616, 0.0450,
         0.0354, 0.0468, 0.0391, 0.0487, 0.0390, 0.0465, 0.0417, 0.0507, 0.0421,
         0.0430, 0.0454, 0.0530, 0.0576, 0.0470, 0.0636, 0.0341, 0.0497, 0.0421,
         0.0430, 0.0394, 0.0492, 0.0678, 0.0429],
        [0.0501, 0.0625, 0.0472, 0.0473, 0.0417, 0.0534, 0.0542, 0.0408, 0.0605,
         0.0390, 0.0425, 0.0621, 0.0520, 0.0576, 0.0568, 0.0470, 0.0451, 0.0420,
         0.0567, 0.0565, 0.0578, 0.0641, 0.0572, 0.0479, 0.0432, 0.0440, 0.0532,
         0.0621, 0.0501, 0.0483, 0.0462, 0.0361],
        [0.0439, 0.0596, 0.0518, 0.0462, 0.0592, 0.0436, 0.0547, 0.0455, 0.0463,
         0.0537, 0.0470, 0.0504, 0.0476, 0.0509, 0.0481, 0.0578, 0.0468, 0.0590,
         0.0346, 0.0442, 0.0529, 0.0479, 0.0431, 0.0439, 0.0439, 0.0563, 0.0413,
         0.0433, 0.0362, 0.0468, 0.0551, 0.0478],
        [0.0465, 0.0435, 0.0506, 0.0469, 0.0429, 0.0507, 0.0514, 0.0575, 0.0474,
         0.0550, 0.0533, 0.0723, 0.0458, 0.0347, 0.0435, 0.0458, 0.0381, 0.0602,
         0.0705, 0.0506, 0.0615, 0.0381, 0.0530, 0.0550, 0.0513, 0.0477, 0.0404,
         0.0329, 0.0408, 0.0494, 0.0466, 0.0405],
        [0.0545, 0.0474, 0.0638, 0.0422, 0.0673, 0.0433, 0.0418, 0.0419, 0.0403,
         0.0451, 0.0559, 0.0427, 0.0567, 0.0502, 0.0549, 0.0498, 0.0381, 0.0485,
         0.0497, 0.0458, 0.0531, 0.0425, 0.0587, 0.0402, 0.0521, 0.0469, 0.0570,
         0.0324, 0.0469, 0.0475, 0.0529, 0.0726]], device='cuda:0')
***********
SINR = tensor([-3.3507, -3.2758, -3.7704, -3.2926, -3.1794, -3.1969, -3.4733, -3.6308,
        -3.1245, -3.5453, -3.1023, -3.3162, -3.0019, -3.1965, -3.5695, -3.1803,
        -3.5492, -3.3679, -3.3452, -3.4090], device='cuda:0')
Real_SINR = tensor([-3.4493, -3.7340, -4.2142, -3.5963, -3.6896, -3.3738, -2.7793, -3.6754,
        -3.3552, -3.5663, -3.4619, -3.7419, -3.6488, -4.1789, -3.8867, -3.0305,
        -3.9200, -3.3646, -3.4737, -3.3957], device='cuda:0')
Real_SINR_noise.shape = torch.Size([20])
ldm/modules/diffusionmodules/util.py, make_ddim_timsteps ddim_discr_method = uniform
ldm/modules/diffusionmodules/util.py, make_ddim_timsteps, Selected timesteps for ddim sampler: (200,)
ldm/modules/diffusionmodules/util.py, make_ddim_sampling_parameters, Selected alphas for ddim sampler: a_t: torch.Size([200]); a_(t-1): (200,)
For the chosen value of eta, which is 0.0, this results in the following sigma_t schedule for ddim sampler tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], dtype=torch.float64)
ddim.py alphas_cumprod = torch.Size([1000])
ddim.py, alpha_bar_u = tensor([0.3161, 0.3199, 0.2956, 0.3190, 0.3247, 0.3239, 0.3101, 0.3024, 0.3275,
        0.3065, 0.3286, 0.3179, 0.3338, 0.3239, 0.3054, 0.3247, 0.3063, 0.3153,
        0.3164, 0.3133], device='cuda:0')
ddim.py start_timesteps after clamp S = 200 : tensor([472, 469, 486, 470, 466, 466, 476, 481, 464, 478, 463, 470, 460, 466,
        479, 466, 479, 472, 471, 474], device='cuda:0')
d = torch.Size([20, 4, 32, 32])
recoverd_img = torch.Size([20, 3, 256, 256])
20 images are saved in outputs/MIMOdiffusion/M=64/K=32/dynamic/
20 images are saved in outputs/MIMOdiffusion/M=64/K=32/nonoisenosample/
--------SNR = 2,  rho_ul = 0.0495279122644098-----------
G_variance = tensor([0.9928, 0.9931, 1.0051, 0.9883, 0.9819, 0.9868, 0.9888, 1.0052, 1.0146,
        0.9842, 1.0020, 0.9988, 1.0296, 1.0071, 1.0226, 1.0089, 0.9861, 1.0035,
        1.0039, 0.9896], device='cuda:0')
G_hat_variance = tensor([0.6254, 0.6158, 0.6019, 0.6056, 0.6157, 0.6339, 0.6067, 0.6168, 0.6328,
        0.6104, 0.5868, 0.6166, 0.6165, 0.6184, 0.6142, 0.6092, 0.5968, 0.6296,
        0.6056, 0.6144], device='cuda:0')
G_tilde_var = tensor([0.3850, 0.3840, 0.3909, 0.3897, 0.3832, 0.3909, 0.3823, 0.3811, 0.3890,
        0.3939, 0.3871, 0.3766, 0.4001, 0.3987, 0.3785, 0.3970, 0.3941, 0.3734,
        0.3887, 0.3836], device='cuda:0')
gamma = tensor([[[0.6131, 0.6131, 0.6131, 0.6131, 0.6131, 0.6131, 0.6131, 0.6131,
          0.6131, 0.6131, 0.6131, 0.6131, 0.6131, 0.6131, 0.6131, 0.6131,
          0.6131, 0.6131, 0.6131, 0.6131, 0.6131, 0.6131, 0.6131, 0.6131,
          0.6131, 0.6131, 0.6131, 0.6131, 0.6131, 0.6131, 0.6131, 0.6131]]],
       device='cuda:0')
Z_mean = tensor([ 0.0251-4.3069e-03j,  0.0207+7.3634e-04j, -0.0079-3.4392e-02j,
        -0.0119+2.7516e-05j, -0.0055-1.8789e-02j,  0.0046+1.7719e-02j,
        -0.0317+3.4131e-03j,  0.0200+7.7512e-03j, -0.0049-1.0230e-02j,
        -0.0334-1.3684e-02j, -0.0036+2.1442e-03j,  0.0054+2.1246e-02j,
         0.0065-1.4028e-02j,  0.0038+1.0955e-03j,  0.0266+1.0200e-02j,
         0.0170-2.1514e-03j, -0.0121+1.9100e-03j,  0.0009+6.6379e-03j,
         0.0090-1.4254e-03j, -0.0109-1.8350e-02j], device='cuda:0')
Z_variance ~CN(0, 1)= tensor([1.0200, 1.0044, 0.9818, 0.9877, 1.0042, 1.0339, 0.9895, 1.0059, 1.0320,
        0.9956, 0.9570, 1.0056, 1.0054, 1.0085, 1.0017, 0.9936, 0.9733, 1.0268,
        0.9877, 1.0020], device='cuda:0')
Real_SNR = tensor([1.9847, 3.1263, 3.4770, 1.9365, 2.2217, 2.9283, 1.6432, 2.8203, 2.4850,
        2.6945, 1.8821, 2.3631, 2.4092, 2.2335, 2.4058, 2.5361, 2.2542, 2.2254,
        2.4598, 1.7584], device='cuda:0')
q_var = tensor([1.0001, 1.0002, 1.0002, 1.0002, 0.9999, 1.0002, 1.0000, 1.0002, 0.9999,
        1.0002, 1.0002, 1.0000, 1.0000, 0.9986, 1.0002, 0.9998, 1.0002, 1.0002,
        1.0002, 0.9989], device='cuda:0')
(D_eta_sqrt @ q).var = tensor([1.0001, 1.0002, 1.0002, 1.0002, 0.9999, 1.0002, 1.0000, 1.0002, 0.9999,
        1.0002, 1.0002, 1.0000, 1.0000, 0.9986, 1.0002, 0.9998, 1.0002, 1.0002,
        1.0002, 0.9989], device='cuda:0')
(G @ (D_eta_sqrt @ q)).var = tensor([31.9398, 40.1863, 45.6219, 31.3885, 33.3104, 40.3790, 29.1532, 37.5495,
        35.0479, 37.1746, 31.7647, 35.1262, 35.4183, 33.1489, 35.8977, 36.2883,
        33.4924, 34.2065, 35.4207, 30.4666], device='cuda:0')
signal_var = tensor([1.5819, 1.9903, 2.2596, 1.5546, 1.6498, 1.9999, 1.4439, 1.8598, 1.7358,
        1.8412, 1.5732, 1.7397, 1.7542, 1.6418, 1.7779, 1.7973, 1.6588, 1.6942,
        1.7543, 1.5089], device='cuda:0')
w_var = tensor([1.0016, 0.9689, 1.0147, 0.9953, 0.9891, 1.0190, 0.9890, 0.9715, 0.9795,
        0.9900, 1.0200, 1.0096, 1.0073, 0.9817, 1.0217, 1.0023, 0.9871, 1.0149,
        0.9957, 1.0065], device='cuda:0')
y_var = tensor([2.6239, 2.9840, 3.2365, 2.5753, 2.6567, 3.0548, 2.4194, 2.8555, 2.7050,
        2.8321, 2.5982, 2.7141, 2.7751, 2.6190, 2.7901, 2.8053, 2.6291, 2.7264,
        2.7854, 2.4474], device='cuda:0')
####cond finisihed #####
sum_betak_gammak = tensor([12.3796, 12.3796, 12.3796, 12.3796, 12.3796, 12.3796, 12.3796, 12.3796,
        12.3796, 12.3796, 12.3796, 12.3796, 12.3796, 12.3796, 12.3796, 12.3796,
        12.3796, 12.3796, 12.3796, 12.3796], device='cuda:0')
************
inv_Z_H_Z_k (shape: torch.Size([20, 32])) = tensor([[0.0315, 0.0332, 0.0258, 0.0375, 0.0316, 0.0326, 0.0517, 0.0309, 0.0397,
         0.0310, 0.0268, 0.0393, 0.0220, 0.0290, 0.0396, 0.0332, 0.0350, 0.0261,
         0.0282, 0.0300, 0.0256, 0.0285, 0.0391, 0.0406, 0.0464, 0.0289, 0.0388,
         0.0348, 0.0414, 0.0269, 0.0299, 0.0273],
        [0.0246, 0.0318, 0.0277, 0.0312, 0.0279, 0.0349, 0.0253, 0.0333, 0.0310,
         0.0306, 0.0303, 0.0336, 0.0229, 0.0401, 0.0294, 0.0296, 0.0312, 0.0367,
         0.0264, 0.0360, 0.0282, 0.0293, 0.0356, 0.0290, 0.0469, 0.0354, 0.0263,
         0.0281, 0.0227, 0.0378, 0.0258, 0.0248],
        [0.0319, 0.0259, 0.0273, 0.0335, 0.0372, 0.0303, 0.0323, 0.0328, 0.0335,
         0.0330, 0.0261, 0.0261, 0.0234, 0.0260, 0.0283, 0.0265, 0.0310, 0.0346,
         0.0273, 0.0351, 0.0282, 0.0323, 0.0242, 0.0277, 0.0299, 0.0281, 0.0252,
         0.0307, 0.0229, 0.0288, 0.0279, 0.0321],
        [0.0262, 0.0504, 0.0336, 0.0335, 0.0476, 0.0366, 0.0352, 0.0415, 0.0430,
         0.0326, 0.0416, 0.0293, 0.0299, 0.0331, 0.0364, 0.0343, 0.0339, 0.0244,
         0.0370, 0.0306, 0.0286, 0.0346, 0.0247, 0.0298, 0.0333, 0.0346, 0.0255,
         0.0351, 0.0257, 0.0261, 0.0363, 0.0387],
        [0.0230, 0.0212, 0.0270, 0.0357, 0.0474, 0.0270, 0.0291, 0.0221, 0.0368,
         0.0384, 0.0388, 0.0366, 0.0422, 0.0293, 0.0347, 0.0292, 0.0280, 0.0244,
         0.0321, 0.0313, 0.0419, 0.0301, 0.0340, 0.0366, 0.0350, 0.0328, 0.0307,
         0.0355, 0.0336, 0.0403, 0.0207, 0.0293],
        [0.0274, 0.0347, 0.0316, 0.0253, 0.0185, 0.0345, 0.0270, 0.0386, 0.0395,
         0.0244, 0.0224, 0.0324, 0.0325, 0.0320, 0.0296, 0.0247, 0.0329, 0.0289,
         0.0326, 0.0294, 0.0259, 0.0292, 0.0311, 0.0279, 0.0235, 0.0271, 0.0242,
         0.0230, 0.0247, 0.0267, 0.0314, 0.0324],
        [0.0232, 0.0257, 0.0332, 0.0299, 0.0339, 0.0381, 0.0313, 0.0306, 0.0309,
         0.0230, 0.0259, 0.0296, 0.0228, 0.0278, 0.0376, 0.0272, 0.0274, 0.0341,
         0.0274, 0.0330, 0.0280, 0.0277, 0.0322, 0.0285, 0.0338, 0.0276, 0.0204,
         0.0313, 0.0296, 0.0257, 0.0308, 0.0293],
        [0.0265, 0.0265, 0.0265, 0.0337, 0.0341, 0.0362, 0.0226, 0.0280, 0.0253,
         0.0258, 0.0318, 0.0251, 0.0235, 0.0313, 0.0318, 0.0336, 0.0305, 0.0357,
         0.0313, 0.0308, 0.0318, 0.0237, 0.0298, 0.0303, 0.0302, 0.0283, 0.0290,
         0.0417, 0.0234, 0.0309, 0.0321, 0.0264],
        [0.0302, 0.0429, 0.0251, 0.0344, 0.0263, 0.0354, 0.0355, 0.0320, 0.0454,
         0.0252, 0.0364, 0.0286, 0.0262, 0.0413, 0.0317, 0.0288, 0.0316, 0.0305,
         0.0270, 0.0317, 0.0263, 0.0304, 0.0274, 0.0254, 0.0343, 0.0242, 0.0410,
         0.0259, 0.0293, 0.0295, 0.0235, 0.0273],
        [0.0252, 0.0338, 0.0353, 0.0277, 0.0225, 0.0244, 0.0380, 0.0316, 0.0373,
         0.0280, 0.0310, 0.0263, 0.0284, 0.0279, 0.0323, 0.0343, 0.0263, 0.0319,
         0.0397, 0.0258, 0.0376, 0.0321, 0.0246, 0.0273, 0.0319, 0.0273, 0.0304,
         0.0336, 0.0318, 0.0308, 0.0324, 0.0310],
        [0.0472, 0.0341, 0.0305, 0.0299, 0.0302, 0.0237, 0.0312, 0.0419, 0.0348,
         0.0340, 0.0363, 0.0318, 0.0300, 0.0465, 0.0390, 0.0284, 0.0316, 0.0271,
         0.0336, 0.0284, 0.0331, 0.0327, 0.0452, 0.0362, 0.0297, 0.0265, 0.0418,
         0.0351, 0.0382, 0.0318, 0.0327, 0.0326],
        [0.0309, 0.0289, 0.0248, 0.0332, 0.0365, 0.0340, 0.0310, 0.0214, 0.0248,
         0.0390, 0.0339, 0.0342, 0.0294, 0.0291, 0.0249, 0.0338, 0.0304, 0.0451,
         0.0288, 0.0293, 0.0285, 0.0250, 0.0329, 0.0286, 0.0311, 0.0250, 0.0260,
         0.0370, 0.0294, 0.0364, 0.0260, 0.0383],
        [0.0247, 0.0358, 0.0261, 0.0320, 0.0278, 0.0321, 0.0250, 0.0280, 0.0284,
         0.0347, 0.0330, 0.0237, 0.0363, 0.0274, 0.0326, 0.0267, 0.0454, 0.0270,
         0.0286, 0.0285, 0.0312, 0.0290, 0.0282, 0.0230, 0.0253, 0.0346, 0.0265,
         0.0276, 0.0255, 0.0262, 0.0368, 0.0432],
        [0.0296, 0.0210, 0.0301, 0.0288, 0.0335, 0.0320, 0.0330, 0.0298, 0.0310,
         0.0393, 0.0262, 0.0299, 0.0255, 0.0267, 0.0238, 0.0353, 0.0355, 0.0331,
         0.0349, 0.0431, 0.0389, 0.0294, 0.0335, 0.0340, 0.0331, 0.0267, 0.0299,
         0.0295, 0.0394, 0.0292, 0.0408, 0.0302],
        [0.0368, 0.0288, 0.0268, 0.0309, 0.0258, 0.0253, 0.0318, 0.0235, 0.0294,
         0.0295, 0.0392, 0.0388, 0.0322, 0.0243, 0.0295, 0.0397, 0.0362, 0.0334,
         0.0438, 0.0321, 0.0297, 0.0357, 0.0366, 0.0304, 0.0316, 0.0333, 0.0270,
         0.0326, 0.0347, 0.0359, 0.0309, 0.0250],
        [0.0329, 0.0341, 0.0279, 0.0292, 0.0276, 0.0249, 0.0266, 0.0392, 0.0360,
         0.0305, 0.0298, 0.0217, 0.0281, 0.0363, 0.0296, 0.0247, 0.0291, 0.0273,
         0.0261, 0.0244, 0.0327, 0.0405, 0.0361, 0.0370, 0.0290, 0.0268, 0.0400,
         0.0306, 0.0260, 0.0282, 0.0283, 0.0400],
        [0.0351, 0.0332, 0.0280, 0.0269, 0.0231, 0.0321, 0.0367, 0.0385, 0.0391,
         0.0352, 0.0359, 0.0242, 0.0356, 0.0351, 0.0261, 0.0242, 0.0346, 0.0369,
         0.0362, 0.0322, 0.0363, 0.0385, 0.0350, 0.0401, 0.0253, 0.0265, 0.0302,
         0.0341, 0.0257, 0.0347, 0.0313, 0.0295],
        [0.0307, 0.0234, 0.0327, 0.0234, 0.0258, 0.0225, 0.0292, 0.0256, 0.0291,
         0.0295, 0.0223, 0.0292, 0.0250, 0.0284, 0.0252, 0.0269, 0.0306, 0.0308,
         0.0371, 0.0282, 0.0287, 0.0301, 0.0239, 0.0318, 0.0320, 0.0423, 0.0277,
         0.0349, 0.0256, 0.0268, 0.0322, 0.0252],
        [0.0326, 0.0276, 0.0282, 0.0352, 0.0365, 0.0276, 0.0271, 0.0333, 0.0344,
         0.0263, 0.0388, 0.0317, 0.0346, 0.0292, 0.0239, 0.0354, 0.0432, 0.0310,
         0.0282, 0.0292, 0.0407, 0.0247, 0.0277, 0.0271, 0.0412, 0.0286, 0.0336,
         0.0282, 0.0263, 0.0366, 0.0382, 0.0320],
        [0.0301, 0.0304, 0.0291, 0.0326, 0.0462, 0.0340, 0.0282, 0.0345, 0.0305,
         0.0404, 0.0228, 0.0274, 0.0246, 0.0287, 0.0329, 0.0209, 0.0281, 0.0367,
         0.0219, 0.0293, 0.0355, 0.0236, 0.0275, 0.0242, 0.0357, 0.0300, 0.0286,
         0.0266, 0.0251, 0.0289, 0.0334, 0.0281]], device='cuda:0')
inv_Z_H_Z_k.mean (expected to be = 0.03124999990234375) = 0.031043145805597305
Var (shape: torch.Size([20, 32])) = tensor([[0.0508, 0.0536, 0.0416, 0.0605, 0.0509, 0.0526, 0.0834, 0.0498, 0.0640,
         0.0500, 0.0432, 0.0634, 0.0355, 0.0467, 0.0639, 0.0536, 0.0565, 0.0421,
         0.0455, 0.0485, 0.0413, 0.0460, 0.0631, 0.0656, 0.0749, 0.0466, 0.0625,
         0.0561, 0.0667, 0.0434, 0.0482, 0.0441],
        [0.0397, 0.0512, 0.0447, 0.0503, 0.0450, 0.0562, 0.0408, 0.0537, 0.0500,
         0.0494, 0.0489, 0.0542, 0.0369, 0.0646, 0.0475, 0.0478, 0.0504, 0.0593,
         0.0425, 0.0581, 0.0455, 0.0472, 0.0575, 0.0467, 0.0756, 0.0571, 0.0424,
         0.0453, 0.0366, 0.0609, 0.0416, 0.0401],
        [0.0514, 0.0418, 0.0441, 0.0540, 0.0600, 0.0488, 0.0521, 0.0529, 0.0540,
         0.0532, 0.0421, 0.0422, 0.0378, 0.0419, 0.0457, 0.0428, 0.0501, 0.0559,
         0.0441, 0.0567, 0.0456, 0.0521, 0.0391, 0.0446, 0.0483, 0.0453, 0.0406,
         0.0496, 0.0369, 0.0465, 0.0450, 0.0518],
        [0.0422, 0.0812, 0.0542, 0.0540, 0.0769, 0.0591, 0.0567, 0.0669, 0.0693,
         0.0526, 0.0671, 0.0473, 0.0482, 0.0533, 0.0588, 0.0553, 0.0548, 0.0393,
         0.0596, 0.0494, 0.0461, 0.0557, 0.0398, 0.0481, 0.0538, 0.0559, 0.0411,
         0.0566, 0.0414, 0.0421, 0.0585, 0.0625],
        [0.0371, 0.0343, 0.0436, 0.0575, 0.0764, 0.0435, 0.0469, 0.0356, 0.0594,
         0.0620, 0.0626, 0.0591, 0.0681, 0.0472, 0.0560, 0.0471, 0.0452, 0.0394,
         0.0519, 0.0504, 0.0676, 0.0486, 0.0549, 0.0591, 0.0564, 0.0529, 0.0496,
         0.0572, 0.0542, 0.0650, 0.0333, 0.0473],
        [0.0442, 0.0559, 0.0510, 0.0408, 0.0299, 0.0557, 0.0436, 0.0623, 0.0637,
         0.0394, 0.0361, 0.0523, 0.0525, 0.0515, 0.0478, 0.0399, 0.0530, 0.0465,
         0.0526, 0.0474, 0.0418, 0.0471, 0.0502, 0.0450, 0.0379, 0.0437, 0.0390,
         0.0371, 0.0398, 0.0431, 0.0507, 0.0522],
        [0.0373, 0.0414, 0.0536, 0.0482, 0.0547, 0.0615, 0.0504, 0.0493, 0.0499,
         0.0372, 0.0418, 0.0478, 0.0367, 0.0449, 0.0606, 0.0438, 0.0442, 0.0550,
         0.0442, 0.0533, 0.0452, 0.0446, 0.0519, 0.0459, 0.0544, 0.0445, 0.0330,
         0.0504, 0.0478, 0.0415, 0.0497, 0.0473],
        [0.0427, 0.0428, 0.0428, 0.0544, 0.0550, 0.0585, 0.0365, 0.0451, 0.0408,
         0.0415, 0.0513, 0.0405, 0.0379, 0.0505, 0.0513, 0.0541, 0.0493, 0.0575,
         0.0504, 0.0497, 0.0513, 0.0383, 0.0480, 0.0490, 0.0486, 0.0457, 0.0468,
         0.0673, 0.0378, 0.0499, 0.0518, 0.0425],
        [0.0487, 0.0691, 0.0405, 0.0555, 0.0425, 0.0571, 0.0572, 0.0517, 0.0733,
         0.0407, 0.0587, 0.0462, 0.0422, 0.0666, 0.0511, 0.0464, 0.0510, 0.0492,
         0.0436, 0.0511, 0.0425, 0.0490, 0.0441, 0.0409, 0.0553, 0.0390, 0.0661,
         0.0418, 0.0473, 0.0475, 0.0379, 0.0440],
        [0.0406, 0.0545, 0.0570, 0.0446, 0.0363, 0.0393, 0.0613, 0.0509, 0.0602,
         0.0452, 0.0501, 0.0424, 0.0459, 0.0450, 0.0520, 0.0554, 0.0425, 0.0515,
         0.0641, 0.0417, 0.0606, 0.0518, 0.0397, 0.0440, 0.0515, 0.0441, 0.0490,
         0.0543, 0.0513, 0.0497, 0.0522, 0.0501],
        [0.0761, 0.0551, 0.0492, 0.0482, 0.0488, 0.0382, 0.0503, 0.0676, 0.0562,
         0.0549, 0.0586, 0.0513, 0.0484, 0.0750, 0.0629, 0.0458, 0.0510, 0.0437,
         0.0541, 0.0458, 0.0534, 0.0528, 0.0728, 0.0584, 0.0478, 0.0428, 0.0675,
         0.0567, 0.0615, 0.0513, 0.0527, 0.0526],
        [0.0498, 0.0467, 0.0400, 0.0535, 0.0590, 0.0549, 0.0500, 0.0345, 0.0400,
         0.0629, 0.0547, 0.0551, 0.0475, 0.0469, 0.0401, 0.0545, 0.0491, 0.0727,
         0.0465, 0.0473, 0.0459, 0.0403, 0.0530, 0.0461, 0.0502, 0.0403, 0.0420,
         0.0597, 0.0475, 0.0587, 0.0420, 0.0618],
        [0.0398, 0.0578, 0.0421, 0.0517, 0.0448, 0.0519, 0.0402, 0.0451, 0.0458,
         0.0560, 0.0532, 0.0382, 0.0586, 0.0441, 0.0526, 0.0431, 0.0732, 0.0435,
         0.0461, 0.0460, 0.0503, 0.0468, 0.0454, 0.0371, 0.0409, 0.0558, 0.0428,
         0.0445, 0.0412, 0.0423, 0.0594, 0.0697],
        [0.0478, 0.0339, 0.0485, 0.0464, 0.0540, 0.0517, 0.0532, 0.0481, 0.0500,
         0.0634, 0.0423, 0.0482, 0.0411, 0.0431, 0.0384, 0.0570, 0.0572, 0.0533,
         0.0564, 0.0695, 0.0627, 0.0473, 0.0541, 0.0548, 0.0533, 0.0430, 0.0482,
         0.0477, 0.0635, 0.0471, 0.0658, 0.0488],
        [0.0593, 0.0465, 0.0432, 0.0498, 0.0417, 0.0409, 0.0513, 0.0379, 0.0475,
         0.0476, 0.0632, 0.0625, 0.0519, 0.0392, 0.0476, 0.0640, 0.0584, 0.0539,
         0.0706, 0.0519, 0.0480, 0.0576, 0.0591, 0.0490, 0.0510, 0.0538, 0.0435,
         0.0526, 0.0560, 0.0580, 0.0499, 0.0403],
        [0.0531, 0.0551, 0.0451, 0.0470, 0.0445, 0.0401, 0.0429, 0.0633, 0.0581,
         0.0492, 0.0481, 0.0349, 0.0453, 0.0586, 0.0477, 0.0398, 0.0469, 0.0440,
         0.0421, 0.0394, 0.0528, 0.0654, 0.0582, 0.0597, 0.0468, 0.0433, 0.0646,
         0.0494, 0.0420, 0.0454, 0.0457, 0.0646],
        [0.0566, 0.0536, 0.0452, 0.0434, 0.0373, 0.0518, 0.0592, 0.0621, 0.0631,
         0.0567, 0.0579, 0.0390, 0.0575, 0.0566, 0.0420, 0.0390, 0.0558, 0.0595,
         0.0584, 0.0519, 0.0586, 0.0621, 0.0565, 0.0647, 0.0409, 0.0428, 0.0487,
         0.0549, 0.0414, 0.0559, 0.0505, 0.0475],
        [0.0495, 0.0377, 0.0527, 0.0378, 0.0416, 0.0363, 0.0470, 0.0413, 0.0470,
         0.0476, 0.0360, 0.0470, 0.0403, 0.0458, 0.0406, 0.0434, 0.0493, 0.0497,
         0.0599, 0.0455, 0.0463, 0.0486, 0.0386, 0.0512, 0.0516, 0.0683, 0.0447,
         0.0563, 0.0412, 0.0432, 0.0520, 0.0406],
        [0.0526, 0.0445, 0.0456, 0.0568, 0.0589, 0.0445, 0.0437, 0.0537, 0.0555,
         0.0425, 0.0626, 0.0511, 0.0558, 0.0470, 0.0386, 0.0571, 0.0696, 0.0501,
         0.0456, 0.0471, 0.0657, 0.0399, 0.0447, 0.0438, 0.0664, 0.0461, 0.0542,
         0.0454, 0.0424, 0.0591, 0.0616, 0.0517],
        [0.0485, 0.0490, 0.0470, 0.0525, 0.0745, 0.0548, 0.0456, 0.0556, 0.0492,
         0.0652, 0.0367, 0.0442, 0.0397, 0.0462, 0.0531, 0.0337, 0.0452, 0.0591,
         0.0353, 0.0473, 0.0572, 0.0381, 0.0443, 0.0390, 0.0575, 0.0483, 0.0461,
         0.0429, 0.0405, 0.0467, 0.0538, 0.0453]], device='cuda:0')
***********
SINR = tensor([-2.3086, -2.0162, -1.8691, -2.4077, -2.1710, -1.7505, -1.8352, -1.8841,
        -2.0327, -2.0221, -2.4470, -2.0335, -1.9132, -2.1664, -2.1924, -2.0070,
        -2.2453, -1.7331, -2.1792, -1.8769], device='cuda:0')
Real_SINR = tensor([-2.7862, -2.1073, -3.1672, -2.2512, -2.3916, -2.1721, -2.2720, -2.1147,
        -2.1080, -2.2607, -3.0032, -2.0617, -2.6220, -2.1568, -2.2805, -2.1718,
        -2.6212, -1.7325, -2.2055, -2.2426], device='cuda:0')
Real_SINR_noise.shape = torch.Size([20])
ldm/modules/diffusionmodules/util.py, make_ddim_timsteps ddim_discr_method = uniform
ldm/modules/diffusionmodules/util.py, make_ddim_timsteps, Selected timesteps for ddim sampler: (200,)
ldm/modules/diffusionmodules/util.py, make_ddim_sampling_parameters, Selected alphas for ddim sampler: a_t: torch.Size([200]); a_(t-1): (200,)
For the chosen value of eta, which is 0.0, this results in the following sigma_t schedule for ddim sampler tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], dtype=torch.float64)
ddim.py alphas_cumprod = torch.Size([1000])
ddim.py, alpha_bar_u = tensor([0.3701, 0.3860, 0.3940, 0.3648, 0.3776, 0.4006, 0.3959, 0.3932, 0.3851,
        0.3857, 0.3627, 0.3850, 0.3916, 0.3778, 0.3764, 0.3865, 0.3736, 0.4015,
        0.3771, 0.3936], device='cuda:0')
ddim.py start_timesteps after clamp S = 200 : tensor([435, 425, 420, 439, 430, 416, 419, 420, 425, 425, 440, 426, 421, 430,
        431, 425, 433, 415, 431, 420], device='cuda:0')
d = torch.Size([20, 4, 32, 32])
recoverd_img = torch.Size([20, 3, 256, 256])
20 images are saved in outputs/MIMOdiffusion/M=64/K=32/dynamic/
20 images are saved in outputs/MIMOdiffusion/M=64/K=32/nonoisenosample/
--------SNR = 3,  rho_ul = 0.062351947342777485-----------
G_variance = tensor([1.0020, 1.0059, 0.9729, 1.0467, 1.0315, 1.0091, 1.0224, 1.0021, 0.9963,
        0.9895, 1.0279, 1.0010, 0.9856, 1.0111, 1.0059, 1.0109, 0.9478, 0.9966,
        1.0080, 1.0334], device='cuda:0')
G_hat_variance = tensor([0.6545, 0.6639, 0.6554, 0.6863, 0.6932, 0.6756, 0.6840, 0.6746, 0.6646,
        0.6669, 0.6731, 0.6620, 0.6567, 0.6816, 0.6769, 0.6773, 0.6582, 0.6508,
        0.6618, 0.6870], device='cuda:0')
G_tilde_var = tensor([0.3356, 0.3478, 0.3428, 0.3420, 0.3416, 0.3323, 0.3403, 0.3347, 0.3290,
        0.3332, 0.3327, 0.3520, 0.3228, 0.3349, 0.3235, 0.3235, 0.3392, 0.3273,
        0.3369, 0.3312], device='cuda:0')
gamma = tensor([[[0.6661, 0.6661, 0.6661, 0.6661, 0.6661, 0.6661, 0.6661, 0.6661,
          0.6661, 0.6661, 0.6661, 0.6661, 0.6661, 0.6661, 0.6661, 0.6661,
          0.6661, 0.6661, 0.6661, 0.6661, 0.6661, 0.6661, 0.6661, 0.6661,
          0.6661, 0.6661, 0.6661, 0.6661, 0.6661, 0.6661, 0.6661, 0.6661]]],
       device='cuda:0')
Z_mean = tensor([-0.0060-0.0013j, -0.0045-0.0174j, -0.0136-0.0137j, -0.0135-0.0057j,
        -0.0239+0.0112j, -0.0115+0.0141j, -0.0056-0.0171j,  0.0336-0.0181j,
         0.0156-0.0324j, -0.0234+0.0247j, -0.0081-0.0121j,  0.0182-0.0019j,
        -0.0277-0.0110j,  0.0054+0.0058j,  0.0204-0.0358j,  0.0002-0.0024j,
        -0.0029+0.0060j,  0.0005+0.0094j, -0.0101-0.0023j, -0.0249+0.0035j],
       device='cuda:0')
Z_variance ~CN(0, 1)= tensor([0.9825, 0.9966, 0.9839, 1.0302, 1.0407, 1.0142, 1.0268, 1.0126, 0.9977,
        1.0011, 1.0104, 0.9937, 0.9858, 1.0233, 1.0161, 1.0168, 0.9881, 0.9769,
        0.9935, 1.0313], device='cuda:0')
Real_SNR = tensor([3.9992, 3.4007, 4.3828, 3.8196, 3.6786, 3.3218, 4.0787, 3.6904, 3.1033,
        3.7870, 3.7784, 3.3600, 3.1849, 3.4464, 3.2145, 3.3157, 2.6941, 4.2784,
        3.2685, 3.0610], device='cuda:0')
q_var = tensor([1.0001, 1.0002, 1.0002, 1.0002, 0.9999, 1.0002, 1.0000, 1.0002, 0.9999,
        1.0002, 1.0002, 1.0000, 1.0000, 0.9986, 1.0002, 0.9998, 1.0002, 1.0002,
        1.0002, 0.9989], device='cuda:0')
(D_eta_sqrt @ q).var = tensor([1.0001, 1.0002, 1.0002, 1.0002, 0.9999, 1.0002, 1.0000, 1.0002, 0.9999,
        1.0002, 1.0002, 1.0000, 1.0000, 0.9986, 1.0002, 0.9998, 1.0002, 1.0002,
        1.0002, 0.9989], device='cuda:0')
(G @ (D_eta_sqrt @ q)).var = tensor([38.5244, 36.0206, 43.4367, 38.8487, 37.3397, 34.7774, 40.6490, 36.5827,
        32.5921, 37.6409, 38.9280, 34.5175, 33.8639, 34.7323, 33.7496, 34.9663,
        29.7728, 43.6410, 33.4789, 32.4479], device='cuda:0')
signal_var = tensor([2.4021, 2.2460, 2.7084, 2.4223, 2.3282, 2.1684, 2.5345, 2.2810, 2.0322,
        2.3470, 2.4272, 2.1522, 2.1115, 2.1656, 2.1044, 2.1802, 1.8564, 2.7211,
        2.0875, 2.0232], device='cuda:0')
w_var = tensor([0.9565, 1.0264, 0.9872, 1.0052, 0.9981, 1.0092, 0.9909, 0.9752, 0.9946,
        0.9813, 1.0169, 0.9929, 1.0141, 0.9794, 1.0039, 1.0161, 0.9983, 1.0160,
        0.9835, 0.9999], device='cuda:0')
y_var = tensor([3.3799, 3.2736, 3.6995, 3.3959, 3.3417, 3.1610, 3.5599, 3.3025, 3.0436,
        3.3382, 3.3768, 3.0970, 3.1085, 3.1577, 3.1594, 3.2502, 2.8918, 3.7442,
        3.0515, 3.0281], device='cuda:0')
####cond finisihed #####
sum_betak_gammak = tensor([10.6835, 10.6835, 10.6835, 10.6835, 10.6835, 10.6835, 10.6835, 10.6835,
        10.6835, 10.6835, 10.6835, 10.6835, 10.6835, 10.6835, 10.6835, 10.6835,
        10.6835, 10.6835, 10.6835, 10.6835], device='cuda:0')
************
inv_Z_H_Z_k (shape: torch.Size([20, 32])) = tensor([[0.0240, 0.0373, 0.0310, 0.0413, 0.0233, 0.0296, 0.0371, 0.0383, 0.0285,
         0.0266, 0.0267, 0.0253, 0.0302, 0.0283, 0.0365, 0.0312, 0.0289, 0.0318,
         0.0323, 0.0328, 0.0321, 0.0369, 0.0347, 0.0280, 0.0379, 0.0419, 0.0342,
         0.0352, 0.0443, 0.0240, 0.0347, 0.0361],
        [0.0287, 0.0351, 0.0294, 0.0301, 0.0376, 0.0276, 0.0383, 0.0345, 0.0367,
         0.0415, 0.0419, 0.0520, 0.0443, 0.0375, 0.0353, 0.0556, 0.0301, 0.0248,
         0.0322, 0.0273, 0.0410, 0.0300, 0.0333, 0.0446, 0.0434, 0.0319, 0.0436,
         0.0336, 0.0380, 0.0363, 0.0299, 0.0311],
        [0.0344, 0.0341, 0.0273, 0.0303, 0.0343, 0.0278, 0.0304, 0.0251, 0.0343,
         0.0291, 0.0253, 0.0280, 0.0334, 0.0433, 0.0206, 0.0303, 0.0278, 0.0311,
         0.0335, 0.0304, 0.0456, 0.0352, 0.0336, 0.0284, 0.0334, 0.0345, 0.0347,
         0.0269, 0.0296, 0.0279, 0.0281, 0.0297],
        [0.0317, 0.0246, 0.0322, 0.0332, 0.0267, 0.0296, 0.0334, 0.0443, 0.0211,
         0.0277, 0.0304, 0.0304, 0.0371, 0.0311, 0.0305, 0.0259, 0.0332, 0.0282,
         0.0308, 0.0325, 0.0278, 0.0269, 0.0344, 0.0334, 0.0273, 0.0292, 0.0286,
         0.0395, 0.0215, 0.0327, 0.0389, 0.0253],
        [0.0343, 0.0286, 0.0337, 0.0432, 0.0254, 0.0221, 0.0299, 0.0340, 0.0401,
         0.0315, 0.0309, 0.0331, 0.0304, 0.0255, 0.0264, 0.0334, 0.0302, 0.0451,
         0.0255, 0.0312, 0.0324, 0.0241, 0.0273, 0.0251, 0.0360, 0.0295, 0.0369,
         0.0256, 0.0358, 0.0274, 0.0370, 0.0248],
        [0.0238, 0.0367, 0.0250, 0.0350, 0.0312, 0.0419, 0.0340, 0.0258, 0.0358,
         0.0328, 0.0310, 0.0342, 0.0365, 0.0247, 0.0409, 0.0296, 0.0409, 0.0271,
         0.0340, 0.0257, 0.0310, 0.0267, 0.0324, 0.0260, 0.0333, 0.0256, 0.0287,
         0.0267, 0.0272, 0.0265, 0.0359, 0.0279],
        [0.0551, 0.0224, 0.0323, 0.0268, 0.0241, 0.0339, 0.0311, 0.0239, 0.0334,
         0.0386, 0.0294, 0.0251, 0.0293, 0.0337, 0.0260, 0.0242, 0.0303, 0.0248,
         0.0319, 0.0416, 0.0317, 0.0339, 0.0287, 0.0297, 0.0390, 0.0290, 0.0355,
         0.0264, 0.0407, 0.0408, 0.0358, 0.0254],
        [0.0269, 0.0323, 0.0316, 0.0348, 0.0264, 0.0208, 0.0372, 0.0217, 0.0242,
         0.0318, 0.0249, 0.0280, 0.0312, 0.0450, 0.0347, 0.0408, 0.0287, 0.0276,
         0.0273, 0.0297, 0.0312, 0.0311, 0.0329, 0.0250, 0.0277, 0.0354, 0.0222,
         0.0346, 0.0317, 0.0315, 0.0430, 0.0334],
        [0.0364, 0.0294, 0.0296, 0.0252, 0.0475, 0.0309, 0.0329, 0.0342, 0.0335,
         0.0271, 0.0291, 0.0252, 0.0301, 0.0423, 0.0342, 0.0296, 0.0243, 0.0321,
         0.0306, 0.0230, 0.0276, 0.0311, 0.0287, 0.0365, 0.0266, 0.0240, 0.0359,
         0.0267, 0.0319, 0.0296, 0.0254, 0.0326],
        [0.0296, 0.0453, 0.0292, 0.0380, 0.0256, 0.0347, 0.0296, 0.0296, 0.0274,
         0.0341, 0.0373, 0.0308, 0.0370, 0.0300, 0.0348, 0.0307, 0.0301, 0.0349,
         0.0360, 0.0318, 0.0326, 0.0266, 0.0314, 0.0343, 0.0313, 0.0284, 0.0288,
         0.0208, 0.0318, 0.0336, 0.0330, 0.0247],
        [0.0349, 0.0325, 0.0232, 0.0225, 0.0355, 0.0268, 0.0278, 0.0306, 0.0276,
         0.0267, 0.0406, 0.0278, 0.0297, 0.0382, 0.0344, 0.0388, 0.0296, 0.0377,
         0.0279, 0.0299, 0.0318, 0.0280, 0.0280, 0.0223, 0.0295, 0.0247, 0.0273,
         0.0295, 0.0273, 0.0346, 0.0334, 0.0537],
        [0.0252, 0.0254, 0.0291, 0.0354, 0.0466, 0.0199, 0.0293, 0.0347, 0.0282,
         0.0284, 0.0457, 0.0330, 0.0417, 0.0306, 0.0288, 0.0379, 0.0264, 0.0280,
         0.0264, 0.0209, 0.0269, 0.0300, 0.0268, 0.0278, 0.0402, 0.0323, 0.0381,
         0.0352, 0.0285, 0.0330, 0.0301, 0.0381],
        [0.0252, 0.0258, 0.0226, 0.0286, 0.0240, 0.0294, 0.0366, 0.0259, 0.0416,
         0.0290, 0.0461, 0.0319, 0.0288, 0.0334, 0.0316, 0.0229, 0.0312, 0.0415,
         0.0407, 0.0436, 0.0260, 0.0288, 0.0284, 0.0345, 0.0315, 0.0422, 0.0557,
         0.0244, 0.0376, 0.0340, 0.0339, 0.0349],
        [0.0302, 0.0330, 0.0272, 0.0230, 0.0305, 0.0245, 0.0374, 0.0320, 0.0333,
         0.0261, 0.0345, 0.0293, 0.0301, 0.0311, 0.0257, 0.0359, 0.0357, 0.0363,
         0.0238, 0.0333, 0.0311, 0.0237, 0.0247, 0.0269, 0.0358, 0.0339, 0.0338,
         0.0303, 0.0237, 0.0265, 0.0332, 0.0273],
        [0.0297, 0.0234, 0.0343, 0.0296, 0.0350, 0.0306, 0.0321, 0.0276, 0.0323,
         0.0245, 0.0246, 0.0409, 0.0291, 0.0302, 0.0312, 0.0320, 0.0334, 0.0244,
         0.0332, 0.0368, 0.0318, 0.0354, 0.0339, 0.0393, 0.0295, 0.0238, 0.0302,
         0.0214, 0.0237, 0.0283, 0.0317, 0.0290],
        [0.0346, 0.0280, 0.0295, 0.0264, 0.0349, 0.0246, 0.0314, 0.0337, 0.0228,
         0.0294, 0.0290, 0.0276, 0.0344, 0.0231, 0.0231, 0.0418, 0.0252, 0.0292,
         0.0401, 0.0326, 0.0371, 0.0350, 0.0280, 0.0325, 0.0250, 0.0322, 0.0330,
         0.0288, 0.0313, 0.0274, 0.0302, 0.0251],
        [0.0298, 0.0238, 0.0307, 0.0273, 0.0338, 0.0365, 0.0322, 0.0299, 0.0274,
         0.0274, 0.0382, 0.0263, 0.0249, 0.0222, 0.0398, 0.0215, 0.0347, 0.0326,
         0.0375, 0.0357, 0.0323, 0.0295, 0.0327, 0.0318, 0.0380, 0.0381, 0.0246,
         0.0241, 0.0286, 0.0316, 0.0278, 0.0334],
        [0.0327, 0.0337, 0.0312, 0.0310, 0.0329, 0.0336, 0.0241, 0.0321, 0.0340,
         0.0361, 0.0304, 0.0315, 0.0256, 0.0291, 0.0303, 0.0280, 0.0248, 0.0290,
         0.0375, 0.0374, 0.0330, 0.0381, 0.0293, 0.0333, 0.0341, 0.0375, 0.0397,
         0.0245, 0.0228, 0.0401, 0.0362, 0.0408],
        [0.0341, 0.0290, 0.0370, 0.0307, 0.0276, 0.0354, 0.0333, 0.0394, 0.0372,
         0.0263, 0.0272, 0.0306, 0.0341, 0.0340, 0.0346, 0.0228, 0.0373, 0.0316,
         0.0341, 0.0227, 0.0285, 0.0270, 0.0305, 0.0355, 0.0263, 0.0421, 0.0303,
         0.0251, 0.0300, 0.0309, 0.0255, 0.0330],
        [0.0423, 0.0345, 0.0297, 0.0281, 0.0336, 0.0207, 0.0308, 0.0309, 0.0230,
         0.0340, 0.0262, 0.0320, 0.0233, 0.0237, 0.0262, 0.0310, 0.0288, 0.0326,
         0.0377, 0.0243, 0.0270, 0.0259, 0.0222, 0.0328, 0.0272, 0.0273, 0.0254,
         0.0316, 0.0313, 0.0217, 0.0324, 0.0348]], device='cuda:0')
inv_Z_H_Z_k.mean (expected to be = 0.03124999990234375) = 0.031373023986816406
Var (shape: torch.Size([20, 32])) = tensor([[0.0399, 0.0621, 0.0517, 0.0688, 0.0388, 0.0492, 0.0618, 0.0639, 0.0476,
         0.0444, 0.0445, 0.0422, 0.0502, 0.0472, 0.0608, 0.0519, 0.0482, 0.0530,
         0.0538, 0.0546, 0.0535, 0.0615, 0.0578, 0.0467, 0.0632, 0.0698, 0.0570,
         0.0587, 0.0739, 0.0400, 0.0578, 0.0601],
        [0.0478, 0.0585, 0.0491, 0.0501, 0.0626, 0.0460, 0.0638, 0.0575, 0.0612,
         0.0691, 0.0699, 0.0866, 0.0739, 0.0625, 0.0589, 0.0926, 0.0501, 0.0414,
         0.0536, 0.0455, 0.0683, 0.0500, 0.0554, 0.0743, 0.0723, 0.0532, 0.0726,
         0.0559, 0.0632, 0.0605, 0.0498, 0.0519],
        [0.0574, 0.0567, 0.0454, 0.0504, 0.0572, 0.0463, 0.0506, 0.0419, 0.0571,
         0.0485, 0.0421, 0.0467, 0.0557, 0.0722, 0.0344, 0.0504, 0.0464, 0.0518,
         0.0559, 0.0507, 0.0759, 0.0586, 0.0560, 0.0474, 0.0557, 0.0574, 0.0578,
         0.0447, 0.0493, 0.0464, 0.0469, 0.0495],
        [0.0527, 0.0410, 0.0536, 0.0553, 0.0445, 0.0494, 0.0557, 0.0738, 0.0352,
         0.0461, 0.0506, 0.0506, 0.0618, 0.0519, 0.0507, 0.0432, 0.0553, 0.0469,
         0.0514, 0.0541, 0.0463, 0.0449, 0.0574, 0.0556, 0.0454, 0.0486, 0.0476,
         0.0659, 0.0359, 0.0545, 0.0648, 0.0421],
        [0.0572, 0.0476, 0.0561, 0.0720, 0.0423, 0.0368, 0.0498, 0.0566, 0.0669,
         0.0525, 0.0516, 0.0551, 0.0507, 0.0425, 0.0440, 0.0556, 0.0504, 0.0751,
         0.0424, 0.0520, 0.0540, 0.0402, 0.0456, 0.0419, 0.0599, 0.0491, 0.0616,
         0.0426, 0.0596, 0.0457, 0.0617, 0.0413],
        [0.0396, 0.0612, 0.0417, 0.0583, 0.0519, 0.0697, 0.0566, 0.0430, 0.0597,
         0.0547, 0.0516, 0.0569, 0.0607, 0.0411, 0.0681, 0.0493, 0.0681, 0.0452,
         0.0566, 0.0428, 0.0516, 0.0445, 0.0540, 0.0434, 0.0554, 0.0427, 0.0478,
         0.0445, 0.0453, 0.0442, 0.0597, 0.0464],
        [0.0917, 0.0373, 0.0538, 0.0446, 0.0402, 0.0566, 0.0518, 0.0399, 0.0557,
         0.0643, 0.0489, 0.0419, 0.0488, 0.0562, 0.0434, 0.0403, 0.0505, 0.0414,
         0.0532, 0.0694, 0.0528, 0.0564, 0.0478, 0.0495, 0.0650, 0.0483, 0.0592,
         0.0440, 0.0678, 0.0679, 0.0597, 0.0424],
        [0.0448, 0.0538, 0.0526, 0.0580, 0.0440, 0.0346, 0.0620, 0.0362, 0.0403,
         0.0530, 0.0415, 0.0466, 0.0520, 0.0750, 0.0578, 0.0680, 0.0477, 0.0460,
         0.0454, 0.0496, 0.0520, 0.0519, 0.0548, 0.0417, 0.0461, 0.0590, 0.0370,
         0.0576, 0.0529, 0.0525, 0.0716, 0.0556],
        [0.0606, 0.0490, 0.0493, 0.0420, 0.0792, 0.0516, 0.0548, 0.0570, 0.0558,
         0.0452, 0.0486, 0.0419, 0.0501, 0.0705, 0.0570, 0.0493, 0.0405, 0.0535,
         0.0510, 0.0383, 0.0459, 0.0519, 0.0479, 0.0609, 0.0443, 0.0399, 0.0598,
         0.0446, 0.0531, 0.0494, 0.0423, 0.0543],
        [0.0494, 0.0755, 0.0487, 0.0633, 0.0427, 0.0578, 0.0493, 0.0493, 0.0457,
         0.0568, 0.0622, 0.0514, 0.0616, 0.0500, 0.0580, 0.0511, 0.0501, 0.0582,
         0.0600, 0.0530, 0.0544, 0.0443, 0.0523, 0.0572, 0.0521, 0.0473, 0.0479,
         0.0347, 0.0530, 0.0560, 0.0549, 0.0411],
        [0.0581, 0.0542, 0.0386, 0.0375, 0.0592, 0.0446, 0.0464, 0.0510, 0.0459,
         0.0445, 0.0676, 0.0464, 0.0495, 0.0636, 0.0573, 0.0646, 0.0493, 0.0629,
         0.0465, 0.0498, 0.0531, 0.0466, 0.0467, 0.0371, 0.0492, 0.0411, 0.0455,
         0.0492, 0.0455, 0.0576, 0.0556, 0.0895],
        [0.0420, 0.0424, 0.0485, 0.0590, 0.0776, 0.0332, 0.0488, 0.0578, 0.0470,
         0.0472, 0.0762, 0.0550, 0.0695, 0.0509, 0.0480, 0.0632, 0.0440, 0.0466,
         0.0439, 0.0348, 0.0447, 0.0499, 0.0447, 0.0463, 0.0670, 0.0537, 0.0635,
         0.0586, 0.0475, 0.0550, 0.0501, 0.0635],
        [0.0420, 0.0429, 0.0377, 0.0476, 0.0400, 0.0490, 0.0610, 0.0432, 0.0693,
         0.0482, 0.0768, 0.0532, 0.0480, 0.0556, 0.0526, 0.0382, 0.0519, 0.0692,
         0.0678, 0.0726, 0.0434, 0.0480, 0.0474, 0.0575, 0.0525, 0.0703, 0.0928,
         0.0407, 0.0626, 0.0566, 0.0565, 0.0582],
        [0.0503, 0.0550, 0.0453, 0.0383, 0.0509, 0.0408, 0.0623, 0.0533, 0.0555,
         0.0434, 0.0575, 0.0487, 0.0501, 0.0519, 0.0428, 0.0598, 0.0595, 0.0605,
         0.0396, 0.0555, 0.0518, 0.0394, 0.0412, 0.0447, 0.0597, 0.0565, 0.0563,
         0.0505, 0.0395, 0.0441, 0.0553, 0.0454],
        [0.0494, 0.0390, 0.0572, 0.0494, 0.0584, 0.0510, 0.0535, 0.0460, 0.0539,
         0.0409, 0.0410, 0.0681, 0.0484, 0.0502, 0.0519, 0.0532, 0.0556, 0.0406,
         0.0553, 0.0614, 0.0529, 0.0589, 0.0565, 0.0656, 0.0492, 0.0397, 0.0504,
         0.0356, 0.0395, 0.0472, 0.0528, 0.0483],
        [0.0577, 0.0466, 0.0491, 0.0440, 0.0581, 0.0409, 0.0523, 0.0562, 0.0380,
         0.0490, 0.0483, 0.0461, 0.0572, 0.0385, 0.0384, 0.0696, 0.0421, 0.0487,
         0.0668, 0.0544, 0.0617, 0.0584, 0.0467, 0.0541, 0.0416, 0.0536, 0.0549,
         0.0479, 0.0521, 0.0456, 0.0502, 0.0419],
        [0.0497, 0.0397, 0.0512, 0.0454, 0.0564, 0.0608, 0.0536, 0.0498, 0.0457,
         0.0457, 0.0637, 0.0438, 0.0415, 0.0370, 0.0664, 0.0358, 0.0578, 0.0543,
         0.0625, 0.0595, 0.0538, 0.0491, 0.0544, 0.0530, 0.0634, 0.0635, 0.0410,
         0.0402, 0.0476, 0.0527, 0.0464, 0.0556],
        [0.0545, 0.0562, 0.0521, 0.0517, 0.0548, 0.0560, 0.0402, 0.0535, 0.0567,
         0.0602, 0.0507, 0.0526, 0.0427, 0.0485, 0.0505, 0.0467, 0.0414, 0.0482,
         0.0624, 0.0622, 0.0549, 0.0635, 0.0488, 0.0554, 0.0568, 0.0625, 0.0661,
         0.0408, 0.0380, 0.0668, 0.0603, 0.0680],
        [0.0567, 0.0483, 0.0617, 0.0512, 0.0460, 0.0589, 0.0555, 0.0657, 0.0620,
         0.0439, 0.0453, 0.0510, 0.0568, 0.0567, 0.0577, 0.0380, 0.0622, 0.0526,
         0.0568, 0.0379, 0.0474, 0.0450, 0.0508, 0.0591, 0.0438, 0.0701, 0.0504,
         0.0419, 0.0500, 0.0515, 0.0426, 0.0550],
        [0.0705, 0.0575, 0.0495, 0.0468, 0.0560, 0.0345, 0.0513, 0.0515, 0.0384,
         0.0566, 0.0437, 0.0534, 0.0388, 0.0395, 0.0436, 0.0517, 0.0479, 0.0542,
         0.0629, 0.0406, 0.0451, 0.0431, 0.0370, 0.0547, 0.0453, 0.0455, 0.0423,
         0.0526, 0.0522, 0.0362, 0.0539, 0.0579]], device='cuda:0')
***********
SINR = tensor([-1.0365, -1.4631, -0.8757, -0.7851, -0.8368, -0.8459, -0.8725, -0.7727,
        -0.8018, -0.9531, -0.8056, -0.8495, -0.9977, -0.7288, -0.7592, -0.7318,
        -0.7967, -1.0285, -0.8985, -0.5595], device='cuda:0')
Real_SINR = tensor([-0.4241, -2.3001, -1.0866, -0.9929, -1.3647, -1.3962, -0.7824, -0.8624,
        -0.7269, -0.7536, -1.0851, -1.6321, -1.5964, -0.5440, -0.5283, -0.7599,
        -1.1993, -1.7682, -1.3216, -0.6006], device='cuda:0')
Real_SINR_noise.shape = torch.Size([20])
ldm/modules/diffusionmodules/util.py, make_ddim_timsteps ddim_discr_method = uniform
ldm/modules/diffusionmodules/util.py, make_ddim_timsteps, Selected timesteps for ddim sampler: (200,)
ldm/modules/diffusionmodules/util.py, make_ddim_sampling_parameters, Selected alphas for ddim sampler: a_t: torch.Size([200]); a_(t-1): (200,)
For the chosen value of eta, which is 0.0, this results in the following sigma_t schedule for ddim sampler tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], dtype=torch.float64)
ddim.py alphas_cumprod = torch.Size([1000])
ddim.py, alpha_bar_u = tensor([0.4406, 0.4166, 0.4498, 0.4549, 0.4520, 0.4515, 0.4499, 0.4556, 0.4540,
        0.4454, 0.4538, 0.4513, 0.4428, 0.4581, 0.4564, 0.4580, 0.4543, 0.4411,
        0.4485, 0.4678], device='cuda:0')
ddim.py start_timesteps after clamp S = 200 : tensor([390, 405, 385, 382, 383, 384, 385, 381, 382, 388, 382, 384, 389, 380,
        381, 380, 382, 390, 386, 374], device='cuda:0')
d = torch.Size([20, 4, 32, 32])
recoverd_img = torch.Size([20, 3, 256, 256])
20 images are saved in outputs/MIMOdiffusion/M=64/K=32/dynamic/
20 images are saved in outputs/MIMOdiffusion/M=64/K=32/nonoisenosample/
--------SNR = 4,  rho_ul = 0.07849645098467438-----------
G_variance = tensor([0.9888, 1.0342, 0.9622, 1.0124, 0.9942, 0.9765, 1.0053, 1.0194, 1.0056,
        0.9645, 0.9826, 0.9971, 1.0231, 0.9683, 0.9869, 1.0122, 1.0098, 1.0207,
        1.0515, 0.9525], device='cuda:0')
G_hat_variance = tensor([0.6887, 0.7275, 0.6917, 0.7218, 0.7137, 0.6975, 0.7048, 0.7027, 0.7244,
        0.7054, 0.7218, 0.7012, 0.7376, 0.6989, 0.7057, 0.7011, 0.7234, 0.7295,
        0.7389, 0.6819], device='cuda:0')
G_tilde_var = tensor([0.2897, 0.2945, 0.2752, 0.2914, 0.2810, 0.2892, 0.2930, 0.2838, 0.2775,
        0.2790, 0.2833, 0.2899, 0.2815, 0.2853, 0.2889, 0.2911, 0.2818, 0.2917,
        0.2976, 0.2805], device='cuda:0')
gamma = tensor([[[0.7153, 0.7153, 0.7153, 0.7153, 0.7153, 0.7153, 0.7153, 0.7153,
          0.7153, 0.7153, 0.7153, 0.7153, 0.7153, 0.7153, 0.7153, 0.7153,
          0.7153, 0.7153, 0.7153, 0.7153, 0.7153, 0.7153, 0.7153, 0.7153,
          0.7153, 0.7153, 0.7153, 0.7153, 0.7153, 0.7153, 0.7153, 0.7153]]],
       device='cuda:0')
Z_mean = tensor([-0.0018+0.0220j, -0.0227-0.0237j, -0.0018+0.0005j, -0.0154+0.0129j,
         0.0055-0.0106j, -0.0019-0.0254j, -0.0146-0.0190j,  0.0028+0.0091j,
        -0.0087-0.0148j,  0.0066+0.0218j, -0.0032-0.0133j, -0.0121-0.0296j,
        -0.0031+0.0111j, -0.0079-0.0032j, -0.0109-0.0406j, -0.0051-0.0028j,
         0.0187-0.0088j,  0.0159-0.0118j, -0.0264+0.0209j, -0.0003-0.0026j],
       device='cuda:0')
Z_variance ~CN(0, 1)= tensor([0.9629, 1.0171, 0.9671, 1.0091, 0.9978, 0.9751, 0.9854, 0.9825, 1.0128,
        0.9862, 1.0092, 0.9804, 1.0313, 0.9772, 0.9867, 0.9802, 1.0114, 1.0200,
        1.0331, 0.9534], device='cuda:0')
Real_SNR = tensor([4.2373, 5.0402, 5.5236, 4.7937, 4.1844, 4.5015, 3.8591, 4.9816, 4.2894,
        3.7783, 4.0994, 4.1676, 5.0283, 4.9421, 4.7668, 3.3746, 4.4624, 4.6536,
        4.4137, 4.0243], device='cuda:0')
q_var = tensor([1.0001, 1.0002, 1.0002, 1.0002, 0.9999, 1.0002, 1.0000, 1.0002, 0.9999,
        1.0002, 1.0002, 1.0000, 1.0000, 0.9986, 1.0002, 0.9998, 1.0002, 1.0002,
        1.0002, 0.9989], device='cuda:0')
(D_eta_sqrt @ q).var = tensor([1.0001, 1.0002, 1.0002, 1.0002, 0.9999, 1.0002, 1.0000, 1.0002, 0.9999,
        1.0002, 1.0002, 1.0000, 1.0000, 0.9986, 1.0002, 0.9998, 1.0002, 1.0002,
        1.0002, 0.9989], device='cuda:0')
(G @ (D_eta_sqrt @ q)).var = tensor([34.0571, 40.8582, 44.5515, 38.0675, 34.3079, 36.3876, 30.1870, 40.8803,
        34.1241, 30.9848, 32.5122, 33.2532, 39.8644, 40.0102, 37.4329, 28.2445,
        36.4006, 37.2816, 35.0663, 31.1114], device='cuda:0')
signal_var = tensor([2.6734, 3.2072, 3.4971, 2.9882, 2.6930, 2.8563, 2.3696, 3.2090, 2.6786,
        2.4322, 2.5521, 2.6103, 3.1292, 3.1407, 2.9383, 2.2171, 2.8573, 2.9265,
        2.7526, 2.4421], device='cuda:0')
w_var = tensor([1.0077, 1.0049, 0.9803, 0.9909, 1.0276, 1.0131, 0.9744, 1.0191, 0.9976,
        1.0190, 0.9930, 0.9998, 0.9831, 1.0065, 0.9805, 1.0194, 1.0226, 1.0023,
        0.9962, 0.9668], device='cuda:0')
y_var = tensor([3.6570, 4.1767, 4.4224, 3.9751, 3.6679, 3.8339, 3.3590, 4.1958, 3.7137,
        3.4005, 3.5929, 3.6312, 4.0208, 4.1774, 3.8790, 3.1944, 3.8930, 3.9654,
        3.7383, 3.4349], device='cuda:0')
####cond finisihed #####
sum_betak_gammak = tensor([9.1119, 9.1119, 9.1119, 9.1119, 9.1119, 9.1119, 9.1119, 9.1119, 9.1119,
        9.1119, 9.1119, 9.1119, 9.1119, 9.1119, 9.1119, 9.1119, 9.1119, 9.1119,
        9.1119, 9.1119], device='cuda:0')
************
inv_Z_H_Z_k (shape: torch.Size([20, 32])) = tensor([[0.0375, 0.0293, 0.0290, 0.0404, 0.0279, 0.0310, 0.0314, 0.0374, 0.0323,
         0.0408, 0.0297, 0.0433, 0.0357, 0.0320, 0.0339, 0.0264, 0.0271, 0.0311,
         0.0297, 0.0487, 0.0353, 0.0246, 0.0394, 0.0370, 0.0332, 0.0289, 0.0409,
         0.0298, 0.0274, 0.0393, 0.0281, 0.0305],
        [0.0285, 0.0289, 0.0314, 0.0278, 0.0384, 0.0270, 0.0330, 0.0296, 0.0324,
         0.0420, 0.0256, 0.0246, 0.0252, 0.0272, 0.0227, 0.0400, 0.0312, 0.0264,
         0.0330, 0.0367, 0.0274, 0.0299, 0.0282, 0.0341, 0.0240, 0.0287, 0.0381,
         0.0274, 0.0333, 0.0341, 0.0281, 0.0222],
        [0.0296, 0.0320, 0.0248, 0.0278, 0.0279, 0.0311, 0.0317, 0.0330, 0.0254,
         0.0524, 0.0380, 0.0357, 0.0355, 0.0248, 0.0263, 0.0270, 0.0264, 0.0336,
         0.0310, 0.0298, 0.0322, 0.0280, 0.0264, 0.0249, 0.0282, 0.0225, 0.0287,
         0.0238, 0.0361, 0.0244, 0.0333, 0.0288],
        [0.0276, 0.0270, 0.0294, 0.0361, 0.0441, 0.0307, 0.0247, 0.0301, 0.0379,
         0.0311, 0.0488, 0.0237, 0.0272, 0.0342, 0.0243, 0.0268, 0.0306, 0.0320,
         0.0298, 0.0251, 0.0281, 0.0278, 0.0270, 0.0234, 0.0302, 0.0409, 0.0251,
         0.0311, 0.0264, 0.0353, 0.0278, 0.0254],
        [0.0369, 0.0324, 0.0299, 0.0248, 0.0296, 0.0375, 0.0333, 0.0358, 0.0289,
         0.0247, 0.0287, 0.0239, 0.0281, 0.0375, 0.0334, 0.0339, 0.0410, 0.0337,
         0.0309, 0.0282, 0.0287, 0.0286, 0.0392, 0.0291, 0.0333, 0.0340, 0.0228,
         0.0295, 0.0184, 0.0339, 0.0306, 0.0330],
        [0.0300, 0.0251, 0.0369, 0.0362, 0.0305, 0.0240, 0.0328, 0.0254, 0.0318,
         0.0259, 0.0361, 0.0457, 0.0196, 0.0320, 0.0285, 0.0338, 0.0356, 0.0287,
         0.0272, 0.0283, 0.0305, 0.0229, 0.0273, 0.0317, 0.0362, 0.0348, 0.0255,
         0.0278, 0.0243, 0.0281, 0.0321, 0.0269],
        [0.0259, 0.0350, 0.0261, 0.0276, 0.0359, 0.0297, 0.0317, 0.0347, 0.0280,
         0.0301, 0.0290, 0.0373, 0.0380, 0.0357, 0.0212, 0.0237, 0.0346, 0.0222,
         0.0263, 0.0298, 0.0328, 0.0322, 0.0341, 0.0308, 0.0332, 0.0328, 0.0320,
         0.0252, 0.0250, 0.0318, 0.0337, 0.0232],
        [0.0281, 0.0287, 0.0276, 0.0210, 0.0311, 0.0299, 0.0262, 0.0503, 0.0472,
         0.0479, 0.0382, 0.0282, 0.0369, 0.0281, 0.0257, 0.0287, 0.0348, 0.0307,
         0.0271, 0.0299, 0.0452, 0.0287, 0.0316, 0.0355, 0.0422, 0.0313, 0.0305,
         0.0276, 0.0404, 0.0296, 0.0287, 0.0519],
        [0.0301, 0.0340, 0.0255, 0.0368, 0.0280, 0.0304, 0.0276, 0.0283, 0.0239,
         0.0342, 0.0374, 0.0449, 0.0270, 0.0249, 0.0311, 0.0330, 0.0423, 0.0332,
         0.0365, 0.0267, 0.0422, 0.0298, 0.0387, 0.0271, 0.0354, 0.0417, 0.0311,
         0.0291, 0.0344, 0.0380, 0.0292, 0.0279],
        [0.0272, 0.0220, 0.0329, 0.0408, 0.0290, 0.0349, 0.0240, 0.0308, 0.0265,
         0.0311, 0.0365, 0.0261, 0.0468, 0.0262, 0.0291, 0.0273, 0.0330, 0.0323,
         0.0304, 0.0322, 0.0285, 0.0297, 0.0400, 0.0288, 0.0323, 0.0304, 0.0283,
         0.0255, 0.0337, 0.0299, 0.0388, 0.0263],
        [0.0271, 0.0311, 0.0252, 0.0302, 0.0376, 0.0376, 0.0321, 0.0290, 0.0275,
         0.0258, 0.0342, 0.0292, 0.0343, 0.0268, 0.0295, 0.0234, 0.0299, 0.0300,
         0.0285, 0.0307, 0.0238, 0.0215, 0.0305, 0.0272, 0.0393, 0.0371, 0.0254,
         0.0239, 0.0262, 0.0237, 0.0293, 0.0236],
        [0.0289, 0.0366, 0.0293, 0.0371, 0.0300, 0.0340, 0.0439, 0.0264, 0.0325,
         0.0340, 0.0233, 0.0361, 0.0307, 0.0312, 0.0407, 0.0289, 0.0223, 0.0321,
         0.0236, 0.0361, 0.0200, 0.0287, 0.0359, 0.0203, 0.0251, 0.0301, 0.0306,
         0.0279, 0.0283, 0.0314, 0.0384, 0.0217],
        [0.0354, 0.0300, 0.0343, 0.0302, 0.0382, 0.0323, 0.0402, 0.0366, 0.0340,
         0.0359, 0.0365, 0.0337, 0.0260, 0.0323, 0.0265, 0.0294, 0.0361, 0.0341,
         0.0243, 0.0348, 0.0421, 0.0286, 0.0297, 0.0372, 0.0396, 0.0305, 0.0280,
         0.0320, 0.0359, 0.0341, 0.0254, 0.0354],
        [0.0296, 0.0421, 0.0300, 0.0407, 0.0320, 0.0223, 0.0289, 0.0414, 0.0297,
         0.0272, 0.0408, 0.0313, 0.0314, 0.0270, 0.0287, 0.0255, 0.0421, 0.0279,
         0.0368, 0.0347, 0.0458, 0.0256, 0.0284, 0.0268, 0.0249, 0.0335, 0.0335,
         0.0308, 0.0325, 0.0288, 0.0351, 0.0475],
        [0.0270, 0.0284, 0.0277, 0.0329, 0.0389, 0.0373, 0.0439, 0.0334, 0.0258,
         0.0266, 0.0464, 0.0311, 0.0287, 0.0324, 0.0348, 0.0255, 0.0227, 0.0385,
         0.0287, 0.0333, 0.0277, 0.0351, 0.0328, 0.0273, 0.0327, 0.0248, 0.0261,
         0.0359, 0.0316, 0.0301, 0.0293, 0.0276],
        [0.0257, 0.0340, 0.0332, 0.0242, 0.0304, 0.0283, 0.0309, 0.0372, 0.0250,
         0.0402, 0.0349, 0.0339, 0.0293, 0.0233, 0.0382, 0.0292, 0.0284, 0.0342,
         0.0287, 0.0264, 0.0325, 0.0357, 0.0248, 0.0343, 0.0276, 0.0354, 0.0381,
         0.0419, 0.0293, 0.0335, 0.0392, 0.0345],
        [0.0333, 0.0356, 0.0296, 0.0289, 0.0287, 0.0328, 0.0295, 0.0305, 0.0316,
         0.0254, 0.0223, 0.0337, 0.0291, 0.0292, 0.0324, 0.0270, 0.0254, 0.0282,
         0.0295, 0.0260, 0.0270, 0.0305, 0.0330, 0.0252, 0.0239, 0.0297, 0.0321,
         0.0347, 0.0328, 0.0389, 0.0371, 0.0341],
        [0.0299, 0.0273, 0.0238, 0.0276, 0.0316, 0.0414, 0.0284, 0.0319, 0.0270,
         0.0282, 0.0301, 0.0397, 0.0288, 0.0291, 0.0291, 0.0337, 0.0503, 0.0293,
         0.0327, 0.0325, 0.0347, 0.0335, 0.0364, 0.0379, 0.0285, 0.0290, 0.0301,
         0.0345, 0.0307, 0.0268, 0.0337, 0.0284],
        [0.0297, 0.0266, 0.0393, 0.0248, 0.0260, 0.0269, 0.0341, 0.0278, 0.0240,
         0.0422, 0.0342, 0.0263, 0.0372, 0.0414, 0.0258, 0.0223, 0.0234, 0.0220,
         0.0258, 0.0338, 0.0365, 0.0267, 0.0231, 0.0231, 0.0255, 0.0348, 0.0289,
         0.0286, 0.0276, 0.0233, 0.0299, 0.0216],
        [0.0368, 0.0306, 0.0424, 0.0325, 0.0311, 0.0307, 0.0298, 0.0388, 0.0280,
         0.0337, 0.0346, 0.0238, 0.0268, 0.0321, 0.0254, 0.0310, 0.0285, 0.0327,
         0.0333, 0.0353, 0.0362, 0.0375, 0.0400, 0.0357, 0.0321, 0.0323, 0.0261,
         0.0257, 0.0294, 0.0278, 0.0422, 0.0368]], device='cuda:0')
inv_Z_H_Z_k.mean (expected to be = 0.03124999990234375) = 0.03121822513639927
Var (shape: torch.Size([20, 32])) = tensor([[0.0643, 0.0502, 0.0497, 0.0693, 0.0478, 0.0532, 0.0539, 0.0641, 0.0554,
         0.0701, 0.0509, 0.0743, 0.0613, 0.0549, 0.0582, 0.0454, 0.0465, 0.0533,
         0.0509, 0.0836, 0.0605, 0.0423, 0.0676, 0.0635, 0.0570, 0.0495, 0.0701,
         0.0511, 0.0470, 0.0674, 0.0482, 0.0523],
        [0.0489, 0.0496, 0.0538, 0.0477, 0.0659, 0.0462, 0.0567, 0.0508, 0.0555,
         0.0721, 0.0439, 0.0422, 0.0432, 0.0467, 0.0390, 0.0685, 0.0536, 0.0453,
         0.0567, 0.0629, 0.0471, 0.0513, 0.0484, 0.0584, 0.0411, 0.0493, 0.0654,
         0.0470, 0.0572, 0.0584, 0.0482, 0.0381],
        [0.0508, 0.0549, 0.0426, 0.0477, 0.0479, 0.0533, 0.0543, 0.0566, 0.0436,
         0.0898, 0.0651, 0.0613, 0.0610, 0.0426, 0.0450, 0.0463, 0.0452, 0.0577,
         0.0532, 0.0511, 0.0552, 0.0481, 0.0453, 0.0427, 0.0484, 0.0386, 0.0492,
         0.0409, 0.0620, 0.0418, 0.0571, 0.0494],
        [0.0474, 0.0463, 0.0504, 0.0620, 0.0756, 0.0526, 0.0423, 0.0516, 0.0650,
         0.0534, 0.0837, 0.0406, 0.0466, 0.0587, 0.0416, 0.0459, 0.0525, 0.0549,
         0.0511, 0.0431, 0.0483, 0.0477, 0.0464, 0.0401, 0.0518, 0.0702, 0.0431,
         0.0533, 0.0454, 0.0605, 0.0477, 0.0436],
        [0.0633, 0.0555, 0.0513, 0.0426, 0.0507, 0.0644, 0.0570, 0.0613, 0.0496,
         0.0424, 0.0492, 0.0410, 0.0482, 0.0642, 0.0573, 0.0582, 0.0703, 0.0577,
         0.0530, 0.0483, 0.0492, 0.0491, 0.0673, 0.0498, 0.0572, 0.0584, 0.0391,
         0.0505, 0.0315, 0.0581, 0.0524, 0.0565],
        [0.0515, 0.0431, 0.0632, 0.0621, 0.0524, 0.0411, 0.0563, 0.0436, 0.0545,
         0.0444, 0.0619, 0.0783, 0.0336, 0.0549, 0.0489, 0.0580, 0.0611, 0.0492,
         0.0466, 0.0486, 0.0524, 0.0393, 0.0467, 0.0545, 0.0622, 0.0596, 0.0437,
         0.0477, 0.0417, 0.0483, 0.0551, 0.0462],
        [0.0445, 0.0600, 0.0448, 0.0473, 0.0616, 0.0510, 0.0544, 0.0596, 0.0480,
         0.0517, 0.0497, 0.0641, 0.0652, 0.0613, 0.0364, 0.0406, 0.0594, 0.0381,
         0.0452, 0.0511, 0.0562, 0.0552, 0.0585, 0.0529, 0.0569, 0.0562, 0.0550,
         0.0432, 0.0429, 0.0546, 0.0579, 0.0398],
        [0.0482, 0.0492, 0.0474, 0.0359, 0.0534, 0.0512, 0.0449, 0.0863, 0.0809,
         0.0822, 0.0656, 0.0484, 0.0632, 0.0482, 0.0440, 0.0493, 0.0597, 0.0526,
         0.0465, 0.0513, 0.0776, 0.0493, 0.0541, 0.0609, 0.0724, 0.0537, 0.0523,
         0.0474, 0.0692, 0.0507, 0.0492, 0.0890],
        [0.0516, 0.0583, 0.0438, 0.0631, 0.0481, 0.0522, 0.0473, 0.0485, 0.0410,
         0.0587, 0.0641, 0.0770, 0.0463, 0.0428, 0.0533, 0.0567, 0.0725, 0.0570,
         0.0626, 0.0458, 0.0723, 0.0511, 0.0664, 0.0465, 0.0607, 0.0715, 0.0534,
         0.0499, 0.0590, 0.0651, 0.0502, 0.0479],
        [0.0467, 0.0377, 0.0565, 0.0700, 0.0497, 0.0599, 0.0411, 0.0528, 0.0455,
         0.0533, 0.0625, 0.0448, 0.0802, 0.0450, 0.0500, 0.0468, 0.0566, 0.0554,
         0.0521, 0.0553, 0.0489, 0.0509, 0.0687, 0.0494, 0.0554, 0.0522, 0.0486,
         0.0438, 0.0579, 0.0513, 0.0665, 0.0451],
        [0.0465, 0.0534, 0.0432, 0.0518, 0.0644, 0.0645, 0.0550, 0.0498, 0.0471,
         0.0443, 0.0586, 0.0502, 0.0589, 0.0460, 0.0507, 0.0402, 0.0512, 0.0515,
         0.0488, 0.0527, 0.0408, 0.0369, 0.0523, 0.0466, 0.0674, 0.0636, 0.0435,
         0.0409, 0.0449, 0.0407, 0.0502, 0.0404],
        [0.0496, 0.0628, 0.0503, 0.0637, 0.0515, 0.0583, 0.0753, 0.0453, 0.0557,
         0.0582, 0.0400, 0.0619, 0.0526, 0.0535, 0.0699, 0.0496, 0.0383, 0.0551,
         0.0405, 0.0620, 0.0343, 0.0492, 0.0615, 0.0348, 0.0430, 0.0516, 0.0524,
         0.0479, 0.0485, 0.0539, 0.0659, 0.0373],
        [0.0607, 0.0514, 0.0587, 0.0518, 0.0655, 0.0553, 0.0689, 0.0628, 0.0584,
         0.0615, 0.0625, 0.0578, 0.0447, 0.0555, 0.0455, 0.0505, 0.0619, 0.0585,
         0.0417, 0.0597, 0.0722, 0.0491, 0.0510, 0.0638, 0.0680, 0.0523, 0.0481,
         0.0549, 0.0616, 0.0584, 0.0436, 0.0607],
        [0.0508, 0.0722, 0.0515, 0.0698, 0.0549, 0.0382, 0.0496, 0.0710, 0.0510,
         0.0467, 0.0699, 0.0537, 0.0539, 0.0464, 0.0493, 0.0438, 0.0722, 0.0478,
         0.0632, 0.0596, 0.0785, 0.0438, 0.0487, 0.0460, 0.0427, 0.0575, 0.0575,
         0.0528, 0.0558, 0.0493, 0.0602, 0.0815],
        [0.0463, 0.0488, 0.0475, 0.0565, 0.0667, 0.0640, 0.0753, 0.0573, 0.0442,
         0.0456, 0.0795, 0.0533, 0.0492, 0.0555, 0.0597, 0.0437, 0.0390, 0.0660,
         0.0492, 0.0571, 0.0474, 0.0602, 0.0563, 0.0469, 0.0560, 0.0425, 0.0448,
         0.0617, 0.0543, 0.0516, 0.0502, 0.0474],
        [0.0440, 0.0583, 0.0570, 0.0415, 0.0522, 0.0486, 0.0530, 0.0639, 0.0430,
         0.0689, 0.0599, 0.0581, 0.0502, 0.0400, 0.0655, 0.0501, 0.0488, 0.0586,
         0.0493, 0.0454, 0.0557, 0.0612, 0.0426, 0.0589, 0.0474, 0.0608, 0.0654,
         0.0718, 0.0503, 0.0574, 0.0673, 0.0592],
        [0.0571, 0.0611, 0.0508, 0.0495, 0.0493, 0.0563, 0.0506, 0.0523, 0.0543,
         0.0435, 0.0382, 0.0578, 0.0500, 0.0501, 0.0556, 0.0464, 0.0436, 0.0484,
         0.0506, 0.0445, 0.0463, 0.0523, 0.0566, 0.0433, 0.0410, 0.0509, 0.0551,
         0.0594, 0.0562, 0.0667, 0.0637, 0.0584],
        [0.0513, 0.0467, 0.0408, 0.0474, 0.0542, 0.0710, 0.0486, 0.0546, 0.0463,
         0.0484, 0.0516, 0.0680, 0.0495, 0.0500, 0.0500, 0.0579, 0.0863, 0.0503,
         0.0561, 0.0558, 0.0595, 0.0574, 0.0625, 0.0650, 0.0489, 0.0497, 0.0517,
         0.0592, 0.0526, 0.0461, 0.0579, 0.0486],
        [0.0509, 0.0457, 0.0674, 0.0425, 0.0446, 0.0461, 0.0585, 0.0477, 0.0412,
         0.0723, 0.0587, 0.0451, 0.0638, 0.0710, 0.0442, 0.0382, 0.0401, 0.0377,
         0.0442, 0.0579, 0.0626, 0.0458, 0.0395, 0.0397, 0.0438, 0.0597, 0.0496,
         0.0491, 0.0474, 0.0400, 0.0513, 0.0371],
        [0.0631, 0.0525, 0.0727, 0.0558, 0.0534, 0.0526, 0.0511, 0.0666, 0.0481,
         0.0578, 0.0593, 0.0409, 0.0460, 0.0550, 0.0435, 0.0532, 0.0488, 0.0560,
         0.0572, 0.0605, 0.0621, 0.0644, 0.0686, 0.0612, 0.0551, 0.0554, 0.0448,
         0.0441, 0.0505, 0.0477, 0.0724, 0.0631]], device='cuda:0')
***********
SINR = tensor([0.0247, 0.4564, 0.4958, 0.4704, 0.3494, 0.4915, 0.4400, 0.1152, 0.1481,
        0.3495, 0.6113, 0.4721, 0.0308, 0.1682, 0.2958, 0.2095, 0.4134, 0.2232,
        0.7035, 0.1247], device='cuda:0')
Real_SINR = tensor([-0.1107, -0.1990, -0.3814,  0.3893, -0.8405,  0.2373,  0.5701, -0.7901,
        -0.4606,  0.3341,  0.6038,  0.4941, -0.1785, -0.5665,  0.0662, -0.2322,
        -0.0568, -0.3246,  0.3309,  0.1186], device='cuda:0')
Real_SINR_noise.shape = torch.Size([20])
ldm/modules/diffusionmodules/util.py, make_ddim_timsteps ddim_discr_method = uniform
ldm/modules/diffusionmodules/util.py, make_ddim_timsteps, Selected timesteps for ddim sampler: (200,)
ldm/modules/diffusionmodules/util.py, make_ddim_sampling_parameters, Selected alphas for ddim sampler: a_t: torch.Size([200]); a_(t-1): (200,)
For the chosen value of eta, which is 0.0, this results in the following sigma_t schedule for ddim sampler tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], dtype=torch.float64)
ddim.py alphas_cumprod = torch.Size([1000])
ddim.py, alpha_bar_u = tensor([0.5014, 0.5262, 0.5285, 0.5271, 0.5201, 0.5283, 0.5253, 0.5066, 0.5085,
        0.5201, 0.5351, 0.5272, 0.5018, 0.5097, 0.5170, 0.5121, 0.5238, 0.5128,
        0.5404, 0.5072], device='cuda:0')
ddim.py start_timesteps after clamp S = 200 : tensor([354, 339, 337, 338, 342, 337, 339, 350, 349, 342, 333, 338, 353, 349,
        344, 347, 340, 347, 330, 350], device='cuda:0')
d = torch.Size([20, 4, 32, 32])
recoverd_img = torch.Size([20, 3, 256, 256])
20 images are saved in outputs/MIMOdiffusion/M=64/K=32/dynamic/
20 images are saved in outputs/MIMOdiffusion/M=64/K=32/nonoisenosample/
--------SNR = 5,  rho_ul = 0.09882117688026186-----------
G_variance = tensor([1.0513, 0.9809, 1.0242, 0.9879, 0.9702, 1.0119, 1.0029, 0.9971, 1.0080,
        0.9879, 1.0165, 0.9908, 0.9867, 0.9994, 0.9848, 1.0226, 1.0519, 1.0182,
        0.9991, 1.0316], device='cuda:0')
G_hat_variance = tensor([0.7827, 0.7376, 0.7766, 0.7512, 0.7430, 0.7485, 0.7716, 0.7454, 0.7587,
        0.7600, 0.7687, 0.7464, 0.7345, 0.7645, 0.7604, 0.7734, 0.7980, 0.7680,
        0.7693, 0.7714], device='cuda:0')
G_tilde_var = tensor([0.2515, 0.2382, 0.2429, 0.2442, 0.2306, 0.2397, 0.2376, 0.2363, 0.2388,
        0.2430, 0.2406, 0.2424, 0.2463, 0.2475, 0.2400, 0.2434, 0.2412, 0.2383,
        0.2288, 0.2381], device='cuda:0')
gamma = tensor([[[0.7597, 0.7597, 0.7597, 0.7597, 0.7597, 0.7597, 0.7597, 0.7597,
          0.7597, 0.7597, 0.7597, 0.7597, 0.7597, 0.7597, 0.7597, 0.7597,
          0.7597, 0.7597, 0.7597, 0.7597, 0.7597, 0.7597, 0.7597, 0.7597,
          0.7597, 0.7597, 0.7597, 0.7597, 0.7597, 0.7597, 0.7597, 0.7597]]],
       device='cuda:0')
Z_mean = tensor([ 0.0239+0.0049j, -0.0069+0.0201j, -0.0218-0.0253j, -0.0003-0.0141j,
         0.0126-0.0094j, -0.0272-0.0009j, -0.0190+0.0014j, -0.0106-0.0020j,
        -0.0126-0.0028j,  0.0091-0.0009j, -0.0086+0.0172j,  0.0148+0.0166j,
        -0.0021-0.0081j, -0.0356-0.0060j, -0.0156-0.0127j, -0.0115-0.0065j,
         0.0039+0.0194j, -0.0020-0.0052j,  0.0055-0.0101j,  0.0152-0.0314j],
       device='cuda:0')
Z_variance ~CN(0, 1)= tensor([1.0302, 0.9709, 1.0221, 0.9887, 0.9780, 0.9852, 1.0156, 0.9811, 0.9987,
        1.0003, 1.0118, 0.9825, 0.9668, 1.0063, 1.0009, 1.0180, 1.0503, 1.0108,
        1.0125, 1.0154], device='cuda:0')
Real_SNR = tensor([5.6179, 5.1935, 6.3912, 5.3117, 4.9828, 5.5739, 6.1838, 5.5406, 5.9752,
        5.1486, 6.0770, 5.5418, 5.7364, 5.2465, 5.7069, 5.6747, 5.3512, 6.1762,
        5.8812, 5.2490], device='cuda:0')
q_var = tensor([1.0001, 1.0002, 1.0002, 1.0002, 0.9999, 1.0002, 1.0000, 1.0002, 0.9999,
        1.0002, 1.0002, 1.0000, 1.0000, 0.9986, 1.0002, 0.9998, 1.0002, 1.0002,
        1.0002, 0.9989], device='cuda:0')
(D_eta_sqrt @ q).var = tensor([1.0001, 1.0002, 1.0002, 1.0002, 0.9999, 1.0002, 1.0000, 1.0002, 0.9999,
        1.0002, 1.0002, 1.0000, 1.0000, 0.9986, 1.0002, 0.9998, 1.0002, 1.0002,
        1.0002, 0.9989], device='cuda:0')
(G @ (D_eta_sqrt @ q)).var = tensor([36.2146, 33.5726, 44.4554, 34.4385, 31.5494, 37.5556, 41.4276, 36.0073,
        40.3182, 33.9234, 41.2866, 36.3714, 38.2160, 33.2433, 36.5803, 37.8859,
        34.6565, 42.2153, 38.4883, 34.0276], device='cuda:0')
signal_var = tensor([3.5788, 3.3177, 4.3931, 3.4033, 3.1177, 3.7113, 4.0939, 3.5583, 3.9843,
        3.3524, 4.0800, 3.5943, 3.7766, 3.2851, 3.6149, 3.7439, 3.4248, 4.1718,
        3.8035, 3.3627], device='cuda:0')
w_var = tensor([0.9816, 1.0034, 1.0084, 1.0017, 0.9898, 1.0283, 0.9857, 0.9935, 1.0065,
        1.0244, 1.0068, 1.0033, 1.0080, 0.9815, 0.9714, 1.0136, 0.9989, 1.0062,
        0.9819, 1.0041], device='cuda:0')
y_var = tensor([4.4698, 4.2944, 5.4725, 4.3964, 4.1687, 4.7456, 5.1132, 4.5700, 5.0488,
        4.3333, 5.1025, 4.5819, 4.7979, 4.3131, 4.5241, 4.7328, 4.3725, 5.1911,
        4.7750, 4.3315], device='cuda:0')
####cond finisihed #####
sum_betak_gammak = tensor([7.6881, 7.6881, 7.6881, 7.6881, 7.6881, 7.6881, 7.6881, 7.6881, 7.6881,
        7.6881, 7.6881, 7.6881, 7.6881, 7.6881, 7.6881, 7.6881, 7.6881, 7.6881,
        7.6881, 7.6881], device='cuda:0')
************
inv_Z_H_Z_k (shape: torch.Size([20, 32])) = tensor([[0.0333, 0.0253, 0.0333, 0.0401, 0.0323, 0.0332, 0.0333, 0.0240, 0.0235,
         0.0259, 0.0271, 0.0374, 0.0296, 0.0242, 0.0411, 0.0268, 0.0300, 0.0289,
         0.0288, 0.0285, 0.0385, 0.0400, 0.0273, 0.0297, 0.0331, 0.0349, 0.0322,
         0.0347, 0.0252, 0.0204, 0.0252, 0.0375],
        [0.0360, 0.0324, 0.0263, 0.0327, 0.0294, 0.0313, 0.0286, 0.0297, 0.0293,
         0.0421, 0.0330, 0.0393, 0.0257, 0.0302, 0.0307, 0.0337, 0.0229, 0.0329,
         0.0283, 0.0250, 0.0315, 0.0240, 0.0289, 0.0303, 0.0303, 0.0285, 0.0304,
         0.0308, 0.0350, 0.0344, 0.0287, 0.0336],
        [0.0361, 0.0305, 0.0236, 0.0277, 0.0293, 0.0302, 0.0240, 0.0286, 0.0271,
         0.0388, 0.0275, 0.0241, 0.0394, 0.0264, 0.0368, 0.0223, 0.0266, 0.0262,
         0.0257, 0.0245, 0.0353, 0.0349, 0.0287, 0.0315, 0.0261, 0.0252, 0.0278,
         0.0318, 0.0346, 0.0314, 0.0308, 0.0205],
        [0.0293, 0.0286, 0.0345, 0.0348, 0.0253, 0.0247, 0.0298, 0.0225, 0.0232,
         0.0397, 0.0269, 0.0286, 0.0256, 0.0389, 0.0286, 0.0284, 0.0359, 0.0306,
         0.0217, 0.0320, 0.0270, 0.0278, 0.0280, 0.0378, 0.0340, 0.0288, 0.0314,
         0.0312, 0.0281, 0.0246, 0.0281, 0.0280],
        [0.0301, 0.0346, 0.0391, 0.0306, 0.0506, 0.0336, 0.0344, 0.0357, 0.0387,
         0.0371, 0.0280, 0.0317, 0.0359, 0.0322, 0.0368, 0.0312, 0.0248, 0.0355,
         0.0241, 0.0298, 0.0326, 0.0355, 0.0313, 0.0269, 0.0306, 0.0331, 0.0310,
         0.0306, 0.0312, 0.0440, 0.0264, 0.0281],
        [0.0369, 0.0314, 0.0276, 0.0293, 0.0300, 0.0282, 0.0274, 0.0441, 0.0295,
         0.0291, 0.0334, 0.0286, 0.0268, 0.0352, 0.0256, 0.0305, 0.0398, 0.0334,
         0.0317, 0.0359, 0.0367, 0.0326, 0.0358, 0.0361, 0.0469, 0.0467, 0.0235,
         0.0272, 0.0265, 0.0272, 0.0349, 0.0260],
        [0.0258, 0.0323, 0.0319, 0.0310, 0.0336, 0.0319, 0.0253, 0.0222, 0.0294,
         0.0292, 0.0228, 0.0353, 0.0320, 0.0296, 0.0345, 0.0386, 0.0306, 0.0233,
         0.0418, 0.0372, 0.0375, 0.0260, 0.0311, 0.0260, 0.0295, 0.0338, 0.0445,
         0.0301, 0.0226, 0.0331, 0.0263, 0.0345],
        [0.0304, 0.0317, 0.0320, 0.0275, 0.0335, 0.0309, 0.0458, 0.0366, 0.0308,
         0.0426, 0.0358, 0.0240, 0.0310, 0.0187, 0.0369, 0.0265, 0.0363, 0.0344,
         0.0252, 0.0251, 0.0318, 0.0259, 0.0236, 0.0254, 0.0400, 0.0263, 0.0382,
         0.0348, 0.0309, 0.0433, 0.0321, 0.0342],
        [0.0354, 0.0404, 0.0364, 0.0362, 0.0348, 0.0332, 0.0371, 0.0388, 0.0297,
         0.0286, 0.0337, 0.0268, 0.0294, 0.0273, 0.0242, 0.0382, 0.0261, 0.0281,
         0.0285, 0.0272, 0.0279, 0.0269, 0.0394, 0.0314, 0.0294, 0.0330, 0.0266,
         0.0351, 0.0275, 0.0303, 0.0349, 0.0256],
        [0.0369, 0.0321, 0.0401, 0.0377, 0.0279, 0.0334, 0.0192, 0.0199, 0.0275,
         0.0370, 0.0262, 0.0334, 0.0360, 0.0354, 0.0383, 0.0245, 0.0268, 0.0313,
         0.0358, 0.0275, 0.0307, 0.0303, 0.0372, 0.0283, 0.0309, 0.0344, 0.0332,
         0.0363, 0.0274, 0.0188, 0.0292, 0.0242],
        [0.0270, 0.0273, 0.0317, 0.0283, 0.0348, 0.0328, 0.0319, 0.0285, 0.0239,
         0.0327, 0.0312, 0.0377, 0.0254, 0.0243, 0.0420, 0.0220, 0.0325, 0.0261,
         0.0346, 0.0280, 0.0289, 0.0293, 0.0306, 0.0337, 0.0306, 0.0261, 0.0317,
         0.0365, 0.0299, 0.0463, 0.0324, 0.0344],
        [0.0368, 0.0336, 0.0261, 0.0278, 0.0258, 0.0311, 0.0346, 0.0358, 0.0295,
         0.0284, 0.0345, 0.0383, 0.0324, 0.0342, 0.0295, 0.0265, 0.0245, 0.0268,
         0.0411, 0.0210, 0.0398, 0.0353, 0.0293, 0.0376, 0.0403, 0.0277, 0.0294,
         0.0437, 0.0221, 0.0307, 0.0325, 0.0422],
        [0.0263, 0.0378, 0.0293, 0.0312, 0.0340, 0.0299, 0.0398, 0.0427, 0.0309,
         0.0319, 0.0283, 0.0263, 0.0299, 0.0345, 0.0322, 0.0299, 0.0437, 0.0272,
         0.0416, 0.0345, 0.0294, 0.0302, 0.0223, 0.0413, 0.0332, 0.0415, 0.0403,
         0.0305, 0.0265, 0.0241, 0.0334, 0.0374],
        [0.0366, 0.0254, 0.0210, 0.0282, 0.0321, 0.0262, 0.0282, 0.0310, 0.0303,
         0.0316, 0.0413, 0.0329, 0.0252, 0.0348, 0.0288, 0.0347, 0.0289, 0.0314,
         0.0322, 0.0243, 0.0293, 0.0415, 0.0244, 0.0232, 0.0358, 0.0345, 0.0324,
         0.0261, 0.0267, 0.0290, 0.0275, 0.0348],
        [0.0279, 0.0328, 0.0447, 0.0388, 0.0264, 0.0293, 0.0309, 0.0370, 0.0288,
         0.0258, 0.0282, 0.0315, 0.0271, 0.0278, 0.0368, 0.0340, 0.0262, 0.0221,
         0.0404, 0.0334, 0.0330, 0.0308, 0.0312, 0.0328, 0.0286, 0.0351, 0.0364,
         0.0317, 0.0315, 0.0242, 0.0360, 0.0257],
        [0.0277, 0.0419, 0.0258, 0.0260, 0.0300, 0.0259, 0.0292, 0.0312, 0.0306,
         0.0364, 0.0343, 0.0329, 0.0343, 0.0325, 0.0276, 0.0379, 0.0242, 0.0344,
         0.0332, 0.0296, 0.0297, 0.0286, 0.0273, 0.0378, 0.0359, 0.0363, 0.0373,
         0.0273, 0.0358, 0.0331, 0.0283, 0.0257],
        [0.0343, 0.0300, 0.0340, 0.0331, 0.0232, 0.0222, 0.0195, 0.0340, 0.0209,
         0.0278, 0.0267, 0.0332, 0.0261, 0.0282, 0.0245, 0.0340, 0.0373, 0.0237,
         0.0330, 0.0263, 0.0274, 0.0281, 0.0306, 0.0289, 0.0294, 0.0306, 0.0320,
         0.0396, 0.0312, 0.0267, 0.0226, 0.0418],
        [0.0296, 0.0225, 0.0369, 0.0348, 0.0267, 0.0356, 0.0397, 0.0346, 0.0349,
         0.0399, 0.0326, 0.0280, 0.0252, 0.0259, 0.0300, 0.0290, 0.0204, 0.0319,
         0.0275, 0.0256, 0.0304, 0.0349, 0.0306, 0.0262, 0.0318, 0.0440, 0.0344,
         0.0383, 0.0345, 0.0300, 0.0353, 0.0297],
        [0.0285, 0.0238, 0.0246, 0.0380, 0.0262, 0.0315, 0.0325, 0.0303, 0.0315,
         0.0344, 0.0401, 0.0283, 0.0334, 0.0262, 0.0275, 0.0294, 0.0319, 0.0329,
         0.0314, 0.0298, 0.0232, 0.0355, 0.0248, 0.0356, 0.0315, 0.0285, 0.0299,
         0.0331, 0.0320, 0.0266, 0.0251, 0.0285],
        [0.0254, 0.0352, 0.0282, 0.0323, 0.0308, 0.0296, 0.0287, 0.0349, 0.0212,
         0.0272, 0.0203, 0.0287, 0.0334, 0.0238, 0.0349, 0.0236, 0.0243, 0.0331,
         0.0250, 0.0363, 0.0357, 0.0258, 0.0365, 0.0280, 0.0345, 0.0265, 0.0254,
         0.0321, 0.0260, 0.0319, 0.0307, 0.0322]], device='cuda:0')
inv_Z_H_Z_k.mean (expected to be = 0.03124999990234375) = 0.031050747260451317
Var (shape: torch.Size([20, 32])) = tensor([[0.0586, 0.0445, 0.0586, 0.0706, 0.0568, 0.0584, 0.0587, 0.0422, 0.0413,
         0.0455, 0.0477, 0.0659, 0.0520, 0.0426, 0.0724, 0.0472, 0.0528, 0.0509,
         0.0506, 0.0502, 0.0678, 0.0704, 0.0480, 0.0523, 0.0583, 0.0615, 0.0567,
         0.0611, 0.0443, 0.0358, 0.0444, 0.0660],
        [0.0634, 0.0571, 0.0462, 0.0575, 0.0517, 0.0551, 0.0503, 0.0523, 0.0515,
         0.0741, 0.0581, 0.0692, 0.0452, 0.0531, 0.0541, 0.0592, 0.0402, 0.0579,
         0.0498, 0.0440, 0.0554, 0.0423, 0.0509, 0.0533, 0.0533, 0.0502, 0.0535,
         0.0542, 0.0615, 0.0605, 0.0506, 0.0592],
        [0.0635, 0.0536, 0.0415, 0.0488, 0.0516, 0.0531, 0.0422, 0.0503, 0.0477,
         0.0682, 0.0483, 0.0423, 0.0693, 0.0464, 0.0648, 0.0393, 0.0467, 0.0462,
         0.0452, 0.0430, 0.0622, 0.0614, 0.0504, 0.0555, 0.0459, 0.0444, 0.0489,
         0.0560, 0.0609, 0.0552, 0.0542, 0.0361],
        [0.0516, 0.0504, 0.0607, 0.0613, 0.0446, 0.0435, 0.0524, 0.0396, 0.0407,
         0.0698, 0.0473, 0.0503, 0.0450, 0.0685, 0.0504, 0.0499, 0.0632, 0.0539,
         0.0381, 0.0563, 0.0475, 0.0490, 0.0493, 0.0665, 0.0598, 0.0508, 0.0552,
         0.0550, 0.0495, 0.0433, 0.0495, 0.0493],
        [0.0529, 0.0609, 0.0689, 0.0538, 0.0891, 0.0592, 0.0605, 0.0628, 0.0680,
         0.0652, 0.0492, 0.0558, 0.0632, 0.0566, 0.0648, 0.0549, 0.0436, 0.0624,
         0.0423, 0.0524, 0.0574, 0.0625, 0.0551, 0.0474, 0.0538, 0.0582, 0.0546,
         0.0538, 0.0549, 0.0774, 0.0465, 0.0495],
        [0.0650, 0.0552, 0.0485, 0.0516, 0.0528, 0.0496, 0.0482, 0.0776, 0.0520,
         0.0512, 0.0587, 0.0502, 0.0472, 0.0620, 0.0450, 0.0536, 0.0701, 0.0587,
         0.0559, 0.0633, 0.0646, 0.0574, 0.0630, 0.0635, 0.0825, 0.0822, 0.0414,
         0.0478, 0.0466, 0.0478, 0.0615, 0.0457],
        [0.0454, 0.0569, 0.0562, 0.0545, 0.0592, 0.0561, 0.0445, 0.0391, 0.0517,
         0.0513, 0.0401, 0.0622, 0.0563, 0.0520, 0.0606, 0.0679, 0.0539, 0.0409,
         0.0735, 0.0655, 0.0660, 0.0457, 0.0548, 0.0457, 0.0518, 0.0595, 0.0784,
         0.0529, 0.0398, 0.0582, 0.0462, 0.0607],
        [0.0535, 0.0558, 0.0564, 0.0484, 0.0590, 0.0545, 0.0805, 0.0643, 0.0542,
         0.0749, 0.0629, 0.0422, 0.0545, 0.0329, 0.0649, 0.0467, 0.0639, 0.0605,
         0.0444, 0.0441, 0.0560, 0.0456, 0.0415, 0.0446, 0.0704, 0.0462, 0.0673,
         0.0612, 0.0544, 0.0762, 0.0565, 0.0601],
        [0.0622, 0.0711, 0.0641, 0.0638, 0.0612, 0.0585, 0.0653, 0.0682, 0.0523,
         0.0502, 0.0593, 0.0472, 0.0517, 0.0481, 0.0426, 0.0673, 0.0460, 0.0495,
         0.0501, 0.0478, 0.0492, 0.0473, 0.0693, 0.0552, 0.0518, 0.0581, 0.0468,
         0.0617, 0.0484, 0.0534, 0.0615, 0.0451],
        [0.0649, 0.0565, 0.0706, 0.0664, 0.0492, 0.0588, 0.0339, 0.0350, 0.0484,
         0.0651, 0.0462, 0.0587, 0.0634, 0.0622, 0.0673, 0.0432, 0.0472, 0.0550,
         0.0629, 0.0483, 0.0540, 0.0534, 0.0654, 0.0498, 0.0543, 0.0606, 0.0585,
         0.0639, 0.0482, 0.0332, 0.0513, 0.0426],
        [0.0475, 0.0481, 0.0558, 0.0498, 0.0612, 0.0578, 0.0562, 0.0502, 0.0420,
         0.0575, 0.0550, 0.0663, 0.0447, 0.0427, 0.0738, 0.0387, 0.0572, 0.0459,
         0.0609, 0.0493, 0.0509, 0.0515, 0.0539, 0.0593, 0.0538, 0.0459, 0.0558,
         0.0642, 0.0527, 0.0816, 0.0571, 0.0606],
        [0.0647, 0.0592, 0.0459, 0.0490, 0.0454, 0.0547, 0.0610, 0.0629, 0.0518,
         0.0500, 0.0606, 0.0674, 0.0570, 0.0601, 0.0519, 0.0466, 0.0431, 0.0472,
         0.0724, 0.0369, 0.0700, 0.0622, 0.0516, 0.0662, 0.0709, 0.0487, 0.0518,
         0.0770, 0.0388, 0.0541, 0.0573, 0.0743],
        [0.0463, 0.0666, 0.0516, 0.0549, 0.0598, 0.0526, 0.0701, 0.0752, 0.0543,
         0.0561, 0.0498, 0.0462, 0.0526, 0.0608, 0.0567, 0.0526, 0.0769, 0.0480,
         0.0732, 0.0607, 0.0517, 0.0532, 0.0393, 0.0727, 0.0585, 0.0730, 0.0710,
         0.0536, 0.0467, 0.0424, 0.0588, 0.0659],
        [0.0644, 0.0447, 0.0370, 0.0497, 0.0565, 0.0462, 0.0497, 0.0546, 0.0533,
         0.0556, 0.0726, 0.0579, 0.0443, 0.0612, 0.0508, 0.0611, 0.0509, 0.0552,
         0.0567, 0.0428, 0.0515, 0.0730, 0.0430, 0.0408, 0.0629, 0.0608, 0.0570,
         0.0459, 0.0469, 0.0510, 0.0484, 0.0613],
        [0.0491, 0.0577, 0.0787, 0.0683, 0.0465, 0.0515, 0.0544, 0.0652, 0.0507,
         0.0453, 0.0496, 0.0554, 0.0477, 0.0489, 0.0647, 0.0598, 0.0462, 0.0390,
         0.0712, 0.0588, 0.0581, 0.0542, 0.0549, 0.0578, 0.0504, 0.0618, 0.0641,
         0.0557, 0.0555, 0.0426, 0.0634, 0.0452],
        [0.0488, 0.0737, 0.0454, 0.0457, 0.0528, 0.0455, 0.0513, 0.0549, 0.0539,
         0.0640, 0.0603, 0.0580, 0.0603, 0.0573, 0.0486, 0.0666, 0.0426, 0.0606,
         0.0584, 0.0521, 0.0523, 0.0503, 0.0480, 0.0666, 0.0633, 0.0639, 0.0657,
         0.0480, 0.0630, 0.0582, 0.0498, 0.0452],
        [0.0604, 0.0528, 0.0598, 0.0582, 0.0408, 0.0390, 0.0343, 0.0598, 0.0368,
         0.0490, 0.0470, 0.0584, 0.0460, 0.0497, 0.0430, 0.0599, 0.0656, 0.0416,
         0.0581, 0.0463, 0.0483, 0.0495, 0.0539, 0.0509, 0.0517, 0.0539, 0.0564,
         0.0696, 0.0550, 0.0470, 0.0397, 0.0736],
        [0.0521, 0.0396, 0.0649, 0.0613, 0.0469, 0.0626, 0.0698, 0.0608, 0.0614,
         0.0702, 0.0574, 0.0493, 0.0444, 0.0456, 0.0527, 0.0511, 0.0358, 0.0562,
         0.0484, 0.0450, 0.0534, 0.0615, 0.0539, 0.0461, 0.0559, 0.0775, 0.0606,
         0.0673, 0.0607, 0.0528, 0.0622, 0.0523],
        [0.0501, 0.0419, 0.0434, 0.0668, 0.0461, 0.0555, 0.0573, 0.0533, 0.0555,
         0.0605, 0.0706, 0.0497, 0.0588, 0.0461, 0.0484, 0.0518, 0.0561, 0.0579,
         0.0553, 0.0524, 0.0409, 0.0625, 0.0437, 0.0627, 0.0554, 0.0501, 0.0527,
         0.0582, 0.0564, 0.0468, 0.0442, 0.0502],
        [0.0447, 0.0619, 0.0496, 0.0569, 0.0543, 0.0522, 0.0506, 0.0615, 0.0374,
         0.0479, 0.0357, 0.0506, 0.0588, 0.0418, 0.0613, 0.0416, 0.0427, 0.0582,
         0.0441, 0.0639, 0.0628, 0.0453, 0.0643, 0.0492, 0.0606, 0.0466, 0.0447,
         0.0565, 0.0457, 0.0561, 0.0541, 0.0567]], device='cuda:0')
***********
SINR = tensor([1.5496, 1.4858, 1.7625, 1.6974, 1.2183, 1.3345, 1.5125, 1.4253, 1.4063,
        1.5746, 1.4888, 1.3745, 1.2597, 1.5922, 1.4251, 1.3985, 1.7562, 1.4276,
        1.5762, 1.7196], device='cuda:0')
Real_SINR = tensor([1.4204, 0.8578, 0.5785, 1.2576, 1.0880, 1.1886, 0.9023, 0.5641, 1.1758,
        1.1351, 1.0675, 1.2151, 0.9120, 1.4634, 1.2829, 0.6987, 1.3401, 1.4888,
        1.4419, 1.1808], device='cuda:0')
Real_SINR_noise.shape = torch.Size([20])
ldm/modules/diffusionmodules/util.py, make_ddim_timsteps ddim_discr_method = uniform
ldm/modules/diffusionmodules/util.py, make_ddim_timsteps, Selected timesteps for ddim sampler: (200,)
ldm/modules/diffusionmodules/util.py, make_ddim_sampling_parameters, Selected alphas for ddim sampler: a_t: torch.Size([200]); a_(t-1): (200,)
For the chosen value of eta, which is 0.0, this results in the following sigma_t schedule for ddim sampler tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], dtype=torch.float64)
ddim.py alphas_cumprod = torch.Size([1000])
ddim.py, alpha_bar_u = tensor([0.5883, 0.5847, 0.6001, 0.5965, 0.5697, 0.5762, 0.5862, 0.5813, 0.5803,
        0.5897, 0.5849, 0.5785, 0.5720, 0.5906, 0.5813, 0.5798, 0.5997, 0.5814,
        0.5897, 0.5977], device='cuda:0')
ddim.py start_timesteps after clamp S = 200 : tensor([302, 304, 295, 297, 313, 309, 303, 306, 307, 301, 304, 308, 311, 300,
        306, 307, 295, 306, 301, 296], device='cuda:0')
d = torch.Size([20, 4, 32, 32])
recoverd_img = torch.Size([20, 3, 256, 256])
20 images are saved in outputs/MIMOdiffusion/M=64/K=32/dynamic/
20 images are saved in outputs/MIMOdiffusion/M=64/K=32/nonoisenosample/
--------SNR = 6,  rho_ul = 0.12440849079796788-----------
G_variance = tensor([1.0037, 1.0253, 1.0148, 1.0081, 0.9960, 0.9680, 0.9944, 1.0134, 0.9992,
        0.9941, 1.0088, 0.9876, 0.9837, 0.9943, 0.9892, 0.9901, 1.0027, 0.9898,
        0.9885, 1.0032], device='cuda:0')
G_hat_variance = tensor([0.8146, 0.8275, 0.8086, 0.7997, 0.8067, 0.7696, 0.7963, 0.8027, 0.8029,
        0.7863, 0.8054, 0.7943, 0.7753, 0.8071, 0.7982, 0.7901, 0.8015, 0.7999,
        0.8061, 0.8095], device='cuda:0')
G_tilde_var = tensor([0.1928, 0.2109, 0.2048, 0.1975, 0.1919, 0.2064, 0.2042, 0.1978, 0.1974,
        0.2030, 0.1970, 0.1949, 0.2031, 0.1950, 0.1941, 0.1906, 0.2025, 0.2001,
        0.1968, 0.1989], device='cuda:0')
gamma = tensor([[[0.7992, 0.7992, 0.7992, 0.7992, 0.7992, 0.7992, 0.7992, 0.7992,
          0.7992, 0.7992, 0.7992, 0.7992, 0.7992, 0.7992, 0.7992, 0.7992,
          0.7992, 0.7992, 0.7992, 0.7992, 0.7992, 0.7992, 0.7992, 0.7992,
          0.7992, 0.7992, 0.7992, 0.7992, 0.7992, 0.7992, 0.7992, 0.7992]]],
       device='cuda:0')
Z_mean = tensor([-0.0080-0.0246j,  0.0180-0.0100j,  0.0014-0.0073j, -0.0099+0.0351j,
        -0.0177-0.0191j, -0.0130+0.0206j,  0.0114+0.0170j,  0.0120-0.0135j,
         0.0084+0.0088j, -0.0251+0.0035j,  0.0143+0.0228j,  0.0118+0.0081j,
         0.0128+0.0190j,  0.0090-0.0010j, -0.0207-0.0346j,  0.0327-0.0005j,
        -0.0023-0.0086j, -0.0009+0.0094j,  0.0268+0.0038j, -0.0126-0.0127j],
       device='cuda:0')
Z_variance ~CN(0, 1)= tensor([1.0193, 1.0354, 1.0118, 1.0006, 1.0093, 0.9630, 0.9963, 1.0043, 1.0045,
        0.9838, 1.0077, 0.9938, 0.9701, 1.0099, 0.9987, 0.9885, 1.0028, 1.0008,
        1.0086, 1.0128], device='cuda:0')
Real_SNR = tensor([6.4972, 6.8763, 6.9876, 5.9241, 6.7726, 5.9637, 6.3465, 6.7498, 6.1404,
        6.6490, 6.4372, 6.3101, 6.2932, 6.2094, 6.9143, 6.0074, 6.7379, 6.8664,
        6.2955, 6.2192], device='cuda:0')
q_var = tensor([1.0001, 1.0002, 1.0002, 1.0002, 0.9999, 1.0002, 1.0000, 1.0002, 0.9999,
        1.0002, 1.0002, 1.0000, 1.0000, 0.9986, 1.0002, 0.9998, 1.0002, 1.0002,
        1.0002, 0.9989], device='cuda:0')
(D_eta_sqrt @ q).var = tensor([1.0001, 1.0002, 1.0002, 1.0002, 0.9999, 1.0002, 1.0000, 1.0002, 0.9999,
        1.0002, 1.0002, 1.0000, 1.0000, 0.9986, 1.0002, 0.9998, 1.0002, 1.0002,
        1.0002, 0.9989], device='cuda:0')
(G @ (D_eta_sqrt @ q)).var = tensor([36.3400, 39.7286, 40.3470, 31.2891, 37.1601, 31.5304, 35.0355, 37.5442,
        33.7567, 37.0747, 34.9817, 34.9338, 33.7678, 33.6532, 39.1569, 32.4202,
        38.2935, 38.5555, 33.8285, 34.6246], device='cuda:0')
signal_var = tensor([4.5210, 4.9426, 5.0195, 3.8926, 4.6230, 3.9226, 4.3587, 4.6708, 4.1996,
        4.6124, 4.3520, 4.3461, 4.2010, 4.1867, 4.8715, 4.0333, 4.7640, 4.7966,
        4.2085, 4.3076], device='cuda:0')
w_var = tensor([1.0128, 1.0147, 1.0044, 0.9950, 0.9720, 0.9936, 1.0109, 0.9872, 1.0213,
        0.9978, 0.9885, 1.0164, 0.9864, 1.0022, 0.9913, 1.0114, 1.0097, 0.9870,
        0.9876, 1.0288], device='cuda:0')
y_var = tensor([5.5179, 5.9931, 6.0726, 4.9410, 5.6387, 4.8912, 5.3835, 5.7368, 5.2076,
        5.6085, 5.4019, 5.3781, 5.2636, 5.1643, 5.8165, 5.0223, 5.7747, 5.8305,
        5.1514, 5.3638], device='cuda:0')
####cond finisihed #####
sum_betak_gammak = tensor([6.4243, 6.4243, 6.4243, 6.4243, 6.4243, 6.4243, 6.4243, 6.4243, 6.4243,
        6.4243, 6.4243, 6.4243, 6.4243, 6.4243, 6.4243, 6.4243, 6.4243, 6.4243,
        6.4243, 6.4243], device='cuda:0')
************
inv_Z_H_Z_k (shape: torch.Size([20, 32])) = tensor([[0.0272, 0.0336, 0.0330, 0.0315, 0.0385, 0.0260, 0.0284, 0.0250, 0.0420,
         0.0304, 0.0260, 0.0335, 0.0284, 0.0304, 0.0410, 0.0290, 0.0259, 0.0332,
         0.0256, 0.0259, 0.0361, 0.0316, 0.0286, 0.0252, 0.0314, 0.0278, 0.0236,
         0.0265, 0.0286, 0.0332, 0.0270, 0.0283],
        [0.0234, 0.0312, 0.0277, 0.0258, 0.0321, 0.0256, 0.0235, 0.0392, 0.0299,
         0.0261, 0.0319, 0.0331, 0.0222, 0.0314, 0.0266, 0.0261, 0.0338, 0.0303,
         0.0253, 0.0400, 0.0297, 0.0389, 0.0338, 0.0342, 0.0214, 0.0233, 0.0314,
         0.0266, 0.0214, 0.0273, 0.0275, 0.0281],
        [0.0206, 0.0279, 0.0618, 0.0267, 0.0313, 0.0271, 0.0365, 0.0369, 0.0300,
         0.0292, 0.0378, 0.0254, 0.0319, 0.0269, 0.0455, 0.0303, 0.0344, 0.0245,
         0.0310, 0.0332, 0.0267, 0.0326, 0.0291, 0.0224, 0.0362, 0.0310, 0.0217,
         0.0283, 0.0279, 0.0274, 0.0425, 0.0291],
        [0.0404, 0.0365, 0.0328, 0.0353, 0.0316, 0.0420, 0.0278, 0.0267, 0.0208,
         0.0272, 0.0304, 0.0401, 0.0378, 0.0315, 0.0276, 0.0362, 0.0389, 0.0385,
         0.0239, 0.0257, 0.0255, 0.0265, 0.0256, 0.0327, 0.0380, 0.0308, 0.0281,
         0.0338, 0.0292, 0.0282, 0.0247, 0.0237],
        [0.0324, 0.0268, 0.0407, 0.0339, 0.0360, 0.0356, 0.0351, 0.0320, 0.0328,
         0.0412, 0.0277, 0.0328, 0.0359, 0.0346, 0.0261, 0.0286, 0.0255, 0.0414,
         0.0337, 0.0400, 0.0335, 0.0397, 0.0452, 0.0247, 0.0273, 0.0291, 0.0317,
         0.0264, 0.0322, 0.0240, 0.0331, 0.0214],
        [0.0242, 0.0316, 0.0297, 0.0359, 0.0321, 0.0421, 0.0377, 0.0352, 0.0317,
         0.0313, 0.0336, 0.0249, 0.0329, 0.0336, 0.0339, 0.0333, 0.0316, 0.0452,
         0.0330, 0.0283, 0.0270, 0.0222, 0.0279, 0.0320, 0.0397, 0.0305, 0.0277,
         0.0276, 0.0336, 0.0327, 0.0296, 0.0461],
        [0.0390, 0.0317, 0.0276, 0.0324, 0.0227, 0.0409, 0.0453, 0.0290, 0.0255,
         0.0501, 0.0340, 0.0326, 0.0497, 0.0568, 0.0311, 0.0375, 0.0371, 0.0330,
         0.0380, 0.0266, 0.0254, 0.0331, 0.0318, 0.0254, 0.0344, 0.0287, 0.0500,
         0.0318, 0.0362, 0.0269, 0.0370, 0.0316],
        [0.0313, 0.0308, 0.0317, 0.0351, 0.0445, 0.0289, 0.0243, 0.0257, 0.0301,
         0.0213, 0.0407, 0.0335, 0.0313, 0.0420, 0.0266, 0.0371, 0.0237, 0.0227,
         0.0271, 0.0275, 0.0288, 0.0355, 0.0270, 0.0364, 0.0304, 0.0244, 0.0358,
         0.0316, 0.0277, 0.0228, 0.0249, 0.0385],
        [0.0366, 0.0378, 0.0273, 0.0295, 0.0369, 0.0372, 0.0227, 0.0323, 0.0309,
         0.0260, 0.0451, 0.0415, 0.0355, 0.0282, 0.0238, 0.0405, 0.0295, 0.0307,
         0.0202, 0.0351, 0.0256, 0.0277, 0.0246, 0.0378, 0.0371, 0.0216, 0.0387,
         0.0490, 0.0220, 0.0280, 0.0369, 0.0312],
        [0.0322, 0.0250, 0.0310, 0.0422, 0.0259, 0.0322, 0.0319, 0.0273, 0.0282,
         0.0274, 0.0256, 0.0284, 0.0336, 0.0323, 0.0326, 0.0375, 0.0326, 0.0518,
         0.0326, 0.0208, 0.0376, 0.0294, 0.0263, 0.0267, 0.0311, 0.0379, 0.0231,
         0.0298, 0.0258, 0.0221, 0.0276, 0.0252],
        [0.0329, 0.0348, 0.0286, 0.0259, 0.0389, 0.0279, 0.0340, 0.0254, 0.0305,
         0.0344, 0.0337, 0.0290, 0.0471, 0.0301, 0.0283, 0.0351, 0.0263, 0.0356,
         0.0314, 0.0329, 0.0296, 0.0338, 0.0279, 0.0273, 0.0301, 0.0262, 0.0260,
         0.0399, 0.0305, 0.0394, 0.0362, 0.0380],
        [0.0305, 0.0252, 0.0498, 0.0317, 0.0339, 0.0254, 0.0243, 0.0251, 0.0306,
         0.0267, 0.0290, 0.0252, 0.0223, 0.0291, 0.0371, 0.0248, 0.0286, 0.0379,
         0.0395, 0.0370, 0.0337, 0.0335, 0.0350, 0.0229, 0.0332, 0.0234, 0.0213,
         0.0296, 0.0339, 0.0368, 0.0314, 0.0335],
        [0.0197, 0.0341, 0.0241, 0.0258, 0.0327, 0.0318, 0.0384, 0.0335, 0.0389,
         0.0309, 0.0416, 0.0300, 0.0252, 0.0347, 0.0359, 0.0367, 0.0274, 0.0315,
         0.0188, 0.0314, 0.0493, 0.0399, 0.0342, 0.0292, 0.0226, 0.0359, 0.0396,
         0.0348, 0.0296, 0.0332, 0.0288, 0.0303],
        [0.0260, 0.0281, 0.0352, 0.0310, 0.0302, 0.0301, 0.0357, 0.0260, 0.0379,
         0.0371, 0.0417, 0.0269, 0.0299, 0.0393, 0.0316, 0.0279, 0.0240, 0.0351,
         0.0297, 0.0284, 0.0281, 0.0215, 0.0266, 0.0325, 0.0291, 0.0294, 0.0291,
         0.0225, 0.0371, 0.0374, 0.0260, 0.0345],
        [0.0289, 0.0267, 0.0386, 0.0309, 0.0238, 0.0261, 0.0253, 0.0319, 0.0292,
         0.0315, 0.0305, 0.0259, 0.0377, 0.0416, 0.0279, 0.0274, 0.0259, 0.0340,
         0.0398, 0.0228, 0.0294, 0.0357, 0.0255, 0.0302, 0.0368, 0.0314, 0.0341,
         0.0278, 0.0359, 0.0355, 0.0345, 0.0313],
        [0.0278, 0.0282, 0.0304, 0.0282, 0.0301, 0.0279, 0.0302, 0.0294, 0.0380,
         0.0304, 0.0379, 0.0361, 0.0300, 0.0306, 0.0312, 0.0357, 0.0240, 0.0318,
         0.0311, 0.0376, 0.0225, 0.0237, 0.0248, 0.0310, 0.0316, 0.0305, 0.0378,
         0.0212, 0.0342, 0.0362, 0.0431, 0.0333],
        [0.0337, 0.0387, 0.0317, 0.0234, 0.0445, 0.0285, 0.0330, 0.0261, 0.0440,
         0.0267, 0.0370, 0.0280, 0.0252, 0.0253, 0.0250, 0.0395, 0.0329, 0.0325,
         0.0316, 0.0214, 0.0308, 0.0261, 0.0440, 0.0398, 0.0344, 0.0256, 0.0279,
         0.0306, 0.0351, 0.0339, 0.0266, 0.0244],
        [0.0320, 0.0438, 0.0365, 0.0358, 0.0305, 0.0316, 0.0247, 0.0258, 0.0354,
         0.0307, 0.0300, 0.0366, 0.0240, 0.0448, 0.0433, 0.0305, 0.0317, 0.0405,
         0.0272, 0.0413, 0.0315, 0.0284, 0.0275, 0.0303, 0.0461, 0.0273, 0.0249,
         0.0270, 0.0397, 0.0333, 0.0368, 0.0311],
        [0.0271, 0.0280, 0.0371, 0.0236, 0.0237, 0.0250, 0.0250, 0.0253, 0.0236,
         0.0314, 0.0288, 0.0254, 0.0334, 0.0331, 0.0347, 0.0329, 0.0377, 0.0286,
         0.0292, 0.0212, 0.0288, 0.0292, 0.0272, 0.0307, 0.0285, 0.0407, 0.0335,
         0.0396, 0.0239, 0.0324, 0.0383, 0.0273],
        [0.0236, 0.0289, 0.0336, 0.0412, 0.0327, 0.0290, 0.0249, 0.0323, 0.0293,
         0.0342, 0.0276, 0.0384, 0.0273, 0.0312, 0.0269, 0.0343, 0.0279, 0.0344,
         0.0380, 0.0408, 0.0272, 0.0341, 0.0359, 0.0339, 0.0294, 0.0277, 0.0304,
         0.0311, 0.0305, 0.0372, 0.0407, 0.0297]], device='cuda:0')
inv_Z_H_Z_k.mean (expected to be = 0.03124999990234375) = 0.031455472111701965
Var (shape: torch.Size([20, 32])) = tensor([[0.0490, 0.0605, 0.0593, 0.0567, 0.0693, 0.0468, 0.0511, 0.0451, 0.0756,
         0.0547, 0.0467, 0.0603, 0.0511, 0.0547, 0.0739, 0.0521, 0.0467, 0.0597,
         0.0461, 0.0466, 0.0649, 0.0569, 0.0514, 0.0454, 0.0565, 0.0499, 0.0425,
         0.0477, 0.0515, 0.0598, 0.0486, 0.0509],
        [0.0421, 0.0561, 0.0499, 0.0465, 0.0577, 0.0460, 0.0423, 0.0706, 0.0537,
         0.0469, 0.0575, 0.0596, 0.0400, 0.0564, 0.0479, 0.0469, 0.0608, 0.0545,
         0.0455, 0.0719, 0.0534, 0.0700, 0.0608, 0.0615, 0.0386, 0.0419, 0.0564,
         0.0478, 0.0386, 0.0490, 0.0495, 0.0505],
        [0.0371, 0.0502, 0.1113, 0.0481, 0.0563, 0.0488, 0.0658, 0.0663, 0.0540,
         0.0525, 0.0680, 0.0457, 0.0573, 0.0484, 0.0819, 0.0545, 0.0620, 0.0440,
         0.0557, 0.0598, 0.0481, 0.0587, 0.0523, 0.0404, 0.0652, 0.0558, 0.0390,
         0.0509, 0.0502, 0.0493, 0.0764, 0.0524],
        [0.0727, 0.0656, 0.0591, 0.0635, 0.0568, 0.0755, 0.0500, 0.0481, 0.0375,
         0.0489, 0.0546, 0.0722, 0.0679, 0.0566, 0.0497, 0.0651, 0.0700, 0.0693,
         0.0431, 0.0463, 0.0458, 0.0477, 0.0460, 0.0588, 0.0684, 0.0555, 0.0505,
         0.0609, 0.0526, 0.0507, 0.0444, 0.0426],
        [0.0584, 0.0482, 0.0733, 0.0610, 0.0647, 0.0641, 0.0631, 0.0576, 0.0591,
         0.0742, 0.0499, 0.0590, 0.0646, 0.0622, 0.0470, 0.0514, 0.0459, 0.0745,
         0.0606, 0.0720, 0.0602, 0.0714, 0.0813, 0.0445, 0.0491, 0.0523, 0.0570,
         0.0475, 0.0580, 0.0432, 0.0595, 0.0386],
        [0.0436, 0.0569, 0.0535, 0.0646, 0.0577, 0.0757, 0.0678, 0.0633, 0.0571,
         0.0563, 0.0605, 0.0447, 0.0593, 0.0605, 0.0611, 0.0600, 0.0569, 0.0813,
         0.0594, 0.0510, 0.0485, 0.0399, 0.0502, 0.0575, 0.0714, 0.0549, 0.0498,
         0.0497, 0.0604, 0.0588, 0.0533, 0.0829],
        [0.0701, 0.0570, 0.0497, 0.0583, 0.0408, 0.0736, 0.0815, 0.0523, 0.0459,
         0.0901, 0.0612, 0.0586, 0.0893, 0.1021, 0.0560, 0.0674, 0.0667, 0.0593,
         0.0683, 0.0479, 0.0457, 0.0596, 0.0573, 0.0458, 0.0619, 0.0516, 0.0900,
         0.0573, 0.0651, 0.0484, 0.0665, 0.0569],
        [0.0564, 0.0553, 0.0570, 0.0631, 0.0800, 0.0519, 0.0437, 0.0463, 0.0541,
         0.0384, 0.0733, 0.0603, 0.0563, 0.0756, 0.0479, 0.0668, 0.0427, 0.0409,
         0.0487, 0.0495, 0.0518, 0.0639, 0.0485, 0.0654, 0.0548, 0.0440, 0.0645,
         0.0568, 0.0499, 0.0411, 0.0448, 0.0693],
        [0.0659, 0.0681, 0.0492, 0.0531, 0.0663, 0.0669, 0.0408, 0.0580, 0.0556,
         0.0467, 0.0811, 0.0747, 0.0638, 0.0507, 0.0428, 0.0729, 0.0530, 0.0552,
         0.0363, 0.0632, 0.0460, 0.0499, 0.0442, 0.0681, 0.0667, 0.0389, 0.0696,
         0.0881, 0.0396, 0.0504, 0.0663, 0.0562],
        [0.0579, 0.0451, 0.0557, 0.0759, 0.0466, 0.0579, 0.0575, 0.0492, 0.0508,
         0.0493, 0.0460, 0.0511, 0.0605, 0.0580, 0.0586, 0.0674, 0.0586, 0.0933,
         0.0587, 0.0374, 0.0677, 0.0529, 0.0473, 0.0480, 0.0560, 0.0681, 0.0416,
         0.0536, 0.0464, 0.0397, 0.0497, 0.0454],
        [0.0592, 0.0626, 0.0515, 0.0466, 0.0700, 0.0502, 0.0612, 0.0456, 0.0549,
         0.0619, 0.0607, 0.0523, 0.0847, 0.0541, 0.0509, 0.0632, 0.0474, 0.0640,
         0.0566, 0.0592, 0.0532, 0.0607, 0.0502, 0.0491, 0.0541, 0.0472, 0.0467,
         0.0717, 0.0549, 0.0709, 0.0651, 0.0684],
        [0.0549, 0.0454, 0.0896, 0.0570, 0.0610, 0.0457, 0.0438, 0.0452, 0.0550,
         0.0481, 0.0523, 0.0453, 0.0400, 0.0524, 0.0668, 0.0447, 0.0515, 0.0682,
         0.0710, 0.0666, 0.0605, 0.0602, 0.0631, 0.0411, 0.0598, 0.0421, 0.0383,
         0.0533, 0.0610, 0.0663, 0.0564, 0.0602],
        [0.0355, 0.0613, 0.0434, 0.0464, 0.0589, 0.0572, 0.0690, 0.0604, 0.0699,
         0.0555, 0.0749, 0.0540, 0.0453, 0.0625, 0.0646, 0.0660, 0.0493, 0.0568,
         0.0339, 0.0564, 0.0886, 0.0718, 0.0615, 0.0526, 0.0406, 0.0646, 0.0712,
         0.0626, 0.0532, 0.0597, 0.0519, 0.0545],
        [0.0468, 0.0505, 0.0633, 0.0557, 0.0543, 0.0542, 0.0642, 0.0468, 0.0683,
         0.0667, 0.0750, 0.0483, 0.0537, 0.0707, 0.0568, 0.0503, 0.0431, 0.0631,
         0.0534, 0.0510, 0.0506, 0.0387, 0.0478, 0.0586, 0.0524, 0.0529, 0.0524,
         0.0404, 0.0668, 0.0673, 0.0469, 0.0621],
        [0.0519, 0.0481, 0.0694, 0.0556, 0.0429, 0.0470, 0.0456, 0.0573, 0.0525,
         0.0568, 0.0549, 0.0466, 0.0678, 0.0748, 0.0501, 0.0493, 0.0466, 0.0611,
         0.0716, 0.0410, 0.0529, 0.0643, 0.0460, 0.0544, 0.0663, 0.0564, 0.0614,
         0.0500, 0.0646, 0.0639, 0.0621, 0.0563],
        [0.0500, 0.0507, 0.0546, 0.0507, 0.0542, 0.0501, 0.0544, 0.0529, 0.0683,
         0.0548, 0.0682, 0.0650, 0.0540, 0.0551, 0.0562, 0.0642, 0.0432, 0.0572,
         0.0559, 0.0676, 0.0406, 0.0426, 0.0446, 0.0558, 0.0569, 0.0548, 0.0680,
         0.0382, 0.0615, 0.0652, 0.0776, 0.0599],
        [0.0606, 0.0696, 0.0571, 0.0422, 0.0801, 0.0513, 0.0593, 0.0470, 0.0791,
         0.0481, 0.0666, 0.0504, 0.0453, 0.0454, 0.0450, 0.0712, 0.0592, 0.0584,
         0.0569, 0.0385, 0.0554, 0.0470, 0.0792, 0.0716, 0.0620, 0.0460, 0.0502,
         0.0550, 0.0632, 0.0610, 0.0479, 0.0439],
        [0.0575, 0.0787, 0.0657, 0.0644, 0.0548, 0.0569, 0.0444, 0.0463, 0.0637,
         0.0552, 0.0539, 0.0659, 0.0432, 0.0806, 0.0779, 0.0549, 0.0571, 0.0729,
         0.0489, 0.0742, 0.0567, 0.0510, 0.0494, 0.0546, 0.0830, 0.0492, 0.0448,
         0.0486, 0.0714, 0.0598, 0.0662, 0.0559],
        [0.0488, 0.0504, 0.0667, 0.0425, 0.0426, 0.0449, 0.0450, 0.0455, 0.0424,
         0.0564, 0.0517, 0.0458, 0.0601, 0.0596, 0.0625, 0.0592, 0.0679, 0.0515,
         0.0526, 0.0381, 0.0518, 0.0525, 0.0489, 0.0553, 0.0513, 0.0732, 0.0604,
         0.0713, 0.0430, 0.0583, 0.0689, 0.0492],
        [0.0425, 0.0520, 0.0605, 0.0742, 0.0589, 0.0522, 0.0447, 0.0582, 0.0527,
         0.0616, 0.0497, 0.0691, 0.0492, 0.0561, 0.0485, 0.0618, 0.0501, 0.0619,
         0.0683, 0.0734, 0.0489, 0.0614, 0.0646, 0.0610, 0.0528, 0.0498, 0.0546,
         0.0560, 0.0548, 0.0670, 0.0732, 0.0535]], device='cuda:0')
***********
SINR = tensor([2.7297, 2.9181, 2.6622, 2.6259, 2.4373, 2.4249, 2.2196, 2.7175, 2.5741,
        2.7440, 2.4533, 2.7162, 2.5302, 2.6519, 2.6028, 2.6032, 2.6051, 2.3653,
        2.7983, 2.4590], device='cuda:0')
Real_SINR = tensor([2.1868, 2.1876, 1.8301, 2.2552, 2.2088, 2.3765, 1.8061, 2.5296, 2.3191,
        2.2941, 1.8682, 2.6237, 2.2206, 2.5661, 2.8616, 2.1163, 2.0618, 2.0545,
        2.2697, 1.8545], device='cuda:0')
Real_SINR_noise.shape = torch.Size([20])
ldm/modules/diffusionmodules/util.py, make_ddim_timsteps ddim_discr_method = uniform
ldm/modules/diffusionmodules/util.py, make_ddim_timsteps, Selected timesteps for ddim sampler: (200,)
ldm/modules/diffusionmodules/util.py, make_ddim_sampling_parameters, Selected alphas for ddim sampler: a_t: torch.Size([200]); a_(t-1): (200,)
For the chosen value of eta, which is 0.0, this results in the following sigma_t schedule for ddim sampler tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], dtype=torch.float64)
ddim.py alphas_cumprod = torch.Size([1000])
ddim.py, alpha_bar_u = tensor([0.6522, 0.6619, 0.6486, 0.6467, 0.6367, 0.6361, 0.6251, 0.6515, 0.6440,
        0.6529, 0.6376, 0.6515, 0.6417, 0.6481, 0.6455, 0.6455, 0.6456, 0.6329,
        0.6557, 0.6379], device='cuda:0')
ddim.py start_timesteps after clamp S = 200 : tensor([264, 258, 266, 267, 273, 273, 280, 264, 269, 263, 272, 264, 270, 266,
        268, 268, 268, 275, 261, 272], device='cuda:0')
d = torch.Size([20, 4, 32, 32])
recoverd_img = torch.Size([20, 3, 256, 256])
20 images are saved in outputs/MIMOdiffusion/M=64/K=32/dynamic/
20 images are saved in outputs/MIMOdiffusion/M=64/K=32/nonoisenosample/
--------SNR = 7,  rho_ul = 0.15662101050852256-----------
G_variance = tensor([1.0031, 0.9703, 0.9837, 1.0015, 0.9765, 1.0049, 1.0202, 0.9985, 1.0022,
        0.9922, 0.9709, 1.0042, 1.0140, 0.9973, 0.9747, 0.9971, 0.9817, 1.0141,
        0.9936, 1.0250], device='cuda:0')
G_hat_variance = tensor([0.8451, 0.8215, 0.8405, 0.8233, 0.8391, 0.8398, 0.8579, 0.8337, 0.8230,
        0.8094, 0.8072, 0.8380, 0.8483, 0.8496, 0.8246, 0.8254, 0.8148, 0.8373,
        0.8322, 0.8468], device='cuda:0')
G_tilde_var = tensor([0.1657, 0.1626, 0.1632, 0.1678, 0.1658, 0.1682, 0.1669, 0.1690, 0.1646,
        0.1759, 0.1627, 0.1636, 0.1704, 0.1634, 0.1637, 0.1673, 0.1686, 0.1619,
        0.1628, 0.1648], device='cuda:0')
gamma = tensor([[[0.8337, 0.8337, 0.8337, 0.8337, 0.8337, 0.8337, 0.8337, 0.8337,
          0.8337, 0.8337, 0.8337, 0.8337, 0.8337, 0.8337, 0.8337, 0.8337,
          0.8337, 0.8337, 0.8337, 0.8337, 0.8337, 0.8337, 0.8337, 0.8337,
          0.8337, 0.8337, 0.8337, 0.8337, 0.8337, 0.8337, 0.8337, 0.8337]]],
       device='cuda:0')
Z_mean = tensor([-0.0030+0.0029j, -0.0051+0.0215j,  0.0030+0.0245j,  0.0098-0.0148j,
         0.0020+0.0147j, -0.0007+0.0341j,  0.0310-0.0124j, -0.0124-0.0178j,
         0.0055+0.0076j,  0.0079-0.0173j,  0.0059-0.0097j, -0.0170+0.0113j,
        -0.0114+0.0146j, -0.0015-0.0207j, -0.0242+0.0181j,  0.0020+0.0151j,
        -0.0027-0.0027j,  0.0136+0.0056j,  0.0013-0.0016j, -0.0004-0.0198j],
       device='cuda:0')
Z_variance ~CN(0, 1)= tensor([1.0137, 0.9855, 1.0082, 0.9876, 1.0065, 1.0074, 1.0291, 1.0000, 0.9872,
        0.9709, 0.9682, 1.0052, 1.0175, 1.0191, 0.9892, 0.9901, 0.9774, 1.0043,
        0.9983, 1.0158], device='cuda:0')
Real_SNR = tensor([7.1690, 7.6544, 7.9886, 6.5858, 7.5023, 7.5083, 7.2359, 7.1106, 7.3274,
        7.5067, 7.0361, 7.2156, 7.7282, 6.9279, 7.5550, 7.8865, 7.5801, 7.9239,
        7.1845, 6.8810], device='cuda:0')
q_var = tensor([1.0001, 1.0002, 1.0002, 1.0002, 0.9999, 1.0002, 1.0000, 1.0002, 0.9999,
        1.0002, 1.0002, 1.0000, 1.0000, 0.9986, 1.0002, 0.9998, 1.0002, 1.0002,
        1.0002, 0.9989], device='cuda:0')
(D_eta_sqrt @ q).var = tensor([1.0001, 1.0002, 1.0002, 1.0002, 0.9999, 1.0002, 1.0000, 1.0002, 0.9999,
        1.0002, 1.0002, 1.0000, 1.0000, 0.9986, 1.0002, 0.9998, 1.0002, 1.0002,
        1.0002, 0.9989], device='cuda:0')
(G @ (D_eta_sqrt @ q)).var = tensor([33.5822, 37.8699, 40.1568, 29.6331, 35.1438, 35.1427, 34.2794, 32.3591,
        34.8036, 37.0621, 31.5764, 34.7421, 38.2293, 30.6534, 36.2051, 38.5817,
        36.9657, 39.1963, 33.8671, 31.9992], device='cuda:0')
signal_var = tensor([5.2597, 5.9312, 6.2894, 4.6412, 5.5043, 5.5041, 5.3689, 5.0681, 5.4510,
        5.8047, 4.9455, 5.4413, 5.9875, 4.8010, 5.6705, 6.0427, 5.7896, 6.1390,
        5.3043, 5.0117], device='cuda:0')
w_var = tensor([1.0094, 1.0179, 0.9994, 1.0187, 0.9783, 0.9769, 1.0146, 0.9858, 1.0086,
        1.0306, 0.9786, 1.0331, 1.0102, 0.9740, 0.9957, 0.9831, 1.0107, 0.9902,
        1.0143, 1.0277], device='cuda:0')
y_var = tensor([6.1852, 6.9985, 7.3880, 5.6002, 6.4802, 6.5172, 6.2817, 6.0301, 6.4396,
        6.8805, 5.9078, 6.4728, 7.1098, 5.8391, 6.6868, 7.0190, 6.7348, 7.1354,
        6.2783, 6.0465], device='cuda:0')
####cond finisihed #####
sum_betak_gammak = tensor([5.3228, 5.3228, 5.3228, 5.3228, 5.3228, 5.3228, 5.3228, 5.3228, 5.3228,
        5.3228, 5.3228, 5.3228, 5.3228, 5.3228, 5.3228, 5.3228, 5.3228, 5.3228,
        5.3228, 5.3228], device='cuda:0')
************
inv_Z_H_Z_k (shape: torch.Size([20, 32])) = tensor([[0.0340, 0.0430, 0.0262, 0.0355, 0.0309, 0.0238, 0.0221, 0.0303, 0.0318,
         0.0269, 0.0357, 0.0268, 0.0364, 0.0284, 0.0326, 0.0239, 0.0325, 0.0278,
         0.0286, 0.0290, 0.0283, 0.0328, 0.0300, 0.0415, 0.0280, 0.0263, 0.0329,
         0.0388, 0.0273, 0.0373, 0.0353, 0.0329],
        [0.0245, 0.0394, 0.0235, 0.0304, 0.0325, 0.0336, 0.0278, 0.0233, 0.0349,
         0.0318, 0.0304, 0.0292, 0.0293, 0.0296, 0.0273, 0.0234, 0.0300, 0.0310,
         0.0286, 0.0263, 0.0316, 0.0545, 0.0304, 0.0269, 0.0347, 0.0304, 0.0296,
         0.0257, 0.0248, 0.0285, 0.0263, 0.0295],
        [0.0285, 0.0330, 0.0284, 0.0341, 0.0341, 0.0256, 0.0364, 0.0202, 0.0333,
         0.0272, 0.0271, 0.0242, 0.0282, 0.0322, 0.0241, 0.0269, 0.0314, 0.0274,
         0.0236, 0.0439, 0.0299, 0.0331, 0.0304, 0.0292, 0.0306, 0.0342, 0.0254,
         0.0310, 0.0322, 0.0245, 0.0330, 0.0396],
        [0.0316, 0.0351, 0.0429, 0.0343, 0.0243, 0.0292, 0.0259, 0.0279, 0.0287,
         0.0227, 0.0233, 0.0347, 0.0303, 0.0494, 0.0261, 0.0377, 0.0322, 0.0333,
         0.0303, 0.0405, 0.0282, 0.0313, 0.0238, 0.0260, 0.0418, 0.0381, 0.0337,
         0.0298, 0.0382, 0.0295, 0.0327, 0.0333],
        [0.0305, 0.0244, 0.0335, 0.0305, 0.0258, 0.0263, 0.0384, 0.0320, 0.0270,
         0.0336, 0.0371, 0.0339, 0.0218, 0.0371, 0.0235, 0.0315, 0.0259, 0.0370,
         0.0215, 0.0376, 0.0236, 0.0347, 0.0263, 0.0255, 0.0349, 0.0297, 0.0282,
         0.0356, 0.0301, 0.0437, 0.0242, 0.0250],
        [0.0339, 0.0402, 0.0261, 0.0261, 0.0369, 0.0278, 0.0227, 0.0314, 0.0232,
         0.0321, 0.0337, 0.0330, 0.0276, 0.0312, 0.0290, 0.0307, 0.0356, 0.0305,
         0.0275, 0.0249, 0.0284, 0.0319, 0.0284, 0.0303, 0.0297, 0.0283, 0.0327,
         0.0295, 0.0273, 0.0278, 0.0335, 0.0267],
        [0.0344, 0.0246, 0.0260, 0.0323, 0.0295, 0.0314, 0.0202, 0.0340, 0.0226,
         0.0263, 0.0307, 0.0224, 0.0333, 0.0332, 0.0275, 0.0309, 0.0269, 0.0288,
         0.0445, 0.0315, 0.0298, 0.0255, 0.0203, 0.0259, 0.0273, 0.0317, 0.0306,
         0.0356, 0.0415, 0.0400, 0.0322, 0.0287],
        [0.0338, 0.0231, 0.0304, 0.0395, 0.0345, 0.0190, 0.0250, 0.0337, 0.0341,
         0.0288, 0.0354, 0.0396, 0.0220, 0.0254, 0.0300, 0.0460, 0.0278, 0.0356,
         0.0327, 0.0240, 0.0316, 0.0244, 0.0326, 0.0275, 0.0266, 0.0300, 0.0281,
         0.0279, 0.0288, 0.0367, 0.0309, 0.0269],
        [0.0316, 0.0465, 0.0251, 0.0421, 0.0260, 0.0299, 0.0301, 0.0268, 0.0333,
         0.0253, 0.0288, 0.0281, 0.0283, 0.0375, 0.0343, 0.0290, 0.0234, 0.0310,
         0.0259, 0.0289, 0.0297, 0.0323, 0.0235, 0.0279, 0.0328, 0.0271, 0.0331,
         0.0245, 0.0171, 0.0329, 0.0319, 0.0268],
        [0.0372, 0.0297, 0.0265, 0.0272, 0.0247, 0.0315, 0.0224, 0.0255, 0.0335,
         0.0320, 0.0388, 0.0352, 0.0292, 0.0316, 0.0265, 0.0311, 0.0306, 0.0381,
         0.0271, 0.0306, 0.0304, 0.0366, 0.0266, 0.0269, 0.0336, 0.0266, 0.0272,
         0.0394, 0.0244, 0.0279, 0.0307, 0.0417],
        [0.0470, 0.0553, 0.0347, 0.0375, 0.0361, 0.0271, 0.0358, 0.0489, 0.0243,
         0.0365, 0.0254, 0.0523, 0.0437, 0.0339, 0.0318, 0.0282, 0.0303, 0.0454,
         0.0440, 0.0415, 0.0329, 0.0386, 0.0397, 0.0364, 0.0253, 0.0262, 0.0244,
         0.0405, 0.0283, 0.0274, 0.0309, 0.0258],
        [0.0265, 0.0334, 0.0233, 0.0401, 0.0405, 0.0248, 0.0305, 0.0289, 0.0287,
         0.0238, 0.0284, 0.0340, 0.0289, 0.0326, 0.0345, 0.0247, 0.0294, 0.0288,
         0.0277, 0.0332, 0.0232, 0.0279, 0.0366, 0.0477, 0.0337, 0.0331, 0.0269,
         0.0354, 0.0302, 0.0315, 0.0455, 0.0257],
        [0.0323, 0.0391, 0.0340, 0.0297, 0.0270, 0.0291, 0.0339, 0.0248, 0.0332,
         0.0225, 0.0304, 0.0293, 0.0410, 0.0297, 0.0248, 0.0277, 0.0293, 0.0301,
         0.0277, 0.0260, 0.0270, 0.0277, 0.0324, 0.0268, 0.0228, 0.0258, 0.0288,
         0.0324, 0.0335, 0.0331, 0.0286, 0.0331],
        [0.0314, 0.0262, 0.0245, 0.0348, 0.0432, 0.0281, 0.0522, 0.0237, 0.0404,
         0.0315, 0.0210, 0.0318, 0.0354, 0.0412, 0.0261, 0.0345, 0.0389, 0.0312,
         0.0359, 0.0333, 0.0369, 0.0197, 0.0264, 0.0394, 0.0302, 0.0311, 0.0333,
         0.0399, 0.0321, 0.0290, 0.0225, 0.0428],
        [0.0243, 0.0189, 0.0379, 0.0243, 0.0269, 0.0283, 0.0350, 0.0362, 0.0296,
         0.0331, 0.0264, 0.0330, 0.0323, 0.0290, 0.0350, 0.0290, 0.0222, 0.0316,
         0.0356, 0.0298, 0.0317, 0.0367, 0.0368, 0.0270, 0.0289, 0.0346, 0.0228,
         0.0303, 0.0290, 0.0313, 0.0362, 0.0277],
        [0.0373, 0.0253, 0.0206, 0.0323, 0.0270, 0.0314, 0.0390, 0.0311, 0.0354,
         0.0250, 0.0300, 0.0282, 0.0312, 0.0218, 0.0277, 0.0284, 0.0269, 0.0333,
         0.0271, 0.0365, 0.0399, 0.0228, 0.0311, 0.0254, 0.0424, 0.0281, 0.0391,
         0.0304, 0.0225, 0.0286, 0.0330, 0.0211],
        [0.0236, 0.0227, 0.0325, 0.0326, 0.0442, 0.0345, 0.0422, 0.0309, 0.0297,
         0.0343, 0.0388, 0.0358, 0.0298, 0.0301, 0.0272, 0.0303, 0.0341, 0.0306,
         0.0289, 0.0272, 0.0232, 0.0281, 0.0261, 0.0329, 0.0262, 0.0316, 0.0273,
         0.0392, 0.0276, 0.0290, 0.0344, 0.0396],
        [0.0291, 0.0272, 0.0273, 0.0311, 0.0290, 0.0304, 0.0283, 0.0349, 0.0254,
         0.0381, 0.0293, 0.0224, 0.0247, 0.0322, 0.0310, 0.0365, 0.0230, 0.0296,
         0.0274, 0.0308, 0.0334, 0.0315, 0.0287, 0.0342, 0.0288, 0.0276, 0.0288,
         0.0308, 0.0259, 0.0300, 0.0301, 0.0286],
        [0.0442, 0.0288, 0.0328, 0.0228, 0.0319, 0.0341, 0.0289, 0.0354, 0.0211,
         0.0317, 0.0396, 0.0368, 0.0251, 0.0317, 0.0277, 0.0360, 0.0218, 0.0387,
         0.0335, 0.0269, 0.0303, 0.0218, 0.0296, 0.0312, 0.0327, 0.0293, 0.0480,
         0.0255, 0.0200, 0.0296, 0.0315, 0.0290],
        [0.0288, 0.0312, 0.0276, 0.0288, 0.0360, 0.0229, 0.0265, 0.0324, 0.0281,
         0.0247, 0.0313, 0.0367, 0.0309, 0.0260, 0.0377, 0.0244, 0.0332, 0.0307,
         0.0362, 0.0229, 0.0274, 0.0278, 0.0295, 0.0285, 0.0223, 0.0311, 0.0399,
         0.0331, 0.0332, 0.0296, 0.0320, 0.0337]], device='cuda:0')
inv_Z_H_Z_k.mean (expected to be = 0.03124999990234375) = 0.030804334208369255
Var (shape: torch.Size([20, 32])) = tensor([[0.0623, 0.0789, 0.0481, 0.0651, 0.0566, 0.0436, 0.0405, 0.0556, 0.0583,
         0.0494, 0.0655, 0.0492, 0.0668, 0.0521, 0.0599, 0.0439, 0.0596, 0.0510,
         0.0525, 0.0532, 0.0519, 0.0602, 0.0549, 0.0760, 0.0513, 0.0483, 0.0603,
         0.0711, 0.0501, 0.0684, 0.0647, 0.0603],
        [0.0449, 0.0722, 0.0431, 0.0557, 0.0596, 0.0616, 0.0510, 0.0427, 0.0639,
         0.0584, 0.0558, 0.0535, 0.0537, 0.0542, 0.0501, 0.0429, 0.0551, 0.0569,
         0.0525, 0.0481, 0.0580, 0.1000, 0.0557, 0.0492, 0.0636, 0.0557, 0.0543,
         0.0471, 0.0456, 0.0522, 0.0482, 0.0540],
        [0.0523, 0.0605, 0.0520, 0.0626, 0.0625, 0.0470, 0.0667, 0.0371, 0.0611,
         0.0499, 0.0497, 0.0445, 0.0517, 0.0590, 0.0441, 0.0494, 0.0575, 0.0503,
         0.0433, 0.0806, 0.0548, 0.0607, 0.0557, 0.0536, 0.0562, 0.0627, 0.0466,
         0.0569, 0.0591, 0.0449, 0.0605, 0.0726],
        [0.0580, 0.0644, 0.0787, 0.0630, 0.0446, 0.0535, 0.0475, 0.0511, 0.0526,
         0.0417, 0.0426, 0.0636, 0.0556, 0.0906, 0.0479, 0.0692, 0.0590, 0.0611,
         0.0555, 0.0743, 0.0518, 0.0574, 0.0436, 0.0476, 0.0766, 0.0698, 0.0618,
         0.0547, 0.0700, 0.0541, 0.0600, 0.0611],
        [0.0559, 0.0447, 0.0614, 0.0560, 0.0472, 0.0483, 0.0704, 0.0588, 0.0496,
         0.0615, 0.0681, 0.0622, 0.0399, 0.0681, 0.0430, 0.0577, 0.0474, 0.0678,
         0.0394, 0.0690, 0.0433, 0.0637, 0.0482, 0.0468, 0.0641, 0.0544, 0.0517,
         0.0652, 0.0552, 0.0802, 0.0444, 0.0459],
        [0.0621, 0.0736, 0.0478, 0.0478, 0.0677, 0.0509, 0.0417, 0.0575, 0.0426,
         0.0589, 0.0618, 0.0606, 0.0506, 0.0573, 0.0532, 0.0562, 0.0653, 0.0559,
         0.0504, 0.0456, 0.0521, 0.0585, 0.0521, 0.0555, 0.0544, 0.0518, 0.0600,
         0.0542, 0.0501, 0.0509, 0.0614, 0.0490],
        [0.0631, 0.0450, 0.0476, 0.0592, 0.0542, 0.0575, 0.0371, 0.0624, 0.0414,
         0.0482, 0.0562, 0.0411, 0.0610, 0.0609, 0.0505, 0.0566, 0.0494, 0.0527,
         0.0816, 0.0577, 0.0546, 0.0467, 0.0372, 0.0476, 0.0501, 0.0581, 0.0561,
         0.0653, 0.0761, 0.0734, 0.0590, 0.0526],
        [0.0620, 0.0423, 0.0558, 0.0725, 0.0632, 0.0348, 0.0458, 0.0618, 0.0626,
         0.0528, 0.0648, 0.0726, 0.0403, 0.0466, 0.0549, 0.0843, 0.0510, 0.0653,
         0.0600, 0.0441, 0.0580, 0.0448, 0.0598, 0.0504, 0.0488, 0.0550, 0.0515,
         0.0512, 0.0528, 0.0673, 0.0566, 0.0494],
        [0.0580, 0.0853, 0.0461, 0.0771, 0.0477, 0.0549, 0.0552, 0.0492, 0.0611,
         0.0465, 0.0527, 0.0515, 0.0518, 0.0687, 0.0629, 0.0532, 0.0429, 0.0568,
         0.0476, 0.0530, 0.0544, 0.0592, 0.0430, 0.0512, 0.0601, 0.0496, 0.0607,
         0.0449, 0.0314, 0.0603, 0.0586, 0.0492],
        [0.0681, 0.0544, 0.0486, 0.0499, 0.0452, 0.0578, 0.0410, 0.0467, 0.0614,
         0.0587, 0.0712, 0.0646, 0.0536, 0.0579, 0.0486, 0.0570, 0.0560, 0.0699,
         0.0497, 0.0561, 0.0557, 0.0671, 0.0488, 0.0493, 0.0617, 0.0489, 0.0499,
         0.0722, 0.0448, 0.0512, 0.0562, 0.0764],
        [0.0861, 0.1013, 0.0636, 0.0687, 0.0662, 0.0497, 0.0657, 0.0897, 0.0446,
         0.0669, 0.0466, 0.0958, 0.0801, 0.0622, 0.0584, 0.0516, 0.0555, 0.0832,
         0.0807, 0.0762, 0.0603, 0.0708, 0.0727, 0.0667, 0.0464, 0.0481, 0.0448,
         0.0742, 0.0518, 0.0502, 0.0567, 0.0474],
        [0.0486, 0.0613, 0.0428, 0.0736, 0.0742, 0.0454, 0.0559, 0.0530, 0.0527,
         0.0436, 0.0521, 0.0624, 0.0530, 0.0597, 0.0633, 0.0453, 0.0540, 0.0529,
         0.0508, 0.0609, 0.0426, 0.0511, 0.0671, 0.0876, 0.0618, 0.0606, 0.0493,
         0.0650, 0.0553, 0.0577, 0.0835, 0.0472],
        [0.0592, 0.0717, 0.0624, 0.0545, 0.0494, 0.0534, 0.0621, 0.0454, 0.0608,
         0.0413, 0.0557, 0.0537, 0.0753, 0.0544, 0.0455, 0.0507, 0.0538, 0.0552,
         0.0509, 0.0477, 0.0495, 0.0509, 0.0594, 0.0491, 0.0417, 0.0473, 0.0529,
         0.0595, 0.0614, 0.0607, 0.0525, 0.0607],
        [0.0575, 0.0480, 0.0449, 0.0637, 0.0793, 0.0515, 0.0957, 0.0434, 0.0740,
         0.0578, 0.0386, 0.0583, 0.0649, 0.0755, 0.0479, 0.0633, 0.0714, 0.0571,
         0.0658, 0.0610, 0.0676, 0.0361, 0.0485, 0.0722, 0.0553, 0.0569, 0.0611,
         0.0732, 0.0588, 0.0532, 0.0413, 0.0785],
        [0.0445, 0.0346, 0.0695, 0.0445, 0.0494, 0.0519, 0.0641, 0.0664, 0.0543,
         0.0606, 0.0484, 0.0605, 0.0593, 0.0531, 0.0641, 0.0532, 0.0407, 0.0579,
         0.0653, 0.0546, 0.0582, 0.0672, 0.0674, 0.0495, 0.0530, 0.0635, 0.0418,
         0.0555, 0.0532, 0.0573, 0.0665, 0.0507],
        [0.0684, 0.0464, 0.0378, 0.0592, 0.0495, 0.0575, 0.0716, 0.0570, 0.0650,
         0.0458, 0.0550, 0.0517, 0.0571, 0.0400, 0.0508, 0.0520, 0.0493, 0.0611,
         0.0497, 0.0669, 0.0731, 0.0418, 0.0571, 0.0466, 0.0777, 0.0515, 0.0717,
         0.0558, 0.0412, 0.0524, 0.0604, 0.0388],
        [0.0433, 0.0417, 0.0597, 0.0598, 0.0811, 0.0632, 0.0773, 0.0567, 0.0545,
         0.0629, 0.0712, 0.0657, 0.0546, 0.0552, 0.0498, 0.0556, 0.0625, 0.0561,
         0.0530, 0.0499, 0.0426, 0.0514, 0.0479, 0.0604, 0.0480, 0.0579, 0.0501,
         0.0718, 0.0506, 0.0532, 0.0631, 0.0726],
        [0.0533, 0.0498, 0.0500, 0.0571, 0.0532, 0.0557, 0.0518, 0.0640, 0.0465,
         0.0699, 0.0538, 0.0411, 0.0452, 0.0591, 0.0569, 0.0669, 0.0421, 0.0543,
         0.0502, 0.0565, 0.0613, 0.0578, 0.0526, 0.0626, 0.0528, 0.0506, 0.0528,
         0.0565, 0.0474, 0.0550, 0.0552, 0.0524],
        [0.0810, 0.0528, 0.0602, 0.0419, 0.0584, 0.0625, 0.0529, 0.0649, 0.0387,
         0.0581, 0.0726, 0.0675, 0.0461, 0.0581, 0.0507, 0.0660, 0.0399, 0.0710,
         0.0615, 0.0493, 0.0557, 0.0400, 0.0542, 0.0572, 0.0599, 0.0537, 0.0880,
         0.0467, 0.0366, 0.0543, 0.0578, 0.0532],
        [0.0529, 0.0573, 0.0507, 0.0527, 0.0661, 0.0420, 0.0486, 0.0594, 0.0515,
         0.0452, 0.0575, 0.0674, 0.0566, 0.0477, 0.0692, 0.0447, 0.0609, 0.0562,
         0.0664, 0.0420, 0.0503, 0.0510, 0.0542, 0.0523, 0.0409, 0.0569, 0.0732,
         0.0607, 0.0609, 0.0543, 0.0587, 0.0618]], device='cuda:0')
***********
SINR = tensor([3.6940, 3.8724, 3.8505, 3.6105, 3.8538, 3.8287, 3.8999, 3.8463, 3.9341,
        3.7622, 3.2565, 3.7154, 3.8624, 3.5844, 3.8204, 3.9095, 3.6696, 3.8772,
        3.8084, 3.8233], device='cuda:0')
Real_SINR = tensor([4.1151, 3.5647, 2.8210, 3.5038, 3.8348, 3.2613, 4.1280, 3.2217, 3.7617,
        3.3831, 3.3459, 2.8984, 3.2525, 3.2461, 3.2563, 4.2637, 3.1970, 4.0635,
        3.2848, 3.8073], device='cuda:0')
Real_SINR_noise.shape = torch.Size([20])
ldm/modules/diffusionmodules/util.py, make_ddim_timsteps ddim_discr_method = uniform
ldm/modules/diffusionmodules/util.py, make_ddim_timsteps, Selected timesteps for ddim sampler: (200,)
ldm/modules/diffusionmodules/util.py, make_ddim_sampling_parameters, Selected alphas for ddim sampler: a_t: torch.Size([200]); a_(t-1): (200,)
For the chosen value of eta, which is 0.0, this results in the following sigma_t schedule for ddim sampler tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], dtype=torch.float64)
ddim.py alphas_cumprod = torch.Size([1000])
ddim.py, alpha_bar_u = tensor([0.7007, 0.7092, 0.7082, 0.6966, 0.7083, 0.7072, 0.7105, 0.7080, 0.7122,
        0.7040, 0.6791, 0.7017, 0.7088, 0.6954, 0.7068, 0.7110, 0.6995, 0.7095,
        0.7062, 0.7069], device='cuda:0')
ddim.py start_timesteps after clamp S = 200 : tensor([234, 229, 229, 236, 229, 230, 228, 229, 227, 232, 247, 233, 229, 237,
        230, 228, 235, 229, 231, 230], device='cuda:0')
d = torch.Size([20, 4, 32, 32])
recoverd_img = torch.Size([20, 3, 256, 256])
20 images are saved in outputs/MIMOdiffusion/M=64/K=32/dynamic/
20 images are saved in outputs/MIMOdiffusion/M=64/K=32/nonoisenosample/
--------SNR = 8,  rho_ul = 0.19717417015006042-----------
G_variance = tensor([1.0704, 1.0184, 1.0417, 1.0446, 0.9887, 0.9888, 0.9963, 1.0122, 0.9994,
        0.9967, 1.0041, 0.9953, 1.0239, 1.0047, 1.0471, 0.9958, 0.9635, 0.9968,
        1.0034, 1.0217], device='cuda:0')
G_hat_variance = tensor([0.9173, 0.8749, 0.8865, 0.8732, 0.8541, 0.8645, 0.8523, 0.8793, 0.8768,
        0.8520, 0.8675, 0.8650, 0.8750, 0.8651, 0.8860, 0.8491, 0.8373, 0.8585,
        0.8738, 0.8918], device='cuda:0')
G_tilde_var = tensor([0.1412, 0.1386, 0.1370, 0.1418, 0.1333, 0.1405, 0.1366, 0.1370, 0.1339,
        0.1336, 0.1372, 0.1344, 0.1384, 0.1385, 0.1384, 0.1408, 0.1357, 0.1352,
        0.1295, 0.1374], device='cuda:0')
gamma = tensor([[[0.8632, 0.8632, 0.8632, 0.8632, 0.8632, 0.8632, 0.8632, 0.8632,
          0.8632, 0.8632, 0.8632, 0.8632, 0.8632, 0.8632, 0.8632, 0.8632,
          0.8632, 0.8632, 0.8632, 0.8632, 0.8632, 0.8632, 0.8632, 0.8632,
          0.8632, 0.8632, 0.8632, 0.8632, 0.8632, 0.8632, 0.8632, 0.8632]]],
       device='cuda:0')
Z_mean = tensor([ 6.9335e-03+0.0021j,  5.5606e-03-0.0096j,  5.5960e-04+0.0074j,
         5.2234e-03+0.0162j, -4.0078e-02-0.0040j, -1.0855e-05-0.0081j,
        -2.6638e-03+0.0116j,  3.2221e-02-0.0009j, -2.4213e-03-0.0061j,
        -2.5235e-03+0.0277j, -1.6068e-02-0.0054j,  2.1585e-02-0.0138j,
        -3.3389e-02+0.0131j, -2.2354e-02+0.0099j,  6.3240e-03-0.0317j,
        -3.6452e-04-0.0043j,  2.2170e-03+0.0043j,  3.9279e-03-0.0025j,
         6.9787e-04-0.0175j, -9.8902e-03+0.0082j], device='cuda:0')
Z_variance ~CN(0, 1)= tensor([1.0627, 1.0136, 1.0270, 1.0116, 0.9894, 1.0015, 0.9874, 1.0186, 1.0157,
        0.9870, 1.0050, 1.0021, 1.0137, 1.0022, 1.0264, 0.9837, 0.9701, 0.9946,
        1.0122, 1.0331], device='cuda:0')
Real_SNR = tensor([8.9157, 8.3310, 9.8281, 8.8945, 8.4414, 8.5575, 7.7419, 8.7772, 8.2384,
        8.5774, 8.5178, 8.0486, 8.9927, 8.7386, 9.0183, 8.1375, 8.1764, 8.5906,
        8.6316, 8.6964], device='cuda:0')
q_var = tensor([1.0001, 1.0002, 1.0002, 1.0002, 0.9999, 1.0002, 1.0000, 1.0002, 0.9999,
        1.0002, 1.0002, 1.0000, 1.0000, 0.9986, 1.0002, 0.9998, 1.0002, 1.0002,
        1.0002, 0.9989], device='cuda:0')
(D_eta_sqrt @ q).var = tensor([1.0001, 1.0002, 1.0002, 1.0002, 0.9999, 1.0002, 1.0000, 1.0002, 0.9999,
        1.0002, 1.0002, 1.0000, 1.0000, 0.9986, 1.0002, 0.9998, 1.0002, 1.0002,
        1.0002, 0.9989], device='cuda:0')
(G @ (D_eta_sqrt @ q)).var = tensor([39.4614, 35.5372, 49.5606, 38.8683, 34.2860, 36.1787, 30.4102, 38.1145,
        34.4758, 36.1054, 34.7798, 31.8534, 39.3575, 37.6988, 40.4337, 32.5875,
        32.8490, 36.3407, 35.4488, 37.9887], device='cuda:0')
signal_var = tensor([7.7808, 7.0070, 9.7721, 7.6638, 6.7603, 7.1335, 5.9961, 7.5152, 6.7977,
        7.1190, 6.8577, 6.2807, 7.7603, 7.4332, 7.9725, 6.4254, 6.4770, 7.1654,
        6.9896, 7.4904], device='cuda:0')
w_var = tensor([0.9987, 1.0290, 1.0167, 0.9885, 0.9679, 0.9944, 1.0085, 0.9959, 1.0198,
        0.9878, 0.9647, 0.9843, 0.9786, 0.9938, 0.9994, 0.9866, 0.9857, 0.9912,
        0.9578, 1.0113], device='cuda:0')
y_var = tensor([ 8.7522,  7.8809, 10.7452,  8.6547,  7.7817,  8.0925,  7.0752,  8.5413,
         7.7585,  8.1864,  7.8086,  7.2889,  8.7394,  8.4625,  8.8372,  7.3383,
         7.4446,  8.1869,  7.8759,  8.4314], device='cuda:0')
####cond finisihed #####
sum_betak_gammak = tensor([4.3778, 4.3778, 4.3778, 4.3778, 4.3778, 4.3778, 4.3778, 4.3778, 4.3778,
        4.3778, 4.3778, 4.3778, 4.3778, 4.3778, 4.3778, 4.3778, 4.3778, 4.3778,
        4.3778, 4.3778], device='cuda:0')
************
inv_Z_H_Z_k (shape: torch.Size([20, 32])) = tensor([[0.0461, 0.0268, 0.0242, 0.0284, 0.0263, 0.0246, 0.0297, 0.0251, 0.0254,
         0.0292, 0.0275, 0.0298, 0.0241, 0.0253, 0.0294, 0.0292, 0.0287, 0.0227,
         0.0247, 0.0289, 0.0229, 0.0261, 0.0316, 0.0349, 0.0343, 0.0285, 0.0302,
         0.0256, 0.0207, 0.0317, 0.0235, 0.0275],
        [0.0304, 0.0277, 0.0286, 0.0432, 0.0421, 0.0273, 0.0357, 0.0284, 0.0330,
         0.0256, 0.0231, 0.0244, 0.0287, 0.0395, 0.0238, 0.0254, 0.0256, 0.0271,
         0.0239, 0.0285, 0.0293, 0.0239, 0.0255, 0.0306, 0.0242, 0.0296, 0.0255,
         0.0324, 0.0408, 0.0305, 0.0424, 0.0271],
        [0.0305, 0.0332, 0.0242, 0.0370, 0.0257, 0.0241, 0.0244, 0.0213, 0.0242,
         0.0322, 0.0260, 0.0333, 0.0253, 0.0220, 0.0284, 0.0291, 0.0307, 0.0214,
         0.0335, 0.0324, 0.0330, 0.0382, 0.0281, 0.0222, 0.0413, 0.0242, 0.0270,
         0.0317, 0.0219, 0.0300, 0.0369, 0.0250],
        [0.0350, 0.0299, 0.0277, 0.0364, 0.0328, 0.0271, 0.0428, 0.0408, 0.0191,
         0.0322, 0.0398, 0.0251, 0.0322, 0.0451, 0.0395, 0.0341, 0.0323, 0.0333,
         0.0306, 0.0243, 0.0318, 0.0286, 0.0294, 0.0270, 0.0339, 0.0339, 0.0340,
         0.0299, 0.0464, 0.0398, 0.0323, 0.0234],
        [0.0362, 0.0293, 0.0250, 0.0340, 0.0357, 0.0285, 0.0304, 0.0360, 0.0253,
         0.0320, 0.0245, 0.0301, 0.0296, 0.0325, 0.0305, 0.0266, 0.0303, 0.0316,
         0.0323, 0.0232, 0.0279, 0.0259, 0.0283, 0.0365, 0.0344, 0.0260, 0.0310,
         0.0379, 0.0317, 0.0314, 0.0306, 0.0308],
        [0.0265, 0.0310, 0.0285, 0.0326, 0.0367, 0.0226, 0.0356, 0.0262, 0.0280,
         0.0292, 0.0368, 0.0271, 0.0245, 0.0334, 0.0337, 0.0299, 0.0312, 0.0412,
         0.0278, 0.0243, 0.0201, 0.0314, 0.0389, 0.0318, 0.0317, 0.0307, 0.0318,
         0.0268, 0.0337, 0.0268, 0.0275, 0.0396],
        [0.0267, 0.0277, 0.0402, 0.0260, 0.0394, 0.0306, 0.0220, 0.0254, 0.0252,
         0.0292, 0.0278, 0.0281, 0.0314, 0.0343, 0.0288, 0.0292, 0.0256, 0.0374,
         0.0288, 0.0290, 0.0334, 0.0350, 0.0257, 0.0339, 0.0289, 0.0328, 0.0306,
         0.0304, 0.0521, 0.0430, 0.0295, 0.0284],
        [0.0283, 0.0302, 0.0326, 0.0210, 0.0299, 0.0233, 0.0265, 0.0260, 0.0247,
         0.0292, 0.0305, 0.0274, 0.0359, 0.0243, 0.0278, 0.0245, 0.0327, 0.0315,
         0.0323, 0.0331, 0.0294, 0.0281, 0.0285, 0.0223, 0.0276, 0.0299, 0.0256,
         0.0250, 0.0282, 0.0286, 0.0410, 0.0267],
        [0.0243, 0.0272, 0.0454, 0.0261, 0.0326, 0.0261, 0.0338, 0.0277, 0.0319,
         0.0336, 0.0285, 0.0345, 0.0317, 0.0332, 0.0331, 0.0425, 0.0233, 0.0267,
         0.0327, 0.0272, 0.0281, 0.0250, 0.0327, 0.0306, 0.0275, 0.0231, 0.0301,
         0.0283, 0.0271, 0.0315, 0.0230, 0.0279],
        [0.0297, 0.0277, 0.0406, 0.0404, 0.0323, 0.0302, 0.0284, 0.0271, 0.0361,
         0.0230, 0.0327, 0.0409, 0.0490, 0.0258, 0.0395, 0.0356, 0.0264, 0.0240,
         0.0312, 0.0409, 0.0321, 0.0374, 0.0292, 0.0243, 0.0293, 0.0258, 0.0245,
         0.0325, 0.0314, 0.0308, 0.0290, 0.0356],
        [0.0485, 0.0306, 0.0357, 0.0275, 0.0445, 0.0386, 0.0279, 0.0281, 0.0406,
         0.0357, 0.0369, 0.0257, 0.0336, 0.0350, 0.0300, 0.0327, 0.0261, 0.0367,
         0.0420, 0.0332, 0.0436, 0.0237, 0.0409, 0.0305, 0.0300, 0.0273, 0.0442,
         0.0508, 0.0378, 0.0301, 0.0305, 0.0417],
        [0.0324, 0.0250, 0.0396, 0.0334, 0.0325, 0.0337, 0.0374, 0.0221, 0.0305,
         0.0298, 0.0319, 0.0398, 0.0418, 0.0295, 0.0404, 0.0234, 0.0360, 0.0334,
         0.0364, 0.0264, 0.0287, 0.0315, 0.0296, 0.0363, 0.0353, 0.0365, 0.0376,
         0.0319, 0.0300, 0.0311, 0.0376, 0.0314],
        [0.0282, 0.0268, 0.0353, 0.0278, 0.0276, 0.0365, 0.0383, 0.0411, 0.0221,
         0.0227, 0.0289, 0.0267, 0.0310, 0.0307, 0.0392, 0.0373, 0.0316, 0.0338,
         0.0288, 0.0414, 0.0330, 0.0303, 0.0285, 0.0377, 0.0289, 0.0320, 0.0276,
         0.0349, 0.0296, 0.0265, 0.0245, 0.0265],
        [0.0303, 0.0295, 0.0245, 0.0312, 0.0338, 0.0287, 0.0394, 0.0270, 0.0270,
         0.0289, 0.0282, 0.0312, 0.0315, 0.0400, 0.0276, 0.0444, 0.0419, 0.0288,
         0.0352, 0.0309, 0.0272, 0.0217, 0.0303, 0.0294, 0.0285, 0.0303, 0.0298,
         0.0352, 0.0334, 0.0318, 0.0210, 0.0246],
        [0.0227, 0.0214, 0.0304, 0.0302, 0.0310, 0.0276, 0.0342, 0.0282, 0.0239,
         0.0401, 0.0299, 0.0309, 0.0377, 0.0289, 0.0280, 0.0265, 0.0237, 0.0248,
         0.0275, 0.0298, 0.0404, 0.0273, 0.0220, 0.0366, 0.0298, 0.0326, 0.0252,
         0.0267, 0.0245, 0.0290, 0.0314, 0.0248],
        [0.0501, 0.0314, 0.0343, 0.0344, 0.0410, 0.0340, 0.0284, 0.0321, 0.0245,
         0.0308, 0.0321, 0.0346, 0.0372, 0.0311, 0.0332, 0.0339, 0.0371, 0.0277,
         0.0251, 0.0295, 0.0351, 0.0297, 0.0375, 0.0234, 0.0308, 0.0290, 0.0288,
         0.0237, 0.0435, 0.0315, 0.0374, 0.0328],
        [0.0283, 0.0341, 0.0366, 0.0391, 0.0295, 0.0419, 0.0274, 0.0359, 0.0278,
         0.0292, 0.0315, 0.0255, 0.0261, 0.0311, 0.0293, 0.0278, 0.0307, 0.0367,
         0.0252, 0.0342, 0.0345, 0.0298, 0.0348, 0.0399, 0.0282, 0.0329, 0.0279,
         0.0279, 0.0273, 0.0259, 0.0329, 0.0274],
        [0.0237, 0.0390, 0.0248, 0.0404, 0.0306, 0.0408, 0.0327, 0.0299, 0.0390,
         0.0295, 0.0230, 0.0292, 0.0236, 0.0389, 0.0366, 0.0333, 0.0479, 0.0341,
         0.0422, 0.0307, 0.0276, 0.0292, 0.0342, 0.0343, 0.0294, 0.0248, 0.0337,
         0.0324, 0.0433, 0.0286, 0.0257, 0.0254],
        [0.0321, 0.0341, 0.0374, 0.0243, 0.0290, 0.0366, 0.0358, 0.0268, 0.0278,
         0.0282, 0.0261, 0.0255, 0.0287, 0.0304, 0.0326, 0.0305, 0.0226, 0.0253,
         0.0237, 0.0332, 0.0362, 0.0268, 0.0334, 0.0344, 0.0338, 0.0277, 0.0290,
         0.0212, 0.0422, 0.0335, 0.0364, 0.0242],
        [0.0256, 0.0372, 0.0351, 0.0277, 0.0327, 0.0288, 0.0297, 0.0221, 0.0156,
         0.0318, 0.0319, 0.0310, 0.0244, 0.0316, 0.0236, 0.0315, 0.0274, 0.0502,
         0.0296, 0.0295, 0.0281, 0.0376, 0.0382, 0.0346, 0.0405, 0.0292, 0.0271,
         0.0381, 0.0289, 0.0271, 0.0280, 0.0254]], device='cuda:0')
inv_Z_H_Z_k.mean (expected to be = 0.03124999990234375) = 0.0308903306722641
Var (shape: torch.Size([20, 32])) = tensor([[0.0858, 0.0499, 0.0451, 0.0529, 0.0490, 0.0458, 0.0553, 0.0467, 0.0473,
         0.0544, 0.0512, 0.0555, 0.0448, 0.0472, 0.0548, 0.0544, 0.0536, 0.0422,
         0.0460, 0.0538, 0.0427, 0.0487, 0.0588, 0.0650, 0.0639, 0.0531, 0.0563,
         0.0477, 0.0385, 0.0591, 0.0438, 0.0513],
        [0.0566, 0.0517, 0.0532, 0.0805, 0.0785, 0.0509, 0.0665, 0.0530, 0.0616,
         0.0477, 0.0430, 0.0455, 0.0535, 0.0735, 0.0444, 0.0474, 0.0477, 0.0504,
         0.0445, 0.0532, 0.0547, 0.0444, 0.0475, 0.0571, 0.0450, 0.0551, 0.0475,
         0.0603, 0.0761, 0.0568, 0.0790, 0.0504],
        [0.0568, 0.0618, 0.0450, 0.0689, 0.0480, 0.0449, 0.0455, 0.0398, 0.0451,
         0.0599, 0.0485, 0.0620, 0.0472, 0.0410, 0.0529, 0.0543, 0.0573, 0.0399,
         0.0623, 0.0604, 0.0616, 0.0712, 0.0524, 0.0414, 0.0769, 0.0451, 0.0503,
         0.0591, 0.0407, 0.0559, 0.0687, 0.0466],
        [0.0652, 0.0557, 0.0516, 0.0678, 0.0612, 0.0505, 0.0798, 0.0761, 0.0355,
         0.0600, 0.0741, 0.0467, 0.0600, 0.0841, 0.0735, 0.0636, 0.0602, 0.0620,
         0.0570, 0.0452, 0.0592, 0.0533, 0.0547, 0.0504, 0.0632, 0.0631, 0.0633,
         0.0558, 0.0865, 0.0742, 0.0603, 0.0437],
        [0.0675, 0.0546, 0.0466, 0.0633, 0.0665, 0.0531, 0.0567, 0.0672, 0.0471,
         0.0596, 0.0456, 0.0562, 0.0551, 0.0606, 0.0568, 0.0495, 0.0564, 0.0589,
         0.0602, 0.0433, 0.0519, 0.0482, 0.0528, 0.0680, 0.0641, 0.0484, 0.0578,
         0.0706, 0.0590, 0.0584, 0.0570, 0.0574],
        [0.0493, 0.0577, 0.0531, 0.0608, 0.0684, 0.0421, 0.0663, 0.0489, 0.0522,
         0.0544, 0.0686, 0.0505, 0.0457, 0.0623, 0.0627, 0.0557, 0.0580, 0.0767,
         0.0518, 0.0453, 0.0374, 0.0585, 0.0724, 0.0593, 0.0590, 0.0571, 0.0592,
         0.0500, 0.0628, 0.0499, 0.0512, 0.0738],
        [0.0497, 0.0516, 0.0749, 0.0484, 0.0734, 0.0570, 0.0411, 0.0473, 0.0470,
         0.0543, 0.0518, 0.0523, 0.0585, 0.0638, 0.0537, 0.0543, 0.0477, 0.0697,
         0.0536, 0.0541, 0.0623, 0.0653, 0.0478, 0.0631, 0.0539, 0.0612, 0.0570,
         0.0567, 0.0971, 0.0801, 0.0550, 0.0529],
        [0.0527, 0.0563, 0.0607, 0.0391, 0.0557, 0.0434, 0.0493, 0.0485, 0.0459,
         0.0544, 0.0569, 0.0511, 0.0668, 0.0452, 0.0517, 0.0457, 0.0608, 0.0586,
         0.0602, 0.0617, 0.0547, 0.0524, 0.0530, 0.0415, 0.0514, 0.0558, 0.0476,
         0.0466, 0.0526, 0.0533, 0.0763, 0.0498],
        [0.0454, 0.0508, 0.0846, 0.0487, 0.0608, 0.0486, 0.0630, 0.0517, 0.0595,
         0.0627, 0.0530, 0.0643, 0.0591, 0.0618, 0.0616, 0.0792, 0.0434, 0.0498,
         0.0609, 0.0507, 0.0524, 0.0466, 0.0610, 0.0571, 0.0512, 0.0430, 0.0561,
         0.0528, 0.0506, 0.0587, 0.0428, 0.0519],
        [0.0554, 0.0516, 0.0756, 0.0752, 0.0601, 0.0562, 0.0530, 0.0505, 0.0672,
         0.0428, 0.0608, 0.0762, 0.0913, 0.0482, 0.0735, 0.0664, 0.0491, 0.0448,
         0.0582, 0.0761, 0.0599, 0.0698, 0.0545, 0.0453, 0.0547, 0.0481, 0.0457,
         0.0605, 0.0585, 0.0574, 0.0541, 0.0664],
        [0.0904, 0.0571, 0.0666, 0.0512, 0.0828, 0.0720, 0.0520, 0.0524, 0.0757,
         0.0665, 0.0687, 0.0480, 0.0626, 0.0652, 0.0558, 0.0609, 0.0486, 0.0683,
         0.0783, 0.0619, 0.0812, 0.0441, 0.0763, 0.0568, 0.0560, 0.0510, 0.0823,
         0.0946, 0.0704, 0.0561, 0.0568, 0.0777],
        [0.0603, 0.0466, 0.0738, 0.0622, 0.0605, 0.0627, 0.0697, 0.0412, 0.0568,
         0.0554, 0.0594, 0.0741, 0.0779, 0.0550, 0.0752, 0.0437, 0.0671, 0.0623,
         0.0678, 0.0492, 0.0534, 0.0587, 0.0552, 0.0677, 0.0658, 0.0680, 0.0701,
         0.0594, 0.0558, 0.0579, 0.0700, 0.0584],
        [0.0525, 0.0499, 0.0658, 0.0517, 0.0515, 0.0680, 0.0714, 0.0766, 0.0412,
         0.0423, 0.0538, 0.0498, 0.0578, 0.0572, 0.0731, 0.0695, 0.0588, 0.0630,
         0.0537, 0.0771, 0.0615, 0.0565, 0.0532, 0.0703, 0.0538, 0.0597, 0.0515,
         0.0650, 0.0552, 0.0494, 0.0456, 0.0494],
        [0.0565, 0.0549, 0.0456, 0.0582, 0.0629, 0.0535, 0.0735, 0.0503, 0.0504,
         0.0538, 0.0526, 0.0582, 0.0586, 0.0746, 0.0515, 0.0828, 0.0781, 0.0536,
         0.0656, 0.0576, 0.0506, 0.0404, 0.0564, 0.0547, 0.0530, 0.0565, 0.0556,
         0.0657, 0.0622, 0.0593, 0.0391, 0.0459],
        [0.0424, 0.0398, 0.0566, 0.0563, 0.0578, 0.0514, 0.0638, 0.0526, 0.0446,
         0.0747, 0.0558, 0.0576, 0.0702, 0.0539, 0.0521, 0.0494, 0.0441, 0.0463,
         0.0513, 0.0555, 0.0753, 0.0508, 0.0411, 0.0683, 0.0556, 0.0608, 0.0470,
         0.0498, 0.0457, 0.0540, 0.0585, 0.0463],
        [0.0933, 0.0585, 0.0638, 0.0641, 0.0764, 0.0633, 0.0529, 0.0598, 0.0456,
         0.0573, 0.0598, 0.0644, 0.0692, 0.0579, 0.0618, 0.0632, 0.0690, 0.0516,
         0.0468, 0.0550, 0.0654, 0.0553, 0.0698, 0.0436, 0.0573, 0.0541, 0.0536,
         0.0441, 0.0810, 0.0587, 0.0696, 0.0611],
        [0.0526, 0.0635, 0.0682, 0.0729, 0.0549, 0.0780, 0.0511, 0.0670, 0.0518,
         0.0543, 0.0586, 0.0475, 0.0487, 0.0579, 0.0546, 0.0519, 0.0573, 0.0685,
         0.0469, 0.0637, 0.0642, 0.0556, 0.0648, 0.0743, 0.0525, 0.0613, 0.0520,
         0.0521, 0.0508, 0.0483, 0.0614, 0.0511],
        [0.0442, 0.0727, 0.0462, 0.0753, 0.0570, 0.0760, 0.0610, 0.0557, 0.0726,
         0.0550, 0.0428, 0.0544, 0.0439, 0.0725, 0.0683, 0.0620, 0.0892, 0.0635,
         0.0785, 0.0573, 0.0513, 0.0544, 0.0637, 0.0639, 0.0548, 0.0461, 0.0627,
         0.0604, 0.0806, 0.0534, 0.0479, 0.0474],
        [0.0599, 0.0636, 0.0696, 0.0452, 0.0540, 0.0682, 0.0667, 0.0500, 0.0518,
         0.0525, 0.0486, 0.0474, 0.0535, 0.0567, 0.0607, 0.0568, 0.0421, 0.0471,
         0.0441, 0.0619, 0.0674, 0.0500, 0.0622, 0.0642, 0.0630, 0.0516, 0.0540,
         0.0394, 0.0786, 0.0624, 0.0678, 0.0451],
        [0.0477, 0.0694, 0.0654, 0.0517, 0.0609, 0.0536, 0.0553, 0.0412, 0.0290,
         0.0592, 0.0594, 0.0578, 0.0455, 0.0589, 0.0439, 0.0586, 0.0511, 0.0935,
         0.0552, 0.0549, 0.0523, 0.0700, 0.0712, 0.0644, 0.0754, 0.0545, 0.0505,
         0.0710, 0.0538, 0.0506, 0.0523, 0.0474]], device='cuda:0')
***********
SINR = tensor([5.2459, 5.0075, 5.1700, 4.6058, 4.8313, 4.8707, 4.8062, 5.1377, 4.9537,
        4.7033, 4.3277, 4.5356, 4.7891, 4.8508, 5.0941, 4.5846, 4.7519, 4.6562,
        4.9117, 4.9332], device='cuda:0')
Real_SINR = tensor([4.6801, 4.7890, 4.2227, 4.6277, 4.7534, 4.3754, 4.1610, 4.4945, 4.7260,
        4.3124, 4.0202, 4.3859, 4.5115, 4.2765, 5.1895, 4.4422, 4.3273, 4.6719,
        4.8540, 4.4519], device='cuda:0')
Real_SINR_noise.shape = torch.Size([20])
ldm/modules/diffusionmodules/util.py, make_ddim_timsteps ddim_discr_method = uniform
ldm/modules/diffusionmodules/util.py, make_ddim_timsteps, Selected timesteps for ddim sampler: (200,)
ldm/modules/diffusionmodules/util.py, make_ddim_sampling_parameters, Selected alphas for ddim sampler: a_t: torch.Size([200]); a_(t-1): (200,)
For the chosen value of eta, which is 0.0, this results in the following sigma_t schedule for ddim sampler tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], dtype=torch.float64)
ddim.py alphas_cumprod = torch.Size([1000])
ddim.py, alpha_bar_u = tensor([0.7699, 0.7601, 0.7668, 0.7428, 0.7526, 0.7543, 0.7515, 0.7655, 0.7578,
        0.7471, 0.7304, 0.7397, 0.7508, 0.7534, 0.7637, 0.7419, 0.7492, 0.7450,
        0.7560, 0.7569], device='cuda:0')
ddim.py start_timesteps after clamp S = 200 : tensor([190, 196, 192, 208, 201, 200, 202, 193, 198, 205, 215, 209, 202, 201,
        194, 208, 203, 206, 199, 198], device='cuda:0')
d = torch.Size([20, 4, 32, 32])
recoverd_img = torch.Size([20, 3, 256, 256])
20 images are saved in outputs/MIMOdiffusion/M=64/K=32/dynamic/
20 images are saved in outputs/MIMOdiffusion/M=64/K=32/nonoisenosample/
--------SNR = 9,  rho_ul = 0.248227573351338-----------
G_variance = tensor([0.9895, 1.0532, 0.9597, 0.9999, 1.0119, 1.0263, 0.9967, 0.9926, 0.9804,
        1.0061, 0.9998, 0.9950, 1.0117, 0.9702, 0.9909, 1.0460, 1.0090, 0.9656,
        1.0140, 1.0085], device='cuda:0')
G_hat_variance = tensor([0.8644, 0.9405, 0.8468, 0.8830, 0.9083, 0.9119, 0.8860, 0.8867, 0.8744,
        0.8861, 0.8832, 0.8871, 0.8890, 0.8657, 0.8757, 0.9057, 0.9042, 0.8581,
        0.8912, 0.9032], device='cuda:0')
G_tilde_var = tensor([0.1136, 0.1137, 0.1143, 0.1154, 0.1104, 0.1106, 0.1114, 0.1088, 0.1103,
        0.1101, 0.1149, 0.1111, 0.1139, 0.1104, 0.1101, 0.1133, 0.1113, 0.1123,
        0.1131, 0.1106], device='cuda:0')
gamma = tensor([[[0.8882, 0.8882, 0.8882, 0.8882, 0.8882, 0.8882, 0.8882, 0.8882,
          0.8882, 0.8882, 0.8882, 0.8882, 0.8882, 0.8882, 0.8882, 0.8882,
          0.8882, 0.8882, 0.8882, 0.8882, 0.8882, 0.8882, 0.8882, 0.8882,
          0.8882, 0.8882, 0.8882, 0.8882, 0.8882, 0.8882, 0.8882, 0.8882]]],
       device='cuda:0')
Z_mean = tensor([ 0.0257-0.0084j,  0.0110+0.0289j, -0.0200-0.0022j, -0.0012-0.0061j,
        -0.0226+0.0296j, -0.0095+0.0006j, -0.0035+0.0168j,  0.0166-0.0018j,
        -0.0123-0.0181j,  0.0168+0.0126j,  0.0077+0.0247j,  0.0089+0.0224j,
         0.0220-0.0045j, -0.0152-0.0098j, -0.0153-0.0008j,  0.0108+0.0234j,
         0.0171-0.0110j,  0.0310-0.0092j,  0.0154+0.0116j,  0.0019+0.0003j],
       device='cuda:0')
Z_variance ~CN(0, 1)= tensor([0.9732, 1.0589, 0.9534, 0.9942, 1.0226, 1.0267, 0.9975, 0.9983, 0.9845,
        0.9976, 0.9944, 0.9988, 1.0009, 0.9747, 0.9859, 1.0198, 1.0180, 0.9661,
        1.0034, 1.0169], device='cuda:0')
Real_SNR = tensor([ 8.7635,  9.8953, 10.0105,  8.8491,  9.1465,  9.6963,  9.3454,  9.8340,
         9.3401,  9.6890,  8.9857,  9.5057,  9.6946,  9.4283,  9.8612,  9.5582,
         8.9546,  9.2336,  9.6398,  9.5550], device='cuda:0')
q_var = tensor([1.0001, 1.0002, 1.0002, 1.0002, 0.9999, 1.0002, 1.0000, 1.0002, 0.9999,
        1.0002, 1.0002, 1.0000, 1.0000, 0.9986, 1.0002, 0.9998, 1.0002, 1.0002,
        1.0002, 0.9989], device='cuda:0')
(D_eta_sqrt @ q).var = tensor([1.0001, 1.0002, 1.0002, 1.0002, 0.9999, 1.0002, 1.0000, 1.0002, 0.9999,
        1.0002, 1.0002, 1.0000, 1.0000, 0.9986, 1.0002, 0.9998, 1.0002, 1.0002,
        1.0002, 0.9989], device='cuda:0')
(G @ (D_eta_sqrt @ q)).var = tensor([29.8183, 38.4889, 40.2812, 31.5346, 32.2000, 37.6507, 34.7579, 38.5324,
        35.1536, 36.8094, 32.4781, 34.9443, 37.5048, 35.4102, 39.1228, 37.3199,
        31.4908, 34.4608, 36.9972, 36.0619], device='cuda:0')
signal_var = tensor([7.4017, 9.5540, 9.9989, 7.8278, 7.9929, 9.3459, 8.6279, 9.5648, 8.7261,
        9.1371, 8.0620, 8.6741, 9.3097, 8.7898, 9.7114, 9.2638, 7.8169, 8.5541,
        9.1837, 8.9516], device='cuda:0')
w_var = tensor([0.9840, 0.9787, 0.9975, 1.0203, 0.9729, 1.0023, 1.0032, 0.9938, 1.0158,
        0.9815, 1.0183, 0.9720, 0.9988, 1.0027, 1.0027, 1.0256, 0.9944, 1.0205,
        0.9978, 0.9917], device='cuda:0')
y_var = tensor([ 8.4261, 10.6131, 10.8451,  8.8341,  9.0470, 10.2644,  9.6876, 10.5753,
         9.7478, 10.0846,  9.1315,  9.7350, 10.2788,  9.7779, 10.7333, 10.2592,
         8.8554,  9.6697, 10.2194,  9.9308], device='cuda:0')
####cond finisihed #####
sum_betak_gammak = tensor([3.5781, 3.5781, 3.5781, 3.5781, 3.5781, 3.5781, 3.5781, 3.5781, 3.5781,
        3.5781, 3.5781, 3.5781, 3.5781, 3.5781, 3.5781, 3.5781, 3.5781, 3.5781,
        3.5781, 3.5781], device='cuda:0')
************
inv_Z_H_Z_k (shape: torch.Size([20, 32])) = tensor([[0.0360, 0.0292, 0.0299, 0.0457, 0.0391, 0.0295, 0.0395, 0.0239, 0.0267,
         0.0279, 0.0284, 0.0348, 0.0337, 0.0280, 0.0278, 0.0451, 0.0416, 0.0257,
         0.0309, 0.0404, 0.0325, 0.0227, 0.0295, 0.0363, 0.0308, 0.0298, 0.0333,
         0.0288, 0.0353, 0.0306, 0.0299, 0.0272],
        [0.0227, 0.0333, 0.0230, 0.0237, 0.0259, 0.0259, 0.0270, 0.0280, 0.0295,
         0.0285, 0.0363, 0.0363, 0.0401, 0.0330, 0.0253, 0.0288, 0.0275, 0.0263,
         0.0218, 0.0292, 0.0386, 0.0301, 0.0275, 0.0225, 0.0430, 0.0267, 0.0344,
         0.0318, 0.0347, 0.0275, 0.0221, 0.0333],
        [0.0406, 0.0374, 0.0393, 0.0392, 0.0399, 0.0374, 0.0335, 0.0367, 0.0398,
         0.0332, 0.0382, 0.0346, 0.0304, 0.0449, 0.0330, 0.0342, 0.0387, 0.0221,
         0.0416, 0.0435, 0.0401, 0.0239, 0.0383, 0.0250, 0.0395, 0.0281, 0.0401,
         0.0316, 0.0239, 0.0303, 0.0424, 0.0289],
        [0.0234, 0.0326, 0.0247, 0.0365, 0.0262, 0.0382, 0.0256, 0.0343, 0.0324,
         0.0334, 0.0221, 0.0350, 0.0225, 0.0262, 0.0319, 0.0289, 0.0294, 0.0331,
         0.0353, 0.0276, 0.0344, 0.0305, 0.0275, 0.0282, 0.0230, 0.0348, 0.0263,
         0.0295, 0.0322, 0.0277, 0.0360, 0.0277],
        [0.0328, 0.0362, 0.0382, 0.0358, 0.0263, 0.0262, 0.0242, 0.0380, 0.0293,
         0.0379, 0.0305, 0.0260, 0.0221, 0.0329, 0.0340, 0.0272, 0.0221, 0.0346,
         0.0293, 0.0386, 0.0225, 0.0329, 0.0325, 0.0216, 0.0355, 0.0376, 0.0362,
         0.0267, 0.0386, 0.0315, 0.0446, 0.0220],
        [0.0324, 0.0252, 0.0246, 0.0381, 0.0314, 0.0368, 0.0272, 0.0300, 0.0213,
         0.0258, 0.0280, 0.0360, 0.0363, 0.0304, 0.0254, 0.0272, 0.0300, 0.0301,
         0.0210, 0.0300, 0.0248, 0.0277, 0.0459, 0.0276, 0.0252, 0.0268, 0.0406,
         0.0242, 0.0295, 0.0285, 0.0200, 0.0344],
        [0.0319, 0.0275, 0.0336, 0.0283, 0.0349, 0.0270, 0.0351, 0.0306, 0.0295,
         0.0266, 0.0329, 0.0290, 0.0189, 0.0272, 0.0271, 0.0352, 0.0289, 0.0313,
         0.0369, 0.0308, 0.0304, 0.0274, 0.0325, 0.0299, 0.0269, 0.0270, 0.0340,
         0.0332, 0.0322, 0.0280, 0.0235, 0.0385],
        [0.0353, 0.0398, 0.0321, 0.0289, 0.0270, 0.0343, 0.0327, 0.0260, 0.0316,
         0.0336, 0.0387, 0.0333, 0.0299, 0.0395, 0.0394, 0.0227, 0.0252, 0.0304,
         0.0278, 0.0332, 0.0272, 0.0300, 0.0465, 0.0247, 0.0306, 0.0257, 0.0334,
         0.0268, 0.0349, 0.0272, 0.0367, 0.0315],
        [0.0252, 0.0365, 0.0358, 0.0381, 0.0307, 0.0358, 0.0292, 0.0319, 0.0405,
         0.0274, 0.0373, 0.0232, 0.0316, 0.0340, 0.0292, 0.0332, 0.0297, 0.0262,
         0.0343, 0.0353, 0.0350, 0.0347, 0.0398, 0.0354, 0.0353, 0.0204, 0.0260,
         0.0292, 0.0246, 0.0368, 0.0287, 0.0282],
        [0.0230, 0.0358, 0.0269, 0.0269, 0.0282, 0.0320, 0.0297, 0.0343, 0.0272,
         0.0238, 0.0263, 0.0252, 0.0285, 0.0274, 0.0254, 0.0283, 0.0329, 0.0251,
         0.0271, 0.0362, 0.0306, 0.0351, 0.0256, 0.0293, 0.0305, 0.0253, 0.0310,
         0.0276, 0.0353, 0.0393, 0.0279, 0.0293],
        [0.0263, 0.0329, 0.0366, 0.0264, 0.0272, 0.0336, 0.0244, 0.0265, 0.0355,
         0.0271, 0.0289, 0.0316, 0.0239, 0.0259, 0.0498, 0.0238, 0.0374, 0.0262,
         0.0328, 0.0331, 0.0299, 0.0254, 0.0270, 0.0389, 0.0281, 0.0308, 0.0419,
         0.0224, 0.0331, 0.0246, 0.0297, 0.0279],
        [0.0390, 0.0366, 0.0320, 0.0243, 0.0344, 0.0357, 0.0407, 0.0326, 0.0291,
         0.0310, 0.0241, 0.0297, 0.0352, 0.0275, 0.0288, 0.0260, 0.0425, 0.0276,
         0.0201, 0.0313, 0.0396, 0.0323, 0.0308, 0.0260, 0.0311, 0.0295, 0.0249,
         0.0305, 0.0248, 0.0301, 0.0257, 0.0367],
        [0.0289, 0.0280, 0.0288, 0.0307, 0.0329, 0.0367, 0.0303, 0.0304, 0.0435,
         0.0341, 0.0268, 0.0324, 0.0322, 0.0264, 0.0241, 0.0332, 0.0233, 0.0316,
         0.0233, 0.0253, 0.0237, 0.0409, 0.0302, 0.0333, 0.0316, 0.0331, 0.0245,
         0.0300, 0.0332, 0.0333, 0.0256, 0.0299],
        [0.0308, 0.0311, 0.0313, 0.0281, 0.0314, 0.0408, 0.0263, 0.0384, 0.0277,
         0.0323, 0.0357, 0.0325, 0.0288, 0.0378, 0.0275, 0.0342, 0.0310, 0.0320,
         0.0329, 0.0262, 0.0282, 0.0454, 0.0325, 0.0467, 0.0460, 0.0331, 0.0315,
         0.0347, 0.0421, 0.0503, 0.0379, 0.0330],
        [0.0298, 0.0323, 0.0379, 0.0273, 0.0488, 0.0332, 0.0317, 0.0242, 0.0310,
         0.0326, 0.0351, 0.0409, 0.0278, 0.0271, 0.0414, 0.0275, 0.0205, 0.0292,
         0.0267, 0.0424, 0.0486, 0.0346, 0.0395, 0.0338, 0.0343, 0.0279, 0.0261,
         0.0370, 0.0425, 0.0417, 0.0262, 0.0337],
        [0.0342, 0.0289, 0.0273, 0.0236, 0.0283, 0.0286, 0.0269, 0.0253, 0.0258,
         0.0350, 0.0288, 0.0287, 0.0421, 0.0285, 0.0215, 0.0266, 0.0282, 0.0298,
         0.0332, 0.0355, 0.0337, 0.0302, 0.0290, 0.0291, 0.0315, 0.0268, 0.0228,
         0.0384, 0.0304, 0.0322, 0.0322, 0.0330],
        [0.0263, 0.0250, 0.0303, 0.0257, 0.0335, 0.0355, 0.0251, 0.0411, 0.0354,
         0.0291, 0.0310, 0.0277, 0.0301, 0.0344, 0.0334, 0.0265, 0.0244, 0.0270,
         0.0254, 0.0324, 0.0343, 0.0203, 0.0283, 0.0363, 0.0286, 0.0276, 0.0374,
         0.0248, 0.0210, 0.0374, 0.0267, 0.0374],
        [0.0289, 0.0489, 0.0360, 0.0357, 0.0329, 0.0357, 0.0296, 0.0304, 0.0315,
         0.0452, 0.0271, 0.0328, 0.0309, 0.0303, 0.0233, 0.0353, 0.0257, 0.0487,
         0.0425, 0.0223, 0.0301, 0.0236, 0.0341, 0.0288, 0.0321, 0.0304, 0.0327,
         0.0309, 0.0363, 0.0276, 0.0360, 0.0486],
        [0.0289, 0.0271, 0.0411, 0.0275, 0.0303, 0.0276, 0.0286, 0.0275, 0.0381,
         0.0250, 0.0280, 0.0330, 0.0386, 0.0278, 0.0355, 0.0314, 0.0271, 0.0243,
         0.0311, 0.0269, 0.0378, 0.0341, 0.0418, 0.0254, 0.0343, 0.0304, 0.0312,
         0.0329, 0.0286, 0.0260, 0.0281, 0.0234],
        [0.0218, 0.0271, 0.0315, 0.0275, 0.0274, 0.0295, 0.0250, 0.0303, 0.0454,
         0.0278, 0.0251, 0.0199, 0.0280, 0.0308, 0.0281, 0.0266, 0.0268, 0.0308,
         0.0309, 0.0380, 0.0373, 0.0290, 0.0248, 0.0231, 0.0213, 0.0305, 0.0284,
         0.0233, 0.0257, 0.0355, 0.0303, 0.0240]], device='cuda:0')
inv_Z_H_Z_k.mean (expected to be = 0.03124999990234375) = 0.03113027848303318
Var (shape: torch.Size([20, 32])) = tensor([[0.0680, 0.0551, 0.0565, 0.0863, 0.0739, 0.0557, 0.0745, 0.0452, 0.0505,
         0.0527, 0.0537, 0.0658, 0.0636, 0.0529, 0.0525, 0.0851, 0.0786, 0.0485,
         0.0583, 0.0762, 0.0613, 0.0428, 0.0557, 0.0684, 0.0582, 0.0563, 0.0629,
         0.0544, 0.0667, 0.0577, 0.0565, 0.0513],
        [0.0429, 0.0630, 0.0435, 0.0447, 0.0490, 0.0489, 0.0509, 0.0528, 0.0556,
         0.0539, 0.0685, 0.0685, 0.0757, 0.0624, 0.0478, 0.0544, 0.0519, 0.0496,
         0.0412, 0.0552, 0.0729, 0.0569, 0.0520, 0.0426, 0.0812, 0.0505, 0.0650,
         0.0600, 0.0654, 0.0519, 0.0417, 0.0629],
        [0.0767, 0.0707, 0.0742, 0.0739, 0.0754, 0.0706, 0.0632, 0.0693, 0.0752,
         0.0627, 0.0721, 0.0654, 0.0574, 0.0847, 0.0624, 0.0646, 0.0731, 0.0417,
         0.0785, 0.0822, 0.0758, 0.0450, 0.0724, 0.0472, 0.0746, 0.0531, 0.0757,
         0.0597, 0.0451, 0.0572, 0.0801, 0.0545],
        [0.0441, 0.0616, 0.0466, 0.0689, 0.0495, 0.0722, 0.0483, 0.0647, 0.0612,
         0.0630, 0.0418, 0.0660, 0.0426, 0.0495, 0.0602, 0.0546, 0.0556, 0.0624,
         0.0667, 0.0522, 0.0650, 0.0575, 0.0519, 0.0533, 0.0434, 0.0656, 0.0496,
         0.0556, 0.0607, 0.0524, 0.0680, 0.0523],
        [0.0619, 0.0684, 0.0721, 0.0675, 0.0496, 0.0496, 0.0457, 0.0718, 0.0553,
         0.0716, 0.0575, 0.0490, 0.0416, 0.0622, 0.0641, 0.0514, 0.0416, 0.0654,
         0.0554, 0.0729, 0.0425, 0.0622, 0.0613, 0.0408, 0.0671, 0.0709, 0.0683,
         0.0504, 0.0729, 0.0594, 0.0843, 0.0415],
        [0.0611, 0.0476, 0.0465, 0.0720, 0.0593, 0.0694, 0.0514, 0.0567, 0.0402,
         0.0486, 0.0528, 0.0681, 0.0685, 0.0574, 0.0479, 0.0513, 0.0567, 0.0568,
         0.0397, 0.0566, 0.0468, 0.0522, 0.0866, 0.0521, 0.0476, 0.0506, 0.0766,
         0.0457, 0.0557, 0.0538, 0.0378, 0.0650],
        [0.0602, 0.0519, 0.0635, 0.0535, 0.0659, 0.0510, 0.0662, 0.0578, 0.0557,
         0.0503, 0.0622, 0.0548, 0.0356, 0.0513, 0.0511, 0.0664, 0.0545, 0.0591,
         0.0698, 0.0582, 0.0573, 0.0518, 0.0613, 0.0565, 0.0509, 0.0509, 0.0641,
         0.0627, 0.0607, 0.0529, 0.0444, 0.0726],
        [0.0667, 0.0752, 0.0607, 0.0545, 0.0510, 0.0648, 0.0617, 0.0490, 0.0596,
         0.0635, 0.0731, 0.0628, 0.0564, 0.0746, 0.0745, 0.0429, 0.0475, 0.0575,
         0.0526, 0.0627, 0.0513, 0.0566, 0.0878, 0.0467, 0.0578, 0.0486, 0.0630,
         0.0506, 0.0659, 0.0513, 0.0692, 0.0594],
        [0.0477, 0.0689, 0.0676, 0.0720, 0.0580, 0.0676, 0.0552, 0.0603, 0.0765,
         0.0517, 0.0705, 0.0437, 0.0598, 0.0642, 0.0551, 0.0627, 0.0560, 0.0494,
         0.0647, 0.0667, 0.0660, 0.0656, 0.0752, 0.0668, 0.0666, 0.0384, 0.0490,
         0.0551, 0.0464, 0.0694, 0.0542, 0.0533],
        [0.0434, 0.0676, 0.0507, 0.0507, 0.0533, 0.0605, 0.0561, 0.0648, 0.0513,
         0.0448, 0.0497, 0.0477, 0.0539, 0.0517, 0.0479, 0.0534, 0.0621, 0.0474,
         0.0512, 0.0683, 0.0577, 0.0663, 0.0484, 0.0554, 0.0575, 0.0477, 0.0585,
         0.0521, 0.0666, 0.0743, 0.0527, 0.0553],
        [0.0497, 0.0622, 0.0691, 0.0498, 0.0514, 0.0634, 0.0462, 0.0500, 0.0670,
         0.0511, 0.0545, 0.0597, 0.0452, 0.0489, 0.0941, 0.0449, 0.0707, 0.0495,
         0.0620, 0.0625, 0.0565, 0.0480, 0.0510, 0.0735, 0.0530, 0.0582, 0.0791,
         0.0423, 0.0625, 0.0465, 0.0560, 0.0526],
        [0.0736, 0.0691, 0.0605, 0.0460, 0.0650, 0.0673, 0.0768, 0.0615, 0.0550,
         0.0585, 0.0455, 0.0560, 0.0666, 0.0519, 0.0544, 0.0491, 0.0802, 0.0522,
         0.0379, 0.0590, 0.0748, 0.0610, 0.0582, 0.0490, 0.0587, 0.0556, 0.0470,
         0.0577, 0.0469, 0.0568, 0.0485, 0.0692],
        [0.0546, 0.0530, 0.0544, 0.0579, 0.0620, 0.0694, 0.0572, 0.0575, 0.0822,
         0.0643, 0.0507, 0.0612, 0.0608, 0.0498, 0.0456, 0.0627, 0.0441, 0.0596,
         0.0441, 0.0479, 0.0448, 0.0772, 0.0571, 0.0628, 0.0596, 0.0625, 0.0462,
         0.0567, 0.0627, 0.0628, 0.0484, 0.0565],
        [0.0582, 0.0586, 0.0591, 0.0531, 0.0594, 0.0771, 0.0497, 0.0725, 0.0523,
         0.0609, 0.0675, 0.0614, 0.0544, 0.0714, 0.0519, 0.0646, 0.0585, 0.0605,
         0.0620, 0.0496, 0.0533, 0.0857, 0.0614, 0.0882, 0.0869, 0.0625, 0.0595,
         0.0656, 0.0795, 0.0950, 0.0716, 0.0623],
        [0.0563, 0.0610, 0.0715, 0.0516, 0.0921, 0.0626, 0.0598, 0.0457, 0.0586,
         0.0615, 0.0662, 0.0771, 0.0525, 0.0511, 0.0782, 0.0519, 0.0387, 0.0551,
         0.0504, 0.0801, 0.0917, 0.0654, 0.0746, 0.0638, 0.0647, 0.0527, 0.0492,
         0.0698, 0.0802, 0.0788, 0.0495, 0.0636],
        [0.0645, 0.0545, 0.0515, 0.0445, 0.0534, 0.0541, 0.0508, 0.0477, 0.0488,
         0.0661, 0.0543, 0.0543, 0.0794, 0.0539, 0.0405, 0.0502, 0.0532, 0.0564,
         0.0626, 0.0670, 0.0636, 0.0571, 0.0548, 0.0549, 0.0594, 0.0506, 0.0430,
         0.0724, 0.0574, 0.0608, 0.0608, 0.0622],
        [0.0498, 0.0473, 0.0572, 0.0486, 0.0632, 0.0670, 0.0474, 0.0775, 0.0668,
         0.0550, 0.0586, 0.0523, 0.0569, 0.0650, 0.0631, 0.0501, 0.0461, 0.0510,
         0.0480, 0.0611, 0.0647, 0.0383, 0.0534, 0.0685, 0.0541, 0.0521, 0.0706,
         0.0468, 0.0396, 0.0706, 0.0505, 0.0705],
        [0.0546, 0.0924, 0.0680, 0.0673, 0.0621, 0.0674, 0.0558, 0.0574, 0.0594,
         0.0853, 0.0512, 0.0619, 0.0584, 0.0572, 0.0440, 0.0667, 0.0485, 0.0920,
         0.0802, 0.0420, 0.0569, 0.0446, 0.0645, 0.0544, 0.0605, 0.0575, 0.0617,
         0.0584, 0.0686, 0.0521, 0.0680, 0.0919],
        [0.0546, 0.0512, 0.0776, 0.0519, 0.0572, 0.0520, 0.0540, 0.0519, 0.0719,
         0.0471, 0.0528, 0.0623, 0.0730, 0.0525, 0.0671, 0.0594, 0.0513, 0.0460,
         0.0587, 0.0508, 0.0713, 0.0645, 0.0789, 0.0480, 0.0647, 0.0574, 0.0590,
         0.0620, 0.0540, 0.0490, 0.0531, 0.0441],
        [0.0411, 0.0512, 0.0594, 0.0520, 0.0518, 0.0557, 0.0472, 0.0573, 0.0856,
         0.0525, 0.0473, 0.0376, 0.0528, 0.0581, 0.0530, 0.0502, 0.0507, 0.0582,
         0.0584, 0.0718, 0.0704, 0.0549, 0.0468, 0.0437, 0.0402, 0.0575, 0.0537,
         0.0440, 0.0485, 0.0670, 0.0572, 0.0453]], device='cuda:0')
***********
SINR = tensor([5.7205, 6.1109, 5.3428, 6.0143, 5.8804, 6.1344, 5.9551, 5.7667, 5.7595,
        6.0821, 5.9989, 5.8942, 5.9450, 5.4416, 5.5980, 6.0087, 6.0328, 5.6228,
        5.9143, 6.2534], device='cuda:0')
Real_SINR = tensor([5.9065, 6.0124, 4.4213, 5.5449, 5.6790, 5.8067, 5.5497, 6.0321, 5.5396,
        5.4439, 5.4124, 5.3491, 5.5133, 5.0595, 5.2497, 5.2586, 5.8398, 5.2326,
        5.1391, 6.4872], device='cuda:0')
Real_SINR_noise.shape = torch.Size([20])
ldm/modules/diffusionmodules/util.py, make_ddim_timsteps ddim_discr_method = uniform
ldm/modules/diffusionmodules/util.py, make_ddim_timsteps, Selected timesteps for ddim sampler: (200,)
ldm/modules/diffusionmodules/util.py, make_ddim_sampling_parameters, Selected alphas for ddim sampler: a_t: torch.Size([200]); a_(t-1): (200,)
For the chosen value of eta, which is 0.0, this results in the following sigma_t schedule for ddim sampler tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], dtype=torch.float64)
ddim.py alphas_cumprod = torch.Size([1000])
ddim.py, alpha_bar_u = tensor([0.7887, 0.8033, 0.7739, 0.7998, 0.7948, 0.8042, 0.7976, 0.7905, 0.7902,
        0.8023, 0.7992, 0.7953, 0.7972, 0.7778, 0.7840, 0.7996, 0.8004, 0.7849,
        0.7961, 0.8084], device='cuda:0')
ddim.py start_timesteps after clamp S = 200 : tensor([177, 168, 187, 170, 173, 167, 171, 176, 176, 168, 170, 173, 172, 185,
        181, 170, 170, 180, 172, 164], device='cuda:0')
d = torch.Size([20, 4, 32, 32])
recoverd_img = torch.Size([20, 3, 256, 256])
20 images are saved in outputs/MIMOdiffusion/M=64/K=32/dynamic/
20 images are saved in outputs/MIMOdiffusion/M=64/K=32/nonoisenosample/
